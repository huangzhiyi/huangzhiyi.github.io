<!doctype html><html lang=zh><meta charset=utf-8><meta name=viewport content="width=device-width"><title>Part 10 - Flume 和 Sqoop 操作实例 | Hadoop集群部署与开发 | Heis</title><meta name=generator content="Hugo Eureka 0.8.4"><link rel=stylesheet href=/css/eureka.min.css><script defer src=/js/eureka.min.js></script><script src=/static/js/jquery-3.6.0.min.js></script><script src=/static/js/heis.js?230321></script><link rel=stylesheet href=/static/css/heis.css?230321 media=all onload="this.media='all';this.onload=null" crossorigin><link rel=stylesheet href=/static/css/print.css?230413 media=print crossorigin><link rel=stylesheet href=/static/css/highlight-css/solarized-light.min.css media=print onload="this.media='all';this.onload=null" crossorigin><script defer src=/static/js/highlight.min.js crossorigin></script><script defer src=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14.0/js/all.min.js integrity="sha256-uNYoXefWRqv+PsIF/OflNmwtKM4lStn9yrz2gVl6ymo=" crossorigin></script><script defer src=/static/js/highlightjs-line-numbers.min.js></script><link rel=icon type=image/png sizes=32x32 href=/images/icon_huddfe7d1590fd89155f46b33625956ea5_4357_32x32_fill_box_center_2.png><link rel=apple-touch-icon sizes=180x180 href=/images/icon_huddfe7d1590fd89155f46b33625956ea5_4357_180x180_fill_box_center_2.png><meta name=description content="Part 10 - Flume 和 Sqoop 操作实例"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"系列文章","item":"/docs/"},{"@type":"ListItem","position":2,"name":"Hadoop集群部署与开发","item":"/docs/hadoop-d/"},{"@type":"ListItem","position":3,"name":"Part 10 - Flume 和 Sqoop 操作实例","item":"/docs/hadoop-d/hadoop-d10/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"/docs/hadoop-d/hadoop-d10/"},"headline":"Part 10 - Flume 和 Sqoop 操作实例 | Hadoop集群部署与开发 | Heis","datePublished":"2021-06-01T10:20:00+08:00","dateModified":"2021-06-01T10:20:00+08:00","wordCount":3461,"author":{"@type":"Person","name":"heis"},"publisher":{"@type":"Person","name":"C. Wang","logo":{"@type":"ImageObject","url":"/images/icon.png"}},"description":"Part 10 - Flume 和 Sqoop 操作实例"}</script><meta property="og:title" content="Part 10 - Flume 和 Sqoop 操作实例 | Hadoop集群部署与开发 | Heis"><meta property="og:type" content="article"><meta property="og:image" content="/images/icon.png"><meta property="og:url" content="/docs/hadoop-d/hadoop-d10/"><meta property="og:description" content="Part 10 - Flume 和 Sqoop 操作实例"><meta property="og:locale" content="zh"><meta property="og:site_name" content="Heis"><meta property="article:published_time" content="2021-06-01T10:20:00+08:00"><meta property="article:modified_time" content="2021-06-01T10:20:00+08:00"><meta property="article:section" content="docs"><meta property="article:tag" content="hadoop"><meta property="article:tag" content="大数据"><meta property="article:tag" content="课程"><meta property="og:see_also" content="/docs/hadoop-d/hadoop-d09/"><meta property="og:see_also" content="/docs/hadoop-d/hadoop-d08/"><meta property="og:see_also" content="/docs/hadoop-d/hadoop-d07/"><meta property="og:see_also" content="/docs/hadoop-d/hadoop-d06/"><meta property="og:see_also" content="/docs/hadoop-d/hadoop-d05/"><meta property="og:see_also" content="/docs/hadoop-d/hadoop-d04/"><script>var _hmt=_hmt||[];(function(){var hm=document.createElement("script");hm.src="https://hm.baidu.com/hm.js?f58b6a2675cf52000232edb4d109eccc";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();</script><body class="flex flex-col min-h-screen"><header id=headerctn class="fixed flex items-center w-full pl-scrollbar z-50 bg-secondary-bg shadow-sm"><div class="w-full max-w-screen-xl mx-auto"><script>let storageColorScheme=localStorage.getItem("lightDarkMode")
if(((storageColorScheme=='Auto'||storageColorScheme==null)&&window.matchMedia("(prefers-color-scheme: dark)").matches)||storageColorScheme=="Dark"){document.getElementsByTagName('html')[0].classList.add('dark')}</script><nav class="flex items-center justify-between flex-wrap px-4 py-4 md:py-0"><a href=/ class="mr-6 text-primary-text text-xl font-bold">Heis</a>
<button id=navbar-btn class="md:hidden flex items-center px-3 py-2" aria-label="Open Navbar">
<i class="fas fa-bars"></i></button><div id=target class="hidden block md:flex md:flex-grow md:justify-between md:items-center w-full md:w-auto text-primary-text z-20"><div class="md:flex md:h-16 text-sm md:flex-grow pb-4 md:pb-0 border-b md:border-b-0"><a href=/posts/ class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2 border-transparent mr-4">文章</a>
<a href=/docs/ class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2 selected-menu-item mr-4">系列</a></div><div class=flex><div class="relative pt-4 md:pt-0"><div class="cursor-pointer hover:text-eureka" id=lightDarkMode><i class="fas fa-adjust"></i></div><div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-30" id=is-open></div><div class="absolute flex flex-col left-0 md:left-auto right-auto md:right-0 hidden bg-secondary-bg w-48 rounded py-2 border border-tertiary-bg cursor-pointer z-40" id=lightDarkOptions><span class="px-4 py-1 hover:text-eureka" name=Light>浅色</span>
<span class="px-4 py-1 hover:text-eureka" name=Dark>深色</span>
<span class="px-4 py-1 hover:text-eureka" name=Auto>自动</span></div></div></div></div><div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-0" id=is-open-mobile></div></nav><script>let element=document.getElementById('lightDarkMode')
if(storageColorScheme==null||storageColorScheme=='Auto'){document.addEventListener('DOMContentLoaded',()=>{window.matchMedia("(prefers-color-scheme: dark)").addEventListener('change',switchDarkMode)})}else if(storageColorScheme=="Light"){element.firstElementChild.classList.remove('fa-adjust')
element.firstElementChild.setAttribute("data-icon",'sun')
element.firstElementChild.classList.add('fa-sun')}else if(storageColorScheme=="Dark"){element.firstElementChild.classList.remove('fa-adjust')
element.firstElementChild.setAttribute("data-icon",'moon')
element.firstElementChild.classList.add('fa-moon')}
document.addEventListener('DOMContentLoaded',()=>{getcolorscheme();switchBurger();});</script></div></header><main class="flex-grow pt-16"><div class=pl-scrollbar><div class="w-full max-w-screen-xl lg:px-4 xl:px-8 mx-auto"><div id=doc-container class=lg:pt-12><div class="flex flex-col md:flex-row bg-secondary-bg rounded"><div class="md:w-1/4 lg:w-1/5 border-r"><div class="sticky top-16 pt-6"><div id=sidebar-title class="md:hidden mx-4 px-2 pt-4 pb-2 md:border-b text-tertiary-text md:text-primary-text"><span class=font-semibold>目录</span>
<i class="fas fa-caret-right ml-1"></i></div><div id=sidebar-toc class="hidden md:block overflow-y-auto mx-6 md:mx-0 pr-6 pt-2 md:max-h-doc-sidebar bg-primary-bg md:bg-transparent"><div class="flex flex-wrap ml-4 -mr-2 p-2 bg-secondary-bg md:bg-primary-bg rounded"><a class=hover:text-eureka href=/docs/hadoop-d/>Hadoop集群部署与开发</a></div><ul class=pl-6><li class=py-2><div><a class=hover:text-eureka href=/docs/hadoop-d/hadoop-d01/>Part 1 - 模板机制作</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/hadoop-d/hadoop-d02/>Part 2 - 部署 Hadoop 完全分布模式（Fully Distributed Mode）</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/hadoop-d/hadoop-d03/>Part 3 - 通过 Shell 命令访问 HDFS</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/hadoop-d/hadoop-d04/>Part 4 - 搭建 Hadoop 开发环境</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/hadoop-d/hadoop-d05/>Part 5 - HDFS Java 编程访问</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/hadoop-d/hadoop-d06/>Part 6 - 编写 MapReduce 程序</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/hadoop-d/hadoop-d07/>Part 7 - 部署 Hive 和 Hive 常用操作</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/hadoop-d/hadoop-d08/>Part 8 - 部署 HBase 和 HBase 常用操作</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/hadoop-d/hadoop-d09/>Part 9 - 部署 ZooKeeper 和 ZooKeeper 常用操作</a></div></li><li class=py-2><div><a class="text-eureka hover:text-eureka" href=/docs/hadoop-d/hadoop-d10/>Part 10 - Flume 和 Sqoop 操作实例</a></div></li></ul></div></div></div><div class="w-full md:w-3/4 lg:w-4/5 pb-8 pt-2 md:pt-8"><div id=doc-tit class="w-full lg:w-3/4 pl-6 ml-0 mr-auto"><h1 class="font-bold text-3xl text-primary-text">Part 10 - Flume 和 Sqoop 操作实例</h1><div class="flex flex-wrap flex-row items-center mt-2 text-tertiary-text"><div class="mr-6 my-2"><i class="fas fa-calendar mr-1"></i><span>2021-06-01</span></div><div class="mr-6 my-2"><i class="fas fa-clock mr-1"></i><span>7分钟阅读时长</span></div><div class="mr-6 my-2"><i class="fas fa-folder mr-1"></i><a href=/categories/hadoopd/ class=hover:text-eureka>hadoopd</a></div></div></div><div class=flex><div class="w-full lg:w-3/4 px-6"><div class=content><h2 id=版本>【版本】</h2><p>当前版本号<code>v20230414</code></p><div class=tbl-start></div><table><thead><tr><th>版本</th><th>修改说明</th></tr></thead><tbody><tr><td>v20230414</td><td>修改nc命令的注释，增加安装命令</td></tr><tr><td>v20220418</td><td>上传commons-lang包，修复sqoop从MariaDB到HBase导入数据的错误</td></tr><tr><td>v20210611</td><td>新增Sqoop的内容</td></tr><tr><td>v20210607</td><td>初始化版本</td></tr></tbody></table><div class=tbl-end style=height:10px></div><h2 id=实验101----部署-flume>实验10.1 - 部署 Flume</h2><h2 id=实验目的>【实验目的】</h2><ul><li>部署 Flume</li></ul><h2 id=实验环境>【实验环境】</h2><ul><li>Hadoop 3</li><li>CentOS 7</li></ul><h2 id=实验资源>【实验资源】</h2><ul><li>Flume 安装包</li></ul><pre><code>链接：https://pan.baidu.com/s/1MoQ0iU0Qb1o8_o5JV6X6iw 
提取码：3rno
</code></pre><h2 id=实验内容>【实验内容】</h2><ul><li>部署 Flume</li></ul><h2 id=实验步骤>【实验步骤】</h2><ol><li>在NodeA节点运行以下语句，注意提升为root权限执行。</li></ol><ul><li>创建 Flume 的安装目录。</li></ul><pre><code>su
mkdir /opt/flume
chown hadoop:wheel /opt/flume
</code></pre><ul><li>提升 root 用户权限执行以下语句，加入 ZooKeeper 环境变量。</li></ul><pre><code>su
echo &quot;export FLUME_HOME=/opt/flume
export PATH=\$FLUME_HOME/bin:\$PATH&quot; &gt;&gt;/etc/profile
</code></pre><ul><li>切换回 hadoop 用户</li></ul><pre><code>su hadoop
</code></pre><ul><li>使环境变量生效。</li></ul><pre><code>source /etc/profile
</code></pre><ol start=2><li>使用 hadoop 登录NodeA节点。</li></ol><pre><code>su hadoop
</code></pre><ol start=3><li><p>上传 Flume 安装包<code>apache-flume-1.8.0-bin.tar.gz</code> 到 NodeA 节点 <code>/home/hadoop</code> 目录。</p></li><li><p>解压<code>apache-flume-1.8.0-bin.tar.gz</code>到<code>/home/hadoop</code> 目录。</p></li></ol><pre><code>tar -xvf apache-flume-1.8.0-bin.tar.gz
</code></pre><ol start=5><li>把解压以后的目录移到安装目录</li></ol><pre><code>sudo mv ~/apache-flume-1.8.0-bin/* /opt/flume
</code></pre><ol start=6><li>输入命令查看 Flume 版本</li></ol><pre><code>flume-ng version
</code></pre><h2 id=实验102-flume-的配置与使用-avrosource---memorychannel---loggersink>实验10.2 Flume 的配置与使用 Avro(Source) -> Memory(Channel) -> Logger(Sink)</h2><h2 id=实验目的-1>【实验目的】</h2><ul><li><ol><li>理解 Flume 的基本原理，掌握各组件的作用及关系。</li></ol></li><li><ol start=2><li><table><thead><tr><th>熟悉 Flume 的常用配置。</th></tr></thead></table></li></ol></li></ul><h2 id=实验原理>【实验原理】</h2><p>Avro Source 会启动一个 RPC 的 Netty 服务器，此实验配置监听端口为 4141 。Avro Source 通过监听发送过来的文件，通过 Flume 的 Channel，输出到 Logger Sink。Logger Sink 可以打印文件的内容到控制台。</p><h2 id=实验环境-1>【实验环境】</h2><ul><li>Hadoop 3</li><li>CentOS 7</li><li>Flume 1.8.0 （下载地址：https://mirrors.tuna.tsinghua.edu.cn/apache/flume/1.8.0/apache-flume-1.8.0-bin.tar.gz）</li><li></li></ul><h2 id=实验内容-1>【实验内容】</h2><ul><li>配置 Flume 与使用 Avro(Source)、Memory(Channel)、Logger(Sink)组合的Agent</li></ul><h2 id=实验步骤-1>【实验步骤】</h2><ol><li>创建 Agent 配置文件/opt/flume/conf/avro.conf，并按如下配置。</li></ol><pre><code>vim /opt/flume/conf/avro.conf
</code></pre><pre><code>agent1.sources = srch2
agent1.sinks = ssink2
agent1.channels = ch1

# 配置 Source 监听端口为4141的 avro 服务
agent1.sources.srch2.type = avro
agent1.sources.srch2.bind = 0.0.0.0
agent1.sources.srch2.port = 4141
agent1.sources.srch2.channels = ch1

# 配置 Sink
agent1.sinks.ssink2.type = logger
agent1.sinks.ssink2.channel = ch1

# 配置 Channel
agent1.channels.ch1.type = memory
agent1.channels.ch1.capacity = 1000
agent1.channels.ch1.transactionCapacity = 100

</code></pre><ol start=2><li>启动 Agent agent1，命令如下。</li></ol><pre><code>flume-ng agent --conf /opt/flume/conf/ --conf-file /opt/flume/conf/avro.conf --name agent1 -Dflume.root.logger=INFO,console
</code></pre><ol start=3><li>用 XShell 重新打开一个新终端窗口，创建 avro-input1.txt 输入一些信息。</li></ol><pre><code>echo &quot;hello flume&quot; &gt; ~/avro-input1.txt
</code></pre><ol start=4><li>在新终端窗口使用 avro-client 向 agent1 监听的 avro 服务发送文件。</li></ol><pre><code>flume-ng avro-client -c /opt/flume/conf/ -H 0.0.0.0 -p 4141 -F ~/avro-input1.txt
</code></pre><ol start=5><li>在第一个终端窗口输出信息的最后一行可看到发送文件的内容。</li></ol><pre><code>2021-06-07 17:00:36,006 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: { headers:{} body: 68 65 6C 6C 6F 20 66 6C 75 6D 65                hello flume }
</code></pre><h2 id=实验-103-flume-的配置与使用-syslogsource---memorychannel---hdfssink>实验 10.3 Flume 的配置与使用 Syslog(Source) -> Memory(Channel) -> HDFS(Sink)</h2><h2 id=实验目的-2>【实验目的】</h2><p>1．理解 Flume 的基本原理，掌握各组件的作用及关系。
2．熟悉 Flume 的常用配置。</p><h2 id=实验原理-1>【实验原理】</h2><p>Syslog Source 读取 syslog 数据，产生 Event，syslog 支持 UDP 和 TCP 协议。通过 Memory Channel，把 Event 写入 HDFS。</p><h2 id=实验环境-2>【实验环境】</h2><ul><li>Hadoop 3</li><li>CentOS 7</li><li>Flume 1.8.0 （下载地址：https://mirrors.tuna.tsinghua.edu.cn/apache/flume/1.8.0/apache-flume-1.8.0-bin.tar.gz）</li></ul><h2 id=实验内容-2>【实验内容】</h2><ul><li>配置 Flume 与使用 Syslog(Source)、Memory(Channel) 、HDFS(Sink)组合的Agent</li></ul><h2 id=实验步骤-2>【实验步骤】</h2><ol><li>创建 Agent 配置文件/opt/flume/conf/syslogtcp.conf，并按如下配置。注意替换为你的学号。</li></ol><pre><code>vim /opt/flume/conf/syslogtcp.conf
</code></pre><pre><code>agent2.sources = src2
agent2.sinks = sink2
agent2.channels = ch2
# 配置 Source
agent2.sources.src2.type = syslogtcp
agent2.sources.src2.port = 5140
agent2.sources.src2.host = localhost
agent2.sources.src2.channels = ch2
# 配置 Sink
agent2.sinks.sink2.type = hdfs
#注意这里的 HDFS 的IP地址替换为你的真实IP地址
agent2.sinks.sink2.hdfs.path = hdfs://nodea你的学号后4位:8020/user/hadoop/flume/syslogtcp输入你的学号后4位
agent2.sinks.sink2.hdfs.filePrefix = Syslog
agent2.sinks.sink2.hdfs.round = true
agent2.sinks.sink2.hdfs.roundValue = 10
agent2.sinks.sink2.hdfs.roundUnit = minute
agent2.sinks.sink2.channel = ch2

# 配置 Channel
agent2.channels.ch2.type = memory
agent2.channels.ch2.capacity = 1000
agent2.channels.ch2.transactionCapacity = 100
# 绑定 Source 和 Sink 到 Channel
</code></pre><ol start=2><li>启动 HDFS。</li></ol><pre><code>start-dfs.sh
</code></pre><ol start=3><li>启动 Agent agent2，命令如下。</li></ol><pre><code>flume-ng agent -c /opt/flume/conf/ -f /opt/flume/conf/syslogtcp.conf -n agent2 -Dflume.root.logger=INFO,console
</code></pre><ol start=4><li>XShell 启动一个新的终端窗口，输入以下命令，测试产生 syslog。请注意以下命令需要替换为你的个人学号。</li></ol><pre><code>echo &quot;hello 替换为你的学号&quot; | nc localhost 5140
</code></pre><blockquote><p>注1：nc命令找不到，可以使用 yum install nc -y 命令安装。关于nc（netcat）命令，大家可以搜索“Linux netcat 命令”或参考 <a href=http://www.linuxso.com/command/nc.html>http://www.linuxso.com/command/nc.html</a></p><p>注2：关于 | （管道）命令，大家可以搜索“Linux 管道 命令”或参考 <a href=https://blog.csdn.net/hellojoy/article/details/77337854>https://blog.csdn.net/hellojoy/article/details/77337854</a></p></blockquote><ol start=5><li>在新的终端窗口查看 HDFS 相应配置的路径上是否生成了 syslogtcp 文件，并查看文件内容，正确能看到“hello 你的学号”。（请注意以下命令需要替换为你的个人学号。）</li></ol><pre><code>hdfs dfs -ls /user/hadoop/flume/syslogtcp你的学号后4位
</code></pre><pre><code>hdfs dfs -cat /user/hadoop/flume/syslogtcp你的学号后4位/Syslog.xxxxxx
</code></pre><h2 id=实验-104-sqoop-的安装>实验 10.4 Sqoop 的安装</h2><h2 id=实验目的-3>【实验目的】</h2><ul><li>熟悉 Sqoop 的安装</li></ul><h2 id=实验环境-3>【实验环境】</h2><ul><li>Hadoop 3</li><li>CentOS 7</li><li>Sqoop 1.4.7</li></ul><h2 id=实验资源-1>【实验资源】</h2><ul><li>Sqoop 安装包</li></ul><pre><code>链接：https://pan.baidu.com/s/1MoQ0iU0Qb1o8_o5JV6X6iw 
提取码：3rno
</code></pre><h2 id=实验内容-3>【实验内容】</h2><ul><li>安装 Sqoop</li></ul><h2 id=实验步骤-3>【实验步骤】</h2><ol><li>在NodeA节点运行以下语句，注意提升为root权限执行。</li></ol><ul><li>创建 Sqoop 的安装目录。</li></ul><pre><code>su
mkdir /opt/sqoop
chown hadoop:wheel /opt/flume
</code></pre><ul><li>提升 root 用户权限执行以下语句，加入 ZooKeeper 环境变量。</li></ul><pre><code>su
echo &quot;export SQOOP_HOME=/opt/sqoop
export PATH=\$SQOOP_HOME/bin:\$PATH&quot; &gt;&gt;/etc/profile
</code></pre><ul><li>切换 hadoop 用户</li></ul><pre><code>su hadoop
</code></pre><ul><li>使环境变量生效。</li></ul><pre><code>source /etc/profile
</code></pre><ol start=2><li>使用 hadoop 登录NodeA节点。</li></ol><pre><code>su hadoop
</code></pre><ol start=3><li><p>上传 Sqoop 安装包<code>sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz</code> 到 NodeA 节点 <code>/home/hadoop</code> 目录。</p></li><li><p>解压<code>sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz</code>到<code>/home/hadoop</code> 目录。</p></li></ol><pre><code>tar -xvf sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz
</code></pre><ol start=5><li>把解压以后的目录移到安装目录</li></ol><pre><code>sudo mv ~/sqoop-1.4.7.bin__hadoop-2.6.0/* /opt/sqoop
</code></pre><ol start=6><li>查看 Sqoop 版本，验证 Sqoop 是否正确安装</li></ol><pre><code>sqoop version
</code></pre><ol start=7><li><p>上传 MySQL 的驱动包 <code>mysql-connector-java-5.1.48.jar</code> 到<code>/home/hadoop</code> 目录。</p></li><li><p>拷贝驱动包到 Sqoop 的 lib 目录下。</p></li></ol><pre><code>mv ~/mysql-connector-java-5.1.48.jar $SQOOP_HOME/lib
</code></pre><ol start=9><li>拷贝 Hive 的依赖包到 Sqoop 的 lib 目录下。</li></ol><pre><code>cp $HIVE_HOME/lib/hive-common-2.3.8.jar $SQOOP_HOME/lib/
</code></pre><h2 id=实验-105-使用-sqoop-进行数据转换>实验 10.5 使用 Sqoop 进行数据转换</h2><h2 id=实验目的-4>【实验目的】</h2><ul><li>掌握使用 Sqoop 在 MariaDB、Hive、HDFS、HBase 之间进行数据转换</li></ul><h2 id=实验环境-4>【实验环境】</h2><ul><li>Hadoop 3</li><li>CentOS 7</li><li>Sqoop 1.4.7 （下载地址：https://mirrors.tuna.tsinghua.edu.cn/apache/sqoop/1.4.7/sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz）</li></ul><h2 id=实验资源-2>【实验资源】</h2><ul><li>commons-lang-2.6.jar</li></ul><h2 id=实验内容-4>【实验内容】</h2><ul><li>使用 Sqoop 在 MariaDB、Hive、HDFS、HBase 之间进行数据转换</li></ul><h2 id=实验步骤-4>【实验步骤】</h2><ol><li>使用 hadoop 登录NodeA节点。</li></ol><pre><code>su hadoop
</code></pre><ol start=2><li><p>上传员工表SQL脚本文件 <code>EMP.sql</code> 到 <code>/home/hadoop</code></p></li><li><p>使用 root 用户登录 MariaDB。</p></li></ol><pre><code>mysql -u root -p
</code></pre><ol start=4><li>在 MariaDB 中创建 sqoop 库和 sqoop 用户。</li></ol><pre><code>create database sqoopdb;
use sqoopdb；
create user 'sqoop'@'localhost' identified by 'sqoop123';
create user 'sqoop'@'%' identified by 'sqoop123';
grant all on sqoopdb.* to 'sqoop'@'localhost';
grant all on sqoopdb.* to 'sqoop'@'%';
</code></pre><ol start=5><li>执行 <code>EMP.sql</code> 文件 SQL 语句。</li></ol><pre><code>use sqoopdb；
source /home/hadoop/EMP.sql
</code></pre><ol start=6><li>在 MariaDB 查询员工表内容。</li></ol><pre><code>select * from EMP;
</code></pre><ol start=7><li>退出 MariaDB 的命令终端</li></ol><pre><code>exit
</code></pre><ol start=8><li>使用 Sqoop 对 MariaDB 的数据库进行查询。是否存在库 <code>sqoopdb</code></li></ol><pre><code>sqoop list-databases --connect jdbc:mysql://localhost:3306/ --username root -password 123456
</code></pre><ol start=9><li>使用 Sqoop 对 MariaDB 的数据库 sqoopdb 进行查询。是否存在表<code>EMP</code>。</li></ol><pre><code>sqoop list-tables --connect jdbc:mysql://localhost:3306/sqoopdb --username sqoop -password sqoop123
</code></pre><h3 id=导入数据从-mariadb-到-hdfs>导入数据从 MariaDB 到 HDFS</h3><ol start=10><li>启动 Hadoop。</li></ol><pre><code>start-hdp.sh
</code></pre><ol start=11><li>把 MariaDB 中的 <code>EMP</code>表导出到 HDFS 的 <code>/sqoop</code>目录。其中参数 <code>-m 1</code> 表示使用1个 Mapper。注意替换为你的学号后4位。</li></ol><pre><code>hdfs dfs -rm -r /sqoop
sqoop import --connect jdbc:mysql://nodea你的学号后4位:3306/sqoopdb --username sqoop -password sqoop123 --table EMP -target-dir /sqoop -m 1
</code></pre><ol start=12><li>输出导入的结果进行查看</li></ol><pre><code>hdfs dfs -cat /sqoop/part-m-00000
</code></pre><h3 id=导入数据从-mariadb-到-hive>导入数据从 MariaDB 到 Hive</h3><ol start=13><li>把 MariaDB 的<code>EMP</code>表导入到 Hive。注意替换为你的学号。</li></ol><pre><code>sqoop import --connect jdbc:mysql://nodea你的学号后4位:3306/sqoopdb --username sqoop -password sqoop123 --table EMP --fields-terminated-by '\t' --target-dir /user/hadoop/db2hive --num-mappers 1 --hive-database default --hive-import --hive-table emp
</code></pre><ol start=14><li>进入 Hive，并查询 emp 表的内容。</li></ol><pre><code>hive
</code></pre><pre><code>hive (default)&gt; use default;
hive (default)&gt; select * from emp;
</code></pre><h3 id=导入数据从-mariadb-到-hbase>导入数据从 MariaDB 到 HBase</h3><ol start=15><li>启动 HBase，并登录 HBase。</li></ol><pre><code>start-dfs.sh
start-hbase.sh
hbase shell
</code></pre><ol start=16><li>创建一个 HBase 表 EMP。</li></ol><pre><code>create 'EMP', { NAME =&gt; 'EMPINFO', VERSIONS =&gt; 5}
</code></pre><blockquote><p>注：上面命令在 HBase 中创建了一个 EMP 表，这个表中有一个列族 EMPINFO，历史版本保留数量为 5。</p></blockquote><ol start=17><li>创建完成，通过命令 list 可看到 HBase 中有表 EMP。</li></ol><pre><code>list
</code></pre><ol start=18><li>退出HBase Shell。</li></ol><pre><code>quit
</code></pre><ol start=19><li>把<code>commons-lang-2.6.jar</code>上传到 <code>/opt/sqoop/lib</code>目录。</li><li>修改<code>commons-lang-2.6.jar</code> 权限，让<code>hadoop</code>用户可以读取。</li></ol><pre><code>chown hadoop:wheel /opt/sqoop/lib/commons-lang-2.6.jar
chmod 544 /opt/sqoop/lib/commons-lang-2.6.jar
</code></pre><ol start=21><li>执行以下命令把 MariaDB 中的 EMP 表导入到 HBase 中的 EMP 表，并使用 <code>EMPNO</code> 作为 <code>Row key</code>。注意替换为你的学号。</li></ol><pre><code>sqoop import --connect jdbc:mysql://nodea你的学号后4位:3306/sqoopdb --username sqoop --password sqoop123 --table EMP --hbase-table EMP --column-family EMPINFO --hbase-row-key EMPNO
</code></pre><ol start=22><li>再次进入 Hbase Shell</li></ol><pre><code>hbase shell
</code></pre><ol start=23><li>查看 EMP 表的数据</li></ol><pre><code>scan 'EMP'
</code></pre><h3 id=导出数据从-hdfs-到-mariadb>导出数据从 HDFS 到 MariaDB</h3><ol start=24><li>在导出前需要在 MariaDB 中创建接收 HDFS 数据的空表<code>EMP2</code>。登录 sqp。</li></ol><pre><code>mysql sqoopdb -u sqoop -psqoop123
</code></pre><ol start=25><li>创建接收数据的空表 <code>EMP2</code></li></ol><pre><code>create table `EMP2` like `EMP`;
</code></pre><ol start=26><li>对比<code>EMP</code>和<code>EMP2</code>的表结构。</li></ol><pre><code>describe `EMP2`;
describe `EMP`;
</code></pre><ol start=27><li>通过以下命令把之前导入到 HDFS 的数据，再次导出到 MariaDB 的 EMP2 表。注意替换为你的学号。</li></ol><pre><code>sqoop export --connect jdbc:mysql://nodea你的学号后4位:3306/sqoopdb --table EMP2 --export-dir /sqoop/part-m-00000 --username sqoop --password sqoop123 -m 1
</code></pre><ol start=28><li>导出成功后可进入 MariaDB 查看导出的内容。</li></ol><pre><code>select * from  `EMP2`;
</code></pre></div><div class=my-4><a href=/tags/hadoop/ class="inline-block bg-tertiary-bg text-sm rounded px-3 py-1 my-1 mr-2 hover:text-eureka">#hadoop</a>
<a href=/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/ class="inline-block bg-tertiary-bg text-sm rounded px-3 py-1 my-1 mr-2 hover:text-eureka">#大数据</a>
<a href=/tags/%E8%AF%BE%E7%A8%8B/ class="inline-block bg-tertiary-bg text-sm rounded px-3 py-1 my-1 mr-2 hover:text-eureka">#课程</a></div><div class=py-2><div class="flex flex-col md:flex-row items-center my-8"><a href=/authors/heis/ class="w-24 h-24 md:mr-4"><img src=/static/img/authors/heis.png class="w-full bg-primary-bg rounded-full" alt=Avatar></a><div class="w-full md:w-auto mt-4 md:mt-0"><a href=/authors/heis/ class="block font-bold text-lg pb-1 mb-2 border-b">黄老师</a>
<span class="block pb-2"></span><a href=mailto:heishuangzy@qq.com class=mr-1><i class="fas fa-envelope"></i></a><a href=https://gitee.com/heis/ class=mr-1><i class="fab fa-git"></i></a><a href=http://heis.gitee.io/ class=mr-1><i class="fas fa-blog"></i></a></div></div></div><div id=btmQrcode></div><p style=text-align:center>扫码或长按识别访问</p><script src=/static/js/qrcode.min.js></script><script type=text/javascript>function getURL(){var url=window.location.href;if(window.location.hash!=""){url=url.substring(0,url.indexOf("#"));}
return url;}
new QRCode(document.getElementById("btmQrcode"),{text:getURL(),width:192,height:192,colorDark:"#000000",colorLight:"#ffffff",correctLevel:QRCode.CorrectLevel.H});</script><div class="flex flex-col md:flex-row md:justify-between -mx-2 mt-4 px-2 pt-4 border-t"><div id=presec><span class="block font-bold">上一页</span>
<a href=/docs/hadoop-d/hadoop-d09/ class=block>Part 9 - 部署 ZooKeeper 和 ZooKeeper 常用操作</a></div><div id=nextsec class="md:text-right mt-4 md:mt-0"></div></div></div><div class="hidden lg:block lg:w-1/4"><div class="sticky top-16 z-10 hidden lg:block px-6 py-4 bg-secondary-bg pt-16 -mt-16"><span class="text-lg font-semibold">本页内容</span></div><div class="sticky-toc hidden lg:block px-6 pb-6 pt-10 -mt-10 border-l"><nav id=TableOfContents><ul><li><a href=#版本>【版本】</a></li><li><a href=#实验101----部署-flume>实验10.1 - 部署 Flume</a></li><li><a href=#实验目的>【实验目的】</a></li><li><a href=#实验环境>【实验环境】</a></li><li><a href=#实验资源>【实验资源】</a></li><li><a href=#实验内容>【实验内容】</a></li><li><a href=#实验步骤>【实验步骤】</a></li><li><a href=#实验102-flume-的配置与使用-avrosource---memorychannel---loggersink>实验10.2 Flume 的配置与使用 Avro(Source) -> Memory(Channel) -> Logger(Sink)</a></li><li><a href=#实验目的-1>【实验目的】</a></li><li><a href=#实验原理>【实验原理】</a></li><li><a href=#实验环境-1>【实验环境】</a></li><li><a href=#实验内容-1>【实验内容】</a></li><li><a href=#实验步骤-1>【实验步骤】</a></li><li><a href=#实验-103-flume-的配置与使用-syslogsource---memorychannel---hdfssink>实验 10.3 Flume 的配置与使用 Syslog(Source) -> Memory(Channel) -> HDFS(Sink)</a></li><li><a href=#实验目的-2>【实验目的】</a></li><li><a href=#实验原理-1>【实验原理】</a></li><li><a href=#实验环境-2>【实验环境】</a></li><li><a href=#实验内容-2>【实验内容】</a></li><li><a href=#实验步骤-2>【实验步骤】</a></li><li><a href=#实验-104-sqoop-的安装>实验 10.4 Sqoop 的安装</a></li><li><a href=#实验目的-3>【实验目的】</a></li><li><a href=#实验环境-3>【实验环境】</a></li><li><a href=#实验资源-1>【实验资源】</a></li><li><a href=#实验内容-3>【实验内容】</a></li><li><a href=#实验步骤-3>【实验步骤】</a></li><li><a href=#实验-105-使用-sqoop-进行数据转换>实验 10.5 使用 Sqoop 进行数据转换</a></li><li><a href=#实验目的-4>【实验目的】</a></li><li><a href=#实验环境-4>【实验环境】</a></li><li><a href=#实验资源-2>【实验资源】</a></li><li><a href=#实验内容-4>【实验内容】</a></li><li><a href=#实验步骤-4>【实验步骤】</a><ul><li><a href=#导入数据从-mariadb-到-hdfs>导入数据从 MariaDB 到 HDFS</a></li><li><a href=#导入数据从-mariadb-到-hive>导入数据从 MariaDB 到 Hive</a></li><li><a href=#导入数据从-mariadb-到-hbase>导入数据从 MariaDB 到 HBase</a></li><li><a href=#导出数据从-hdfs-到-mariadb>导出数据从 HDFS 到 MariaDB</a></li></ul></li></ul></nav></div><script>window.addEventListener('DOMContentLoaded',()=>{enableStickyToc();});</script></div></div></div></div></div><div id=outerdiv><div id=innerdiv><img id=bigimg src></div></div><div id=popOuterDiv><div id=popDiv style=display:none><div class=close><span onclick="$('#popDiv').hide();"></span></div><p id=popCtn></p></div></div><div id=nav_top_icon style=display:none></div><div id=list_note_icon></div><script>$(function(){var scrollTop=$(window).scrollTop();if(scrollTop>0){$("#nav_top_icon").show(200);}
window.onscroll=function(){scrollTop=$(window).scrollTop();if(scrollTop==0){$("#nav_top_icon").hide(200);}else{$("#nav_top_icon").show(200);}}
$("#nav_top_icon").click(function(){$("body,html").animate({scrollTop:0},500);});$("#list_note_icon").click(function(){$("#popOuterDiv").toggle();$("#popDiv").slideToggle();$("#popCtn").html($("#TableOfContents").html());})
$("#popOuterDiv").click(function(){$("#popOuterDiv").hide();$("#popDiv").slideUp();})});document.addEventListener('DOMContentLoaded',()=>{hljs.highlightAll();hljs.initLineNumbersOnLoad({singleLine:true});changeSidebarHeight();switchDocToc();$("img").css("cursor:pointer")
$("img").click(function(){var _this=$(this);imgShow("#outerdiv","#innerdiv","#bigimg",_this);});$("ol").each(function(index){if(/\d{1,4}/.test($(this).attr("start"))){let idx=parseInt($(this).attr("start"));let lis=$(this).find("li");if(lis.length>0){lis.each(function(index){$(this).attr("id","step"+(idx+index));});}else{$(this).attr("id","step"+idx);}}});});</script><script src=/static/js/clipboard.min.js></script><script src=/static/js/codecopy.bundle.js?258></script></div></div></main><footer class=pl-scrollbar><div class="w-full max-w-screen-xl mx-auto"><div class="text-center p-6 pin-b"><p class="text-sm text-tertiary-text"></p></div></div></footer></body></html>