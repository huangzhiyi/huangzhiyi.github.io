+++
Description = "Hadoop Part 2 - 部署 Hadoop 完全分布模式（Fully Distributed Mode）"
Tags = ["hadoop","大数据"]
Categories = ["hadoopd"]
date = "2021-03-19T00:44:00+08:00"
draft = false
title = "Hadoop Part 2 - 部署 Hadoop 完全分布模式（Fully Distributed Mode）"
toc = true
authors = "heis"
weight = 200
+++

## 【版本】

当前版本号`v20210415`
<div class="tbl-start"></div>

|版本|修改说明|
|-|-|
|v20220124|增加了更多的解析，和分阶段展示步骤。|
|v20210415|修改了虚拟机名称的描述避免误解为hostname|
|v20210414|修改了步骤1，提示要使用hadoop用户进行登录|
|v20210408|新增配置到core-site.xml，修正jobhistoryserver意外退出的问题|
|v20210407-1|修正NodeB和NodeC的公钥操作|
|v20210407|修正authorized_keys 在 NodeB 和 NodeC 的操作|
|v20210406|修改了mapred-site.xml出现的配置错误；新增了把key写入 authorized_keys 步骤；增加了slaves的说明，避免出错；|
|v20210319|初始化版本|

<div class="tbl-end" style="height:10px"></div>

## 【实验目的】
- 掌握搭建 Hadoop 完全分布模式
- 熟练掌握Linux命令（vi、tar、mv等等）的使用
- 掌握VirtualBox、FinalShell等客户端的使用

## 【实验环境】
- 内存：至少4G
- 硬盘：至少空余40G
- 操作系统: 64位 Windows系统。

## 【实验资源】
- FinalShell
- CentOS 7.9系统镜像
- VirtualBox 6.5
- Hadoop 3 安装包
```
下载链接：https://pan.baidu.com/s/1ghde86wcK6pwg1fdSSWg0w
提取码：v3wv
```
## 【实验步骤】
### 克隆模板机
1. 关闭 Part1 完成的 HadoopTmpl 模板机。依次克隆出3台虚拟机，名称，主机名和 IP 地址如下表所示，注意替换为你的学号后3位。

<div class="tbl-start"></div>

|虚拟机名称|hostname|IP地址|
|-|-|-|
|节点A主机（Namenode）|nodea+你学号后3位|10.0.0.71|
|节点B主机（Datanode）|nodeb+你学号后3位|10.0.0.72|
|节点C主机（Datanode）|nodec+你学号后3位|10.0.0.73|

<div class="tbl-end" style="height:10px"></div>

![](/static/img/hadoop-d02/Snipaste_2022-01-21_17-36-15.png)
![](/static/img/hadoop-d02/Snipaste_2022-01-21_17-37-26.png)

2. 依次启动克隆的虚拟机，修改为对应的 hostname 和 IP。以下以`节点A主机（Namenode）`为例。

3. 使用`hadoop`用户登录节点A，密码为`123456`。

4. 修改 hostname。
```
sudo vim /etc/hostname
```
- 修改为`nodea+你学号后3位`
> 如果你学号是123，则命名为`nodea123`，相应的节点B和节点C分别命名为`nodeb123`和`nodec123`。

5. 修改 IP。
```
sudo vim /etc/sysconfig/network-scripts/ifcfg-enp0s3
```
- 修改`IPADDR="10.0.0.71"

6. 重启克隆的3台虚拟机，配置 FinalShell 分别连接3台虚拟机，使用`hadoop`用户登录，密码为`123456`，测试是否能够正常登录。

### 配置免密登录
> 免密登录，顾名思义就是不需要输入密码即可登录。免密登录的大致原理，就是在客户端 client 生成一对密钥（包括公钥和私钥），然后将公钥传到服务器 server。当 client 通过 ssh 登录 server 时，不用再输入密码就能直接登进去，这就是 ssh 免密登录。
>
> Hadoop 的 NameNode 是通过SSH 来启动和停止各个节点上的各种守护进程的，这就需要在节点之间执行指令的时候是不需要输入密码的方式，故我们需要配置SSH使用免密登录。
<div class="warning">注意此阶段命令如无特殊说明，均在 NodeA 的 hadoop 用户下执行！</div>

7. 使用 Hadoop 用户登录 NodeA 节点。如果使用root登录的可以使用以下命令切换到hadoop用户。
```
su hadoop
```

8. 使用 ping 命令检查是否能够连通 NodeB 和 NodeC。
```
ping nodeb+你学号后3位 -c 3
ping nodec+你学号后3位 -c 3
```
- 正常情况下应该有类似返回信息如下：
```
64 bytes from nodeb (10.0.0.72): icmp_seq=1 ttl=64 time=0.373 ms
```
- 如果没有看到以上返回消息，请检查`/etc/hosts`是否修改正确，参考 [Part1 步骤55](../hadoop-d01#step55)。

9. 配置免密登录。首先生成密钥对，运行以下命令。直接回车（Enter）3次。
```
ssh-keygen -t rsa
```

- 在返回的对话文字中，直接回车（Enter）3次，输出内容类似以下。
```
Generating public/private rsa key pair.
Enter file in which to save the key (/home/hadoop/.ssh/id_rsa): 
Created directory '/home/hadoop/.ssh'.
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in /home/hadoop/.ssh/id_rsa.
Your public key has been saved in /home/hadoop/.ssh/id_rsa.pub.
The key fingerprint is:
SHA256:MSUbr5VaCY4KSpsCM0l8uhYWkr5R9iNI05SFuF00jLA hadoop@nodea999
The key's randomart image is:
+---[RSA 2048]----+
|.+=.B+  + .      |
|+B.O o.o B o     |
|OE% o . = *      |
|o%o+ +   B       |
|+o= o . S        |
|.+               |
|.                |
|                 |
|                 |
+----[SHA256]-----+
```


10. 查看目录下是否有公钥`id_rsa.pub`和私钥`id_rsa`。
```
cd ~/.ssh
ls
```
- 可以看到以下2个文件。其中`id_rsa`是私钥，`id_rsa.pub`是公钥。
```
id_rsa  id_rsa.pub
```

11. 执行以下命令，把公钥写入本机授权文件。
```
cat id_rsa.pub >> authorized_keys
```

12. 查看授权文件内的公钥内容。
```
cd ~/.ssh
cat authorized_keys
```
- 可以看到类似以下内容
```
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC1Df9cM8NVGURMj3I86EoiO4Jy6LuuHOc+MC3vnZPJX9ISSXDZ9Qx+a5CCdoZJyySG3IlvAFBLv2Wnv60tDZ9xHEQ0WbkAV/IeDrdRk1OI51/bEGfdPqTLBtic1eXsFC6luc7kbQYuxQRoeovl2UwHNgzAX/xTyUV0uAuvTeggyGWq05I9OiantybrumNUJO8gFO3R9CA/zvNrJbuvVDKT9AAqQpn57jDsHkTiAlGoubKUcgAWy1EbYk7hVCL1gFkMcxDMvSOBoY23oqEFSNrkuho2Cj2fNUinaDNDPPzoqbDwvU9IUCGhgfiNYb4Ub/hoabJRjlcNiEgoD+G79lNd hadoop@nodea你的学号后3位
```

13. 确认`NodeB`和`NodeC`2个节点都已经启动。在`NodaA`上面运行以下命令，把公钥拷贝到`NodeB`和`NodeC`。
```
ssh-copy-id -i ~/.ssh/id_rsa.pub nodeb+你学号后3位 -f
ssh-copy-id -i ~/.ssh/id_rsa.pub nodec+你学号后3位 -f
```
- 系统询问是否连接，输入yes
```
Are you sure you want to continue connecting (yes/no)? yes
```
- 输入 hadoop 登录密码
```
hadoop@nodeb你学号后3位's password:
```

14. 使用以下方法测试免密登录是否配置成功。
- 在 NodeA 执行以下命令，使用 SSH 协议登录 NodeB。
```
ssh hadoop@nodeb+你的学号后3位
```
- 如果能够成功登录 NodeB 节点，而且不需要输入密码，则表示免密登录成功。输入以下命令退出登录。
```
exit
```

### 修改 Hadoop 配置文件

<div class="warning">注意此阶段命令如无特殊说明，均在 NodeA 的 hadoop 用户下执行！</div>

15. 备份和编辑 Hadoop 的 core-site.xml 配置文件。在configuration 标签内添加配置，注意替换为你的学号后3位。
```
cp /opt/hadoop/etc/hadoop/core-site.xml{,.bak}
vim /opt/hadoop/etc/hadoop/core-site.xml
```
```
<configuration>
  <!-- HDFS 访问地址 -->
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://nodea+你学号后3位:8020</value>
  </property>
  <property>
    <name>hadoop.tmp.dir</name>
    <value>/opt/hadoop/tmp</value>
  </property>
  <property>
    <name>fs.trash.interval</name>
    <value>1440</value>
  </property>
  <property>
    <name>hadoop.http.staticuser.user</name>
    <value>hadoop</value>
  </property>
</configuration>
```

16. 备份和编辑 Hadoop 的 hdfs-site.xml 配置文件。请注意替换为你的学号。
```
cp /opt/hadoop/etc/hadoop/hdfs-site.xml{,.bak}
vim /opt/hadoop/etc/hadoop/hdfs-site.xml
```
```
<configuration>
  <!-- secondary namenode 访问地址-->
  <property>
    <name>dfs.secondary.http.address</name>
    <value>nodea+你学号后3位:50090</value>
  </property>
  <!-- HDFS 副本数量 -->
  <property>
    <name>dfs.replication</name>
    <value>2</value>
  </property>
</configuration>
```

17. 新建一个 masters 配置文件，写入 Secondary NameNode 的主机名。
```
vim /opt/hadoop/etc/hadoop/masters
```
写入以下内容，注意替换为你的学号后3位。
```
nodea+你的学号后3位
```

18. 备份和编辑 Hadoop 的 mapred-site.xml 配置文件。注意替换为你的学号后3位。
```
cp /opt/hadoop/etc/hadoop/mapred-site.xml{,.bak}
vim /opt/hadoop/etc/hadoop/mapred-site.xml
```
```
<configuration>
  <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
  </property>
  <property>
    <name>mapreduce.jobhistory.address</name>
    <value>nodea+你学号后3位:10020</value>
    <description>Host and port for Job History Server (default 0.0.0.0:10020)</description>
  </property>
  <property> 
      <name>mapreduce.application.classpath</name>
      <value>$HADOOP_HOME/share/hadoop/mapreduce/*,$HADOOP_HOME/share/hadoop/mapreduce/lib/*,$HADOOP_HOME/share/hadoop/common/*,$HADOOP_HOME/share/hadoop/common/lib/*,$HADOOP_HOME/share/hadoop/yarn/*,$HADOOP_HOME/share/hadoop/yarn/lib/*,$HADOOP_HOME/share/hadoop/hdfs/*,$HADOOP_HOME/share/hadoop/hdfs/lib/*</value>
  </property>
</configuration>
```

19. 备份和编辑 Hadoop 的 yarn-site.xml 配置文件。注意替换为你的学号后3位。
```
cp /opt/hadoop/etc/hadoop/yarn-site.xml{,.bak}
vim /opt/hadoop/etc/hadoop/yarn-site.xml
```
```
<configuration>
  <property>
    <name>yarn.resourcemanager.hostname</name>
    <value>nodea+你学号后3位</value>
  </property>
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
  </property>
</configuration>
```

20. 编辑 workers ，清除原来的所有内容，增加配置 DataNode 节点信息。注意替换为你的学号后3位。
```
vim /opt/hadoop/etc/hadoop/workers
```
```
nodeb+你学号后3位
nodec+你学号后3位
```

> 从Hadoop 3.0 开始，slaves 已经启用，改用 workers 来进行替代配置数据节点信息。

21. 修改 hadoop-env.sh，在第1行加入以下代码。
```
vim /opt/hadoop/etc/hadoop/hadoop-env.sh
```
```
export JAVA_HOME=/opt/jdk8
```

22. 把`NodeA`节点的 Hadoop /opt/hadoop/etc/hadoop 下所有配置文件发送到`NodeB`和`NodeC`。如果上面的配置文件有修改，也需要同步发送到`NodeB`和`NodeC`节点。
```
cd /opt/hadoop/etc/
scp -r hadoop hadoop@nodeb+你学号后3位:/opt/hadoop/etc/
scp -r hadoop hadoop@nodec+你学号后3位:/opt/hadoop/etc/
```

23. 格式化 HDFS。
<div class="warning">注意此命令请勿重复执行，因为会导致 DataNode 和 NameNode 的集群ID不一致，造成HDFS出错。</div>

```
hdfs namenode -format
```

- 在输出的内容中，如果能看到以下这句信息，说明格式化成功。

```
2022-01-24 14:32:54,209 INFO common.Storage: Storage directory /opt/hadoop/tmp/dfs/name has been successfully formatted.
```

24. 创建 Hadoop 启动脚本，注意替换为你的学号后3位。
```
vim /opt/hadoop/sbin/start-hdp.sh
```
```
#!/usr/bin/env bash
echo "Start Hadoop by 你的学号后3位"
start-dfs.sh
start-yarn.sh
mapred --daemon start historyserver
```
25. 创建 Hadoop 停止脚本，注意替换为你的学号后3位。
```
vim /opt/hadoop/sbin/stop-hdp.sh
```
```
#!/usr/bin/env bash
echo "Stop Hadoop by 你的学号后3位"
mapred --daemon stop historyserver
stop-yarn.sh
stop-dfs.sh
```
26. 创建 Hadoop 重启脚本，注意替换为你的学号后3位。
```
vim /opt/hadoop/sbin/restart-hdp.sh
```
```
#!/usr/bin/env bash
stop-hdp.sh
start-hdp.sh
```

27. 修改创建的脚本的权限。
```
cd /opt/hadoop/sbin/
chmod 744 start-hdp.sh stop-hdp.sh restart-hdp.sh
```

28. 使用脚本启动 Hadoop。
```
start-hdp.sh
```

### 验证免密登录

29. 在`NodeB`和`NodeC`2个节点分别执行以下命令，查看是否包含来自`NodeA`的公钥。
```
cat  authorized_keys
```

### 验证 Hadoop 是否正常启动

30. 在`NodeA`输入`jps`命令，观察是否有以下进程。
```
NameNode
Jps
ResourceManager
SecondaryNameNode
JobHistoryServer
```

31. 在`NodeA`输入以下命令查看机架拓扑是否有`NodeB`和`NodeC`的信息
```
hdfs dfsadmin -printTopology
```
- 正常应该有类似以下信息返回：
```
Rack: /default-rack
   10.0.0.72:9866 (nodeb你的学号后3位)
   10.0.0.73:9866 (nodec你的学号后3位)
```

32. 在`NodeB`和`NodeC`分别输入`jps`命令，观察是否有以下进程。
```
DataNode
NodeManager
Jps
```


### 验证 HDFS 是否正常工作

33. 打开宿主机浏览器，访问 HDFS Web界面 <a href="http://10.0.0.71:9870/" target="_blank">http://10.0.0.71:9870/</a>

34. 查看 NameNode 是否 Active
![](/static/img/hadoop-d02/Snipaste_2022-01-24_15-24-52.png)

35. 查看2个节点 DataNode 服务状态是否正常。
![](/static/img/hadoop-d02/Snipaste_2022-01-24_15-25-55.png)

36. 上传`countryroad.txt`到`NodeA`的`/home/hadoop`

37. 把`countryroad.txt`从 CentOS 文件系统上传到 HDFS 文件系统。
```
hdfs dfs -mkdir /part2
hdfs dfs -put /home/hadoop/countryroad.txt /part2
hdfs dfs -ls /part2
```

### 验证 MapReduce 是否正常工作

38. 运行 Hadoop 自带的 Wordcount 程序，观察输出的内容。
```
cd $HADOOP_HOME/share/hadoop/mapreduce
hadoop jar hadoop-mapreduce-examples-3.3.1.jar wordcount /part2/countryroad.txt /output
```
- 如果输出的日志内容包含类似以下信息，则表示执行成功
```
2022-01-24 15:48:51,712 INFO mapreduce.Job: Job job_xxxxxxx completed successfully
```

39. 程序执行过程中，可以访问 Yarn Web 界面查看任务进展。<a href="http://10.0.0.71:8088/cluster/apps" target="_blank">http://10.0.0.71:8088/cluster/apps</a>

![](/static/img/hadoop-d02/Snipaste_2021-03-19_23-41-58.png)

40. 等待程序运行完毕，观察输出的内容
```
hdfs dfs -cat /output/part-r-00000
```
