<!doctype html><html lang=zh><meta charset=utf-8><meta name=viewport content="width=device-width"><title>Hadoop Part 6 - 编写 MapReduce 程序 | 《Hadoop集群部署与开发》课程资源汇总 | Heis</title><meta name=generator content="Hugo Eureka 0.8.4"><link rel=stylesheet href=/css/eureka.min.css><script defer src=/js/eureka.min.js></script><script src=/static/js/jquery-3.6.0.min.js></script><script src=/static/js/heis.js></script><link rel=stylesheet href=/static/css/heis.css media=all onload="this.media='all';this.onload=null" crossorigin><link rel=stylesheet href=/static/css/print.css media=print crossorigin><link rel=stylesheet href=/static/css/highlight-css/solarized-light.min.css media=print onload="this.media='all';this.onload=null" crossorigin><script defer src=/static/js/highlight.min.js crossorigin></script><script defer src=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14.0/js/all.min.js integrity="sha256-uNYoXefWRqv+PsIF/OflNmwtKM4lStn9yrz2gVl6ymo=" crossorigin></script><script defer src=/static/js/highlightjs-line-numbers.min.js></script><link rel=icon type=image/png sizes=32x32 href=/images/icon_huddfe7d1590fd89155f46b33625956ea5_4357_32x32_fill_box_center_2.png><link rel=apple-touch-icon sizes=180x180 href=/images/icon_huddfe7d1590fd89155f46b33625956ea5_4357_180x180_fill_box_center_2.png><meta name=description content="Hadoop Part 6 - 编写 MapReduce 程序"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"课程文档","item":"/docs/"},{"@type":"ListItem","position":2,"name":"《Hadoop集群部署与开发》课程资源汇总","item":"/docs/hadoop-d/"},{"@type":"ListItem","position":3,"name":"Hadoop Part 6  - 编写 MapReduce 程序","item":"/docs/hadoop-d/hadoop-d06/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"/docs/hadoop-d/hadoop-d06/"},"headline":"Hadoop Part 6  - 编写 MapReduce 程序 | 《Hadoop集群部署与开发》课程资源汇总 | Heis","datePublished":"2021-04-11T23:20:00+08:00","dateModified":"2021-04-11T23:20:00+08:00","wordCount":2264,"author":{"@type":"Person","name":"heis"},"publisher":{"@type":"Person","name":"C. Wang","logo":{"@type":"ImageObject","url":"/images/icon.png"}},"description":"Hadoop Part 6 - 编写 MapReduce 程序"}</script><meta property="og:title" content="Hadoop Part 6  - 编写 MapReduce 程序 | 《Hadoop集群部署与开发》课程资源汇总 | Heis"><meta property="og:type" content="article"><meta property="og:image" content="/images/icon.png"><meta property="og:url" content="/docs/hadoop-d/hadoop-d06/"><meta property="og:description" content="Hadoop Part 6 - 编写 MapReduce 程序"><meta property="og:locale" content="zh"><meta property="og:site_name" content="Heis"><meta property="article:published_time" content="2021-04-11T23:20:00+08:00"><meta property="article:modified_time" content="2021-04-11T23:20:00+08:00"><meta property="article:section" content="docs"><meta property="article:tag" content="hadoop"><meta property="article:tag" content="大数据"><meta property="article:tag" content="课程"><meta property="og:see_also" content="/docs/hadoop-d/hadoop-d05/"><meta property="og:see_also" content="/docs/hadoop-d/hadoop-d04/"><meta property="og:see_also" content="/docs/hadoop-d/hadoop-d03/"><meta property="og:see_also" content="/docs/hadoop-d/hadoop-d02/"><meta property="og:see_also" content="/docs/bi-exp/bi-training2/"><meta property="og:see_also" content="/docs/bi-exp/bi-training1-rs/"><script>var _hmt=_hmt||[];(function(){var hm=document.createElement("script");hm.src="https://hm.baidu.com/hm.js?f58b6a2675cf52000232edb4d109eccc";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();</script><body class="flex flex-col min-h-screen"><header id=headerctn class="fixed flex items-center w-full pl-scrollbar z-50 bg-secondary-bg shadow-sm"><div class="w-full max-w-screen-xl mx-auto"><script>let storageColorScheme=localStorage.getItem("lightDarkMode")
if(((storageColorScheme=='Auto'||storageColorScheme==null)&&window.matchMedia("(prefers-color-scheme: dark)").matches)||storageColorScheme=="Dark"){document.getElementsByTagName('html')[0].classList.add('dark')}</script><nav class="flex items-center justify-between flex-wrap px-4 py-4 md:py-0"><a href=/ class="mr-6 text-primary-text text-xl font-bold">Heis</a>
<button id=navbar-btn class="md:hidden flex items-center px-3 py-2" aria-label="Open Navbar">
<i class="fas fa-bars"></i></button><div id=target class="hidden block md:flex md:flex-grow md:justify-between md:items-center w-full md:w-auto text-primary-text z-20"><div class="md:flex md:h-16 text-sm md:flex-grow pb-4 md:pb-0 border-b md:border-b-0"><a href=/posts/ class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2 border-transparent mr-4">文章</a>
<a href=/docs/ class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2 selected-menu-item mr-4">课程文档</a>
<a href=/go class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2 border-transparent mr-4">导航</a></div><div class=flex><div class="relative pt-4 md:pt-0"><div class="cursor-pointer hover:text-eureka" id=lightDarkMode><i class="fas fa-adjust"></i></div><div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-30" id=is-open></div><div class="absolute flex flex-col left-0 md:left-auto right-auto md:right-0 hidden bg-secondary-bg w-48 rounded py-2 border border-tertiary-bg cursor-pointer z-40" id=lightDarkOptions><span class="px-4 py-1 hover:text-eureka" name=Light>浅色</span>
<span class="px-4 py-1 hover:text-eureka" name=Dark>深色</span>
<span class="px-4 py-1 hover:text-eureka" name=Auto>自动</span></div></div></div></div><div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-0" id=is-open-mobile></div></nav><script>let element=document.getElementById('lightDarkMode')
if(storageColorScheme==null||storageColorScheme=='Auto'){document.addEventListener('DOMContentLoaded',()=>{window.matchMedia("(prefers-color-scheme: dark)").addEventListener('change',switchDarkMode)})}else if(storageColorScheme=="Light"){element.firstElementChild.classList.remove('fa-adjust')
element.firstElementChild.setAttribute("data-icon",'sun')
element.firstElementChild.classList.add('fa-sun')}else if(storageColorScheme=="Dark"){element.firstElementChild.classList.remove('fa-adjust')
element.firstElementChild.setAttribute("data-icon",'moon')
element.firstElementChild.classList.add('fa-moon')}
document.addEventListener('DOMContentLoaded',()=>{getcolorscheme();switchBurger();});</script></div></header><main class="flex-grow pt-16"><div class=pl-scrollbar><div class="w-full max-w-screen-xl lg:px-4 xl:px-8 mx-auto"><div class=lg:pt-12><div class="flex flex-col md:flex-row bg-secondary-bg rounded"><div class="md:w-1/4 lg:w-1/5 border-r"><div class="sticky top-16 pt-6"><div id=sidebar-title class="md:hidden mx-4 px-2 pt-4 pb-2 md:border-b text-tertiary-text md:text-primary-text"><span class=font-semibold>目录</span>
<i class="fas fa-caret-right ml-1"></i></div><div id=sidebar-toc class="hidden md:block overflow-y-auto mx-6 md:mx-0 pr-6 pt-2 md:max-h-doc-sidebar bg-primary-bg md:bg-transparent"><div class="flex flex-wrap ml-4 -mr-2 p-2 bg-secondary-bg md:bg-primary-bg rounded"><a class=hover:text-eureka href=/docs/hadoop-d/>《Hadoop集群部署与开发》课程资源汇总</a></div><ul class=pl-6><li class=py-2><div><a class=hover:text-eureka href=/docs/hadoop-d/hadoop-d01/>Hadoop Part 1 - 模板机制作</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/hadoop-d/hadoop-d02/>Hadoop Part 2 - 部署 Hadoop 完全分布模式（Fully Distributed Mode）</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/hadoop-d/hadoop-d03/>Hadoop Part 3 - 通过 Shell 命令访问 HDFS</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/hadoop-d/hadoop-d04/>Hadoop Part 4 - 搭建 Hadoop 开发环境</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/hadoop-d/hadoop-d05/>Hadoop Part 5 - HDFS Java 编程访问</a></div></li><li class=py-2><div><a class="text-eureka hover:text-eureka" href=/docs/hadoop-d/hadoop-d06/>Hadoop Part 6 - 编写 MapReduce 程序</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/hadoop-d/hadoop-d07/>Hadoop Part 7 - 部署 Hive 和 Hive 常用操作</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/hadoop-d/hadoop-d08/>Hadoop Part 8 - 部署 HBase 和 HBase 常用操作</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/hadoop-d/hadoop-d09/>Hadoop Part 9 - 部署 ZooKeeper 和 ZooKeeper 常用操作</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/hadoop-d/hadoop-d10/>Hadoop Part 10 - Flume 和 Sqoop 操作实例</a></div></li></ul></div></div></div><div class="w-full md:w-3/4 lg:w-4/5 pb-8 pt-2 md:pt-8"><div class="w-full lg:w-3/4 pl-6 ml-0 mr-auto"><h1 class="font-bold text-3xl text-primary-text">Hadoop Part 6 - 编写 MapReduce 程序</h1><div class="flex flex-wrap flex-row items-center mt-2 text-tertiary-text"><div class="mr-6 my-2"><i class="fas fa-calendar mr-1"></i><span>2021-04-11</span></div><div class="mr-6 my-2"><i class="fas fa-clock mr-1"></i><span>5分钟阅读时长</span></div><div class="mr-6 my-2"><i class="fas fa-folder mr-1"></i><a href=/categories/hadoopd/ class=hover:text-eureka>hadoopd</a></div></div></div><div class=flex><div class="w-full lg:w-3/4 px-6"><div class=content><p><a href=/hadoop-c-summary/>«返回课程汇总页面</a></p><h2 id=版本>【版本】</h2><p>当前版本号<code>v20220512</code></p><div class=tbl-start></div><table><thead><tr><th>版本</th><th>修改说明</th></tr></thead><tbody><tr><td>v20220512</td><td>修正SalesMapper的提示和实验6.2结果</td></tr><tr><td>v20210411</td><td>初始化版本</td></tr></tbody></table><div class=tbl-end style=height:10px></div><h2 id=实验61----编写-mapreduce-wordcount-程序>实验6.1 - 编写 MapReduce wordcount 程序</h2><h2 id=实验名称>【实验名称】</h2><p>实验6.1 - 编写 MapReduce wordcount 程序</p><h2 id=实验目的>【实验目的】</h2><ul><li>分析和编写 WordCount 程序</li></ul><h2 id=实验环境>【实验环境】</h2><ul><li>Windows 7 以上64位操作系统</li><li>JDK8</li><li>IDEA</li><li>Hadoop 3</li><li>Maven 3</li></ul><h2 id=实验资源>【实验资源】</h2><ul><li>countryroad.txt</li></ul><pre><code>链接：https://pan.baidu.com/s/1MoQ0iU0Qb1o8_o5JV6X6iw 
提取码：3rno
</code></pre><h2 id=实验内容>【实验内容】</h2><ul><li>编写 MapReduce wordcount 程序</li></ul><h2 id=实验步骤>【实验步骤】</h2><ol><li><p>打开 Part 4 的 hadoopexp 项目。</p></li><li><p>在项目<code>hadoop-exp\src\main\java</code>下创建一个名为<code>hadoop+你学号后4位.mapreduce.wc</code>的包。注意替换为你的学号后4位。</p></li><li><p>在包下面新建一个 <code>WordCountMapper</code> 的类。代码如下，注意替换为你的学号后4位。</p></li></ol><pre><code>package hadoop你的学号后4位.mapreduce.wc;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.IOException;

public class WordCountMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt;{
    @Override
    protected void map(LongWritable key1,Text v1,Context context)
            throws IOException,InterruptedException{
            String data=v1.toString();
            // 分词
            String[] words=data.split(&quot; &quot;);
            // 输出 k2 v2
            for(String w:words){
                context.write(new Text(w),new IntWritable(1));
            }
    }
}
</code></pre><ol start=4><li>在包下面新建一个 <code>WordCountReducer</code> 的类。代码如下，注意替换为你的学号后4位。</li></ol><pre><code>package hadoop你的学号后4位.mapreduce.wc;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;
import java.io.IOException;

public class WordCountReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
    @Override
    protected void reduce(Text k3, Iterable&lt;IntWritable&gt; v3,Context context) throws IOException, InterruptedException {
		//context 是 reduce 的上下文		
        // 对 v3 求和
		int total = 0;
		for(IntWritable v:v3){
		    total += v.get();
		}
		// 输出： k4 单词 v4 频率
		context.write(k3, new IntWritable(total));
	}
}
</code></pre><ol start=5><li>在包下面新建一个 <code>WordCountMain</code> 的类。代码如下，注意替换为你的学号后4位。</li></ol><pre><code>package hadoop你的学号后4位.mapreduce.wc;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.util.GenericOptionsParser;

import java.io.IOException;

public class WordCountMain {

    public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {
        Configuration conf = new Configuration();
        String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();
        int argLength=otherArgs.length;
        if (otherArgs.length &lt; 2) {
            System.err.println(&quot;Usage: wordcount &lt;in&gt; [&lt;in&gt;...] &lt;out&gt;&quot;);
            System.exit(2);
        }
        //获取一个作业实例，名称为Word Count
        Job job=Job.getInstance(conf,&quot;Word Count&quot;);
        //设置运行的jar包里的类
        job.setJarByClass(WordCountMain.class);
        //设置Mapper
        job.setMapperClass(WordCountMapper.class);
        //设置Reducer
        job.setReducerClass(WordCountReducer.class);
        //设置Combiner
        job.setCombinerClass(WordCountReducer.class);
        //设置k4类型
        job.setOutputKeyClass(Text.class);
        //设置v4类型
        job.setOutputValueClass(IntWritable.class);
        //可以接受多个参数作为输入文件路径
        for(int i=0;i&lt;argLength-1;i++) {
            FileInputFormat.addInputPath(job, new Path(otherArgs[i]));
        }
        //最后的一个参数是结果输出路径
        FileOutputFormat.setOutputPath(job,new Path(otherArgs[argLength-1]));
        //如果作业运行成功就成功退出
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}

</code></pre><ol start=6><li>修改项目的<code>pom.xml</code>。其中<code>&lt;mainClass></code>标签内的类修改为<code>WordCountMain</code>类的包内路径。参考代码如下，注意替换为你的学号后4位。</li></ol><pre><code>&lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.2.0&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;archive&gt;
                        &lt;!--&lt;manifestFile&gt;${project.build.outputDirectory}/META-INF/MANIFEST.MF&lt;/manifestFile&gt;--&gt;
                        &lt;manifest&gt;
                            &lt;!-- main()所在的类，注意修改 --&gt;
                            &lt;mainClass&gt;hadoop你的学号后4位.mapreduce.wc.WordCountMain&lt;/mainClass&gt;
                        &lt;/manifest&gt;
                    &lt;/archive&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
</code></pre><ol start=7><li>在 IDEA 的左下角找到 Terminal，输入以下命令，使用 Maven 对代码进行打包。
<img src=/static/img/hadoop-c06/Snipaste_2021-04-11_23-52-36.png alt></li></ol><pre><code>mvn compile package -Dmaven.test.skip=true
</code></pre><ol start=8><li><p>生成的 jar 包会在项目的 target 目录下。名称为<code>hadoop-exp-1.0.jar</code>。</p></li><li><p>把<code>hadoop-exp-1.0.jar</code>和<code>countryroad.txt</code>都上传到<code>NodeA</code>的<code>/home/hadoop</code>目录下。</p></li><li><p>在<code>NodeA</code>启动Hadoop.</p></li></ol><pre><code>start-hdp.sh
</code></pre><ol start=11><li>把<code>NodeA</code>本地的<code>countryroad.txt</code>文件上传到 HDFS 的根目录<code>/</code>。</li></ol><pre><code>hdfs dfs -put /home/hadoop/countryroad.txt /
</code></pre><ol start=12><li>在<code>NodeA</code>上执行以下命令，开始运行我们编写的 Wordcount 程序。</li></ol><pre><code>hadoop jar /home/hadoop/hadoop-exp-1.0.jar /countryroad.txt /output6
</code></pre><ol start=13><li>运行成功以后，查看结果。</li></ol><pre><code>hdfs dfs -cat /output6/part-r-00000
</code></pre><h2 id=实验62----编写-mapreduce-程序统计数据>实验6.2 - 编写 MapReduce 程序统计数据</h2><h2 id=实验目的-1>【实验目的】</h2><ul><li>掌握编写 MapReduce 程序进行统计数据</li></ul><h2 id=实验环境-1>【实验环境】</h2><ul><li>Windows 7 以上64位操作系统</li><li>JDK8</li><li>IDEA</li><li>Hadoop 3</li><li>CentOS 7</li><li>Maven 3</li></ul><h2 id=实验资源-1>【实验资源】</h2><ul><li>sales.csv</li></ul><pre><code>下载链接：https://pan.baidu.com/s/1ghde86wcK6pwg1fdSSWg0w
提取码：v3wv
</code></pre><h2 id=实验内容-1>【实验内容】</h2><ul><li>编写 MapReduce 程序进行数据统计</li></ul><h2 id=实验要求>【实验要求】</h2><ul><li><p>（1）获取<code>sales.csv</code>文件，文件内是一份销售数据，数据描述如下：
<img src=/static/img/hadoop-d06/bc9e7892-997e-4560-a709-da430b79fcce.png alt></p></li><li><p>（2）根据以上实验步骤，编写相关代码，调用MapReduce，求出各年销售总额。</p></li></ul><h2 id=实验步骤-1>【实验步骤】</h2><ol><li><p>打开 Part 4 的 hadoopexp 项目。</p></li><li><p>在项目<code>hadoop-exp\src\main\java</code>下创建一个名为<code>hadoop+你学号后4位.mapreduce.sales</code>的包。注意替换为你的学号后4位。</p></li><li><p>在包下面新建一个 <code>SalesMapper</code> 的类。下面是部分参考代码，请完成关键的编码部分，注意替换为你的学号后4位。</p></li></ol><pre><code>package hadoop你的学号后4位.mapreduce.sales;

import org.apache.hadoop.io.*;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.IOException;

public class SalesMapper extends Mapper&lt;LongWritable, Text, Text, DoubleWritable&gt;{
    @Override
    protected void map(LongWritable key1,Text v1,Context context)
            throws IOException,InterruptedException{
            String data=v1.toString();
            // 分词
            String[] words=data.split(&quot;,&quot;);
            // 输出 k2 v2
            
            此处关键代码请自己完成
    }
}
</code></pre><ol start=4><li>在包下面新建一个 <code>SalesReducer</code> 的类。代码如下，注意替换为你的学号后4位。</li></ol><pre><code>package hadoop你的学号后4位.mapreduce.sales;

import org.apache.hadoop.io.DoubleWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;
import java.io.IOException;

public class SalesReducer extends Reducer&lt;Text, DoubleWritable, Text, DoubleWritable&gt; {
    @Override
    protected void reduce(Text k3, Iterable&lt;DoubleWritable&gt; v3,Context context) throws IOException, InterruptedException {
		此处关键代码请自己完成
	}
}
</code></pre><ol start=5><li>在包下面新建一个 <code>SalesMain</code> 的类。代码如下，注意替换为你的学号后4位。</li></ol><pre><code>package hadoop你的学号后4位.mapreduce.sales;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.DoubleWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.util.GenericOptionsParser;

import java.io.IOException;

public class SalesMain {

    public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {
        Configuration conf = new Configuration();
        String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();
        int argLength=otherArgs.length;
        if (otherArgs.length &lt; 2) {
            System.err.println(&quot;Usage: xxx.jar &lt;in&gt; [&lt;in&gt;...] &lt;out&gt;&quot;);
            System.exit(2);
        }
        //获取一个作业实例
        Job job=Job.getInstance(conf,&quot;Sales Statistic&quot;);
        //设置运行的jar包里的类
        job.setJarByClass(SalesMain.class);
        //设置Mapper
        job.setMapperClass(SalesMapper.class);
        //设置Reducer
        job.setReducerClass(SalesReducer.class);
        //设置Combiner
        job.setCombinerClass(SalesReducer.class);
        //设置k4类型
        job.setOutputKeyClass(Text.class);
        //设置v4类型
        job.setOutputValueClass(DoubleWritable.class);
        //可以接受多个参数作为输入文件路径
        for(int i=0;i&lt;argLength-1;i++) {
            FileInputFormat.addInputPath(job, new Path(otherArgs[i]));
        }
        //最后的一个参数是结果输出路径
        FileOutputFormat.setOutputPath(job,new Path(otherArgs[argLength-1]));
        //如果作业运行成功就成功退出
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}
</code></pre><ol start=6><li>修改项目的<code>pom.xml</code>。其中<code>&lt;mainClass></code>标签内的类修改为<code>SalesMain</code>类的包内路径。参考代码如下，注意替换为你的学号后4位。</li></ol><pre><code>&lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.2.0&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;archive&gt;
                        &lt;!--&lt;manifestFile&gt;${project.build.outputDirectory}/META-INF/MANIFEST.MF&lt;/manifestFile&gt;--&gt;
                        &lt;manifest&gt;
                            &lt;!-- main()所在的类，注意修改 --&gt;
                            &lt;mainClass&gt;hadoop你的学号后4位.mapreduce.sales.SalesMain&lt;/mainClass&gt;
                        &lt;/manifest&gt;
                    &lt;/archive&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
</code></pre><ol start=7><li>参考实验6.1 打包、上传包、运行和查看结果的步骤。参考结果如下：</li></ol><pre><code>1998    2.408391494998411E7
1999    2.221994766001435E7
2000    2.37655066200018E7
2001    2.8136461979984347E7
</code></pre></div><div class=my-4><a href=/tags/hadoop/ class="inline-block bg-tertiary-bg text-sm rounded px-3 py-1 my-1 mr-2 hover:text-eureka">#hadoop</a>
<a href=/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/ class="inline-block bg-tertiary-bg text-sm rounded px-3 py-1 my-1 mr-2 hover:text-eureka">#大数据</a>
<a href=/tags/%E8%AF%BE%E7%A8%8B/ class="inline-block bg-tertiary-bg text-sm rounded px-3 py-1 my-1 mr-2 hover:text-eureka">#课程</a></div><div class=py-2><div class="flex flex-col md:flex-row items-center my-8"><a href=/authors/heis/ class="w-24 h-24 md:mr-4"><img src=/static/img/authors/heis.png class="w-full bg-primary-bg rounded-full" alt=Avatar></a><div class="w-full md:w-auto mt-4 md:mt-0"><a href=/authors/heis/ class="block font-bold text-lg pb-1 mb-2 border-b">黄老师</a>
<span class="block pb-2"></span><a href=mailto:heishuangzy@qq.com class=mr-1><i class="fas fa-envelope"></i></a><a href=https://gitee.com/heis/ class=mr-1><i class="fab fa-git"></i></a><a href=http://heis.gitee.io/ class=mr-1><i class="fas fa-blog"></i></a></div></div></div><div class="flex flex-col md:flex-row md:justify-between -mx-2 mt-4 px-2 pt-4 border-t"><div id=presec><span class="block font-bold">上一页</span>
<a href=/docs/hadoop-d/hadoop-d05/ class=block>Hadoop Part 5 - HDFS Java 编程访问</a></div><div id=nextsec class="md:text-right mt-4 md:mt-0"><span class="block font-bold">下一页</span>
<a href=/docs/hadoop-d/hadoop-d07/ class=block>Hadoop Part 7 - 部署 Hive 和 Hive 常用操作</a></div></div></div><div class="hidden lg:block lg:w-1/4"><div class="sticky top-16 z-10 hidden lg:block px-6 py-4 bg-secondary-bg pt-16 -mt-16"><span class="text-lg font-semibold">本页内容</span></div><div class="sticky-toc hidden lg:block px-6 pb-6 pt-10 -mt-10 border-l"><nav id=TableOfContents><ul><li><a href=#版本>【版本】</a></li><li><a href=#实验61----编写-mapreduce-wordcount-程序>实验6.1 - 编写 MapReduce wordcount 程序</a></li><li><a href=#实验名称>【实验名称】</a></li><li><a href=#实验目的>【实验目的】</a></li><li><a href=#实验环境>【实验环境】</a></li><li><a href=#实验资源>【实验资源】</a></li><li><a href=#实验内容>【实验内容】</a></li><li><a href=#实验步骤>【实验步骤】</a></li><li><a href=#实验62----编写-mapreduce-程序统计数据>实验6.2 - 编写 MapReduce 程序统计数据</a></li><li><a href=#实验目的-1>【实验目的】</a></li><li><a href=#实验环境-1>【实验环境】</a></li><li><a href=#实验资源-1>【实验资源】</a></li><li><a href=#实验内容-1>【实验内容】</a></li><li><a href=#实验要求>【实验要求】</a></li><li><a href=#实验步骤-1>【实验步骤】</a></li></ul></nav></div><script>window.addEventListener('DOMContentLoaded',()=>{enableStickyToc();});</script></div></div></div></div></div><div id=outerdiv><div id=innerdiv><img id=bigimg src></div></div><script>document.addEventListener('DOMContentLoaded',()=>{hljs.highlightAll();hljs.initLineNumbersOnLoad({singleLine:true});changeSidebarHeight();switchDocToc();$("img").css("cursor:pointer")
$("img").click(function(){var _this=$(this);imgShow("#outerdiv","#innerdiv","#bigimg",_this);});$("ol").each(function(index){if(/\d{1,4}/.test($(this).attr("start"))){let idx=parseInt($(this).attr("start"));let lis=$(this).find("li");if(lis.length>0){lis.each(function(index){$(this).attr("id","step"+(idx+index));});}else{$(this).attr("id","step"+idx);}}});});</script><script src=/static/js/clipboard.min.js></script><script src=/static/js/codecopy.bundle.js?215></script></div></div></main><footer class=pl-scrollbar><div class="w-full max-w-screen-xl mx-auto"><div class="text-center p-6 pin-b"><p class="text-sm text-tertiary-text">&copy; 2021 <a href=https://www.wangchucheng.com/>C. Wang</a> and <a href=https://www.ruiqima.com/>R. Ma</a>
&#183; Powered by the <a href=https://github.com/wangchucheng/hugo-eureka class=hover:text-eureka>Eureka</a> theme for <a href=https://gohugo.io class=hover:text-eureka>Hugo</a></p></div></div></footer></body></html>