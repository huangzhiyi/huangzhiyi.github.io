<!doctype html><html lang=zh><meta charset=utf-8><meta name=viewport content="width=device-width"><title>第六章 Spark Streaming 实验手册 | Spark 课程 | Heis</title><meta name=generator content="Hugo Eureka 0.8.4"><link rel=stylesheet href=/css/eureka.css><script defer src=/js/eureka.min.js></script><script src=/static/js/jquery-3.6.0.min.js></script><script src=/static/js/heis.js></script><link rel=stylesheet href=/static/css/heis.css media=all onload="this.media='all';this.onload=null" crossorigin><link rel=stylesheet href=/static/css/print.css media=print crossorigin><link rel=stylesheet href=/static/css/highlight-css/solarized-light.min.css media=print onload="this.media='all';this.onload=null" crossorigin><script defer src=/static/js/highlight.min.js crossorigin></script><script defer src=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14.0/js/all.min.js integrity="sha256-uNYoXefWRqv+PsIF/OflNmwtKM4lStn9yrz2gVl6ymo=" crossorigin></script><script defer src=/static/js/highlightjs-line-numbers.min.js></script><link rel=icon type=image/png sizes=32x32 href=/images/icon_huddfe7d1590fd89155f46b33625956ea5_4357_32x32_fill_box_center_2.png><link rel=apple-touch-icon sizes=180x180 href=/images/icon_huddfe7d1590fd89155f46b33625956ea5_4357_180x180_fill_box_center_2.png><meta name=description content="Spark 第六章 Spark Streaming 实验手册"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"课程文档","item":"/docs/"},{"@type":"ListItem","position":2,"name":"Spark 课程","item":"/docs/spark-exp/"},{"@type":"ListItem","position":3,"name":"第六章 Spark Streaming 实验手册","item":"/docs/spark-exp/spark-exp06/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"/docs/spark-exp/spark-exp06/"},"headline":"第六章 Spark Streaming 实验手册 | Spark 课程 | Heis","datePublished":"2020-04-19T10:42:51+08:00","dateModified":"2020-04-19T10:42:51+08:00","wordCount":2261,"author":{"@type":"Person","name":"heis"},"publisher":{"@type":"Person","name":"C. Wang","logo":{"@type":"ImageObject","url":"/images/icon.png"}},"description":"Spark 第六章 Spark Streaming 实验手册"}</script><meta property="og:title" content="第六章 Spark Streaming 实验手册 | Spark 课程 | Heis"><meta property="og:type" content="article"><meta property="og:image" content="/images/icon.png"><meta property="og:url" content="/docs/spark-exp/spark-exp06/"><meta property="og:description" content="Spark 第六章 Spark Streaming 实验手册"><meta property="og:locale" content="zh"><meta property="og:site_name" content="Heis"><meta property="article:published_time" content="2020-04-19T10:42:51+08:00"><meta property="article:modified_time" content="2020-04-19T10:42:51+08:00"><meta property="article:section" content="docs"><meta property="article:tag" content="spark"><meta property="article:tag" content="Streaming"><meta property="og:see_also" content="/docs/spark-exp/spark-training1/"><meta property="og:see_also" content="/docs/spark-exp/spark-exp03/"><meta property="og:see_also" content="/docs/spark-exp/spark-exp05/"><meta property="og:see_also" content="/docs/spark-exp/spark-exp04/"><meta property="og:see_also" content="/docs/spark-exp/spark-exp02/"><script>var _hmt=_hmt||[];(function(){var hm=document.createElement("script");hm.src="https://hm.baidu.com/hm.js?f58b6a2675cf52000232edb4d109eccc";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();</script><body class="flex flex-col min-h-screen"><header id=headerctn class="fixed flex items-center w-full pl-scrollbar z-50 bg-secondary-bg shadow-sm"><div class="w-full max-w-screen-xl mx-auto"><script>let storageColorScheme=localStorage.getItem("lightDarkMode")
if(((storageColorScheme=='Auto'||storageColorScheme==null)&&window.matchMedia("(prefers-color-scheme: dark)").matches)||storageColorScheme=="Dark"){document.getElementsByTagName('html')[0].classList.add('dark')}</script><nav class="flex items-center justify-between flex-wrap px-4 py-4 md:py-0"><a href=/ class="mr-6 text-primary-text text-xl font-bold">Heis</a>
<button id=navbar-btn class="md:hidden flex items-center px-3 py-2" aria-label="Open Navbar">
<i class="fas fa-bars"></i></button><div id=target class="hidden block md:flex md:flex-grow md:justify-between md:items-center w-full md:w-auto text-primary-text z-20"><div class="md:flex md:h-16 text-sm md:flex-grow pb-4 md:pb-0 border-b md:border-b-0"><a href=/posts/ class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2 border-transparent mr-4">文章</a>
<a href=/docs/ class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2 selected-menu-item mr-4">课程文档</a>
<a href=/go class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2 border-transparent mr-4">导航</a></div><div class=flex><div class="relative pt-4 md:pt-0"><div class="cursor-pointer hover:text-eureka" id=lightDarkMode><i class="fas fa-adjust"></i></div><div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-30" id=is-open></div><div class="absolute flex flex-col left-0 md:left-auto right-auto md:right-0 hidden bg-secondary-bg w-48 rounded py-2 border border-tertiary-bg cursor-pointer z-40" id=lightDarkOptions><span class="px-4 py-1 hover:text-eureka" name=Light>浅色</span>
<span class="px-4 py-1 hover:text-eureka" name=Dark>深色</span>
<span class="px-4 py-1 hover:text-eureka" name=Auto>自动</span></div></div></div></div><div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-0" id=is-open-mobile></div></nav><script>let element=document.getElementById('lightDarkMode')
if(storageColorScheme==null||storageColorScheme=='Auto'){document.addEventListener('DOMContentLoaded',()=>{window.matchMedia("(prefers-color-scheme: dark)").addEventListener('change',switchDarkMode)})}else if(storageColorScheme=="Light"){element.firstElementChild.classList.remove('fa-adjust')
element.firstElementChild.setAttribute("data-icon",'sun')
element.firstElementChild.classList.add('fa-sun')}else if(storageColorScheme=="Dark"){element.firstElementChild.classList.remove('fa-adjust')
element.firstElementChild.setAttribute("data-icon",'moon')
element.firstElementChild.classList.add('fa-moon')}
document.addEventListener('DOMContentLoaded',()=>{getcolorscheme();switchBurger();});</script></div></header><main class="flex-grow pt-16"><div class=pl-scrollbar><div class="w-full max-w-screen-xl lg:px-4 xl:px-8 mx-auto"><div class=lg:pt-12><div class="flex flex-col md:flex-row bg-secondary-bg rounded"><div class="md:w-1/4 lg:w-1/5 border-r"><div class="sticky top-16 pt-6"><div id=sidebar-title class="md:hidden mx-4 px-2 pt-4 pb-2 md:border-b text-tertiary-text md:text-primary-text"><span class=font-semibold>目录</span>
<i class="fas fa-caret-right ml-1"></i></div><div id=sidebar-toc class="hidden md:block overflow-y-auto mx-6 md:mx-0 pr-6 pt-2 md:max-h-doc-sidebar bg-primary-bg md:bg-transparent"><div class="flex flex-wrap ml-4 -mr-2 p-2 bg-secondary-bg md:bg-primary-bg rounded"><a class=hover:text-eureka href=/docs/spark-exp/>Spark 课程</a></div><ul class=pl-6><li class=py-2><div><a class=hover:text-eureka href=/docs/spark-exp/spark-exp02/>第二章 搭建 Spark 实验手册</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/spark-exp/spark-exp03/>第三章 使用 Python 开发 Spark 应用实验手册</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/spark-exp/spark-exp04/>第四章 Spark RDD 实验手册</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/spark-exp/spark-exp05/>第五章 SparkSQL 实验手册</a></div></li><li class=py-2><div><a class="text-eureka hover:text-eureka" href=/docs/spark-exp/spark-exp06/>第六章 Spark Streaming 实验手册</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/spark-exp/spark-exp07/>第七章 Spark 机器学习库实验手册</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/spark-exp/spark-exp08/>Spark 第八章 GraphFrames 图计算实验手册</a></div></li><li class=py-2><div><a class=hover:text-eureka href=/docs/spark-exp/spark-training1/>Spark 综合实验1</a></div></li></ul></div></div></div><div class="w-full md:w-3/4 lg:w-4/5 pb-8 pt-2 md:pt-8"><div class="w-full lg:w-3/4 pl-6 ml-0 mr-auto"><h1 class="font-bold text-3xl text-primary-text">第六章 Spark Streaming 实验手册</h1><div class="flex flex-wrap flex-row items-center mt-2 text-tertiary-text"><div class="mr-6 my-2"><i class="fas fa-calendar mr-1"></i><span>2020-04-19</span></div><div class="mr-6 my-2"><i class="fas fa-clock mr-1"></i><span>5分钟阅读时长</span></div><div class="mr-6 my-2"><i class="fas fa-folder mr-1"></i><a href=/categories/spark/ class=hover:text-eureka>spark</a></div></div></div><div class=flex><div class="w-full lg:w-3/4 px-6"><div class=content><h2 id=版本>【版本】</h2><p>当前版本号<code>v20200424</code></p><div class=tbl-start></div><table><thead><tr><th>版本</th><th>修改说明</th></tr></thead><tbody><tr><td>v20200424</td><td>新增修改日志级别的步骤</td></tr><tr><td>v20200419</td><td>初始化版本</td></tr></tbody></table><div class=tbl-end style=height:10px></div><h2 id=实验61-运行网络版的wordcount>实验6.1 ：运行网络版的WordCount</h2><h2 id=实验名称-实验61-运行网络版的wordcount>【实验名称】 实验6.1 ：运行网络版的WordCount</h2><h3 id=实验目的>【实验目的】</h3><ul><li>了解NetCat工具的使用。</li><li>初步了解Streaming运行的方式。</li></ul><h3 id=实验原理>【实验原理】</h3><p>运行Spark自带的StreamingWordCount程序，</p><h3 id=实验环境>【实验环境】</h3><ul><li>操作系统：Ubuntu 16.04 （确保机器cpu核数大于接收器的数量，或Local模式线程数大于接收器数量）</li><li>Spark：Spark2.x</li><li>Pyspark</li></ul><h3 id=实验步骤>【实验步骤】</h3><p>一、基于netcat的聊天室</p><ol><li>启动 NetCat 服务端，并在1234端口监听</li></ol><pre><code>nc -lk  1234
</code></pre><ol start=2><li>使用xshell 打开一个新的选项卡，连接虚拟机。启动NetCat客户端，并连接Netcat服务端</li></ol><pre><code>nc localhost  1234
</code></pre><blockquote><p>注意：如果客户端和服务端不在同一台机器，localhost 可以换成实际IP。</p></blockquote><ol start=3><li>在服务端输入以下字符串，并按回车，可以在客户端收到消息，并打印出来。这里注意替换学号为你个人学号。</li></ol><pre><code>hello 你的学号
</code></pre><ol start=4><li>在客户端输入字符串，并按回车，可以在服务端收到消息，并打印出来。这里注意替换学号为你个人学号。</li></ol><pre><code>你好  你的学号
</code></pre><ol start=5><li><p>在 NetCat 客户端的选项卡使用<code>ctrl+c</code>终止客户端进程。</p></li><li><p>修改<code>$SPARK_HOME/conf</code>下的 log4j.properties 下的日志级别，把<code>INFO</code>修改为<code>WARN</code>。这一步主要是为了提升日志级别，减少 WARN 级别以下例如 INFO,DEBUG 级别的日志输出，对结果造成干扰。</p></li></ol><pre><code>#修改这一句
log4j.rootCategory=INFO, console

#修改为
log4j.rootCategory=WARN, console
</code></pre><ol start=7><li>启动 Spark NetworkWordCount 例子和服务端建立连接，并统计单词数量。</li></ol><pre><code>cd $SPARK_HOME
bin/run-example streaming.NetworkWordCount localhost 1234
</code></pre><ol start=8><li>在 NetCat 服务端输入以下字符串，并按回车，观察Streaming WordCount的输出，并截图。这里注意替换学号为你个人学号。</li></ol><pre><code>You jump I jump 你的学号
</code></pre><h2 id=实验62-开发自己的streamingwordcount且支持统计历史数据>实验6.2 ：开发自己的StreamingWordCount，且支持统计历史数据</h2><h2 id=实验名称-实验62-开发自己的streamingwordcount且支持统计历史数据>【实验名称】 实验6.2 ：开发自己的StreamingWordCount，且支持统计历史数据</h2><h3 id=实验目的-1>【实验目的】</h3><ul><li>了解NetCat工具的使用。</li><li>掌握 Spark Streaming 的开发流程。</li></ul><h3 id=实验原理-1>【实验原理】</h3><p>开发自己的StreamingWordCount 程序，用于统计所有流数据的单词数量。</p><h3 id=实验环境-1>【实验环境】</h3><ul><li>操作系统：Ubuntu 16.04 （确保机器cpu核数大于接收器的数量，或Local模式线程数大于接收器数量）</li><li>Spark：Spark2.x</li><li>Pyspark</li></ul><h3 id=实验要求>【实验要求】</h3><ol><li>开发一个 Spark Streaming WordCount 程序，满足以下要求</li></ol><ul><li>（1）自己编写一个 Spark Streaming 的 WordCount 程序，保存为<code>StreamingWordCount123.py</code>。（请替换123为你学号后3位）</li><li>（2）程序需要使用到 transform() 和 updateStateByKey() 算子。</li><li>（3）程序需要对NetCat 服务端发送历史的单词出现的数量一起累计。</li><li>（4）使用 <code>spark-submit</code> 运行你的程序。</li></ul><ol start=2><li>启动 NetCat 服务端，并在1234端口监听。</li></ol><pre><code>nc -lk  1234
</code></pre><ol start=3><li>使用 NetCat 服务端分别发送以下内容。这里注意替换学号为你个人学号。</li></ol><pre><code>Knock 你的学号
</code></pre><pre><code>Knock Knock 你的学号
</code></pre><pre><code>Knock Knock  Knock 你的学号
</code></pre><h2 id=实验63流式日志过滤与分析>实验6.3：流式日志过滤与分析</h2><h2 id=实验名称-实验63流式日志过滤与分析>【实验名称】 实验6.3：流式日志过滤与分析</h2><h3 id=实验目的-2>【实验目的】</h3><p>掌握Spark Steaming的应用</p><h3 id=实验原理-2>【实验原理】</h3><h3 id=实验环境-2>【实验环境】</h3><ul><li>操作系统：Ubuntu 16.04</li><li>Spark：Spark2.x</li><li>Pyspark</li></ul><h3 id=实验资源>【实验资源】</h3><p>请从以下链接下载日志文件。该日志包含<code>日志级别</code>、<code>函数名</code>、<code>日志内容</code>三个字段，字段之间以"\t"拆分。</p><pre><code>https://pan.baidu.com/s/1Vh1w-70x_MpkV_Ycu_54PA#提取码38zq
</code></pre><h3 id=实验步骤-1>【实验步骤】</h3><ol><li><p>启动 HDFS，创建 HDFS 目录<code>/sst-123</code>。请替换123为你的学号后3位。</p></li><li><p>使用 MySQL 的 root 用户创建数据库 spark。并创建表<code>log123</code>。请替换123为你的学号后3位。</p></li></ol><pre><code>用户名：root
密码：Mysql0668
</code></pre><pre><code>create table `log123`(
lvl varchar(15) comment '等级',
method varchar(50) comment '方法',
content varchar(200) comment '内容'
);
</code></pre><ol start=3><li>为了让程序可以调用 MySQL 的JDBC驱动，把驱动文件放入<code>$SPARK_HOME/jars</code>。</li></ol><pre><code>cp /opt/hive/lib/mysql-connector-java-5.1.48.jar $SPARK_HOME/jars/
</code></pre><ol start=4><li>如果配置了Jupytor Notebook，要把这2个环境变量注释掉，并重启虚拟机。</li></ol><pre><code>#export PYSPARK_DRIVER_PYTHON=jupyter
#export PYSPARK_DRIVER_PYTHON_OPTS='notebook --ip=*'
</code></pre><ol start=5><li><p>启动 Spark Standalone 模式。</p></li><li><p>编写程序Log2DB.py，完成以下要求。</p></li></ol><ul><li>（1）采用StreamingContext.textFileStream()算子监听<code>hdfs://node0:8020/sst-123</code>目录。</li><li>（2）把 DStream 转换为 RDD。</li><li>（3）读入日志信息流，将 RDD 转为 DataFrame。</li><li>（4）DataFrame 注册为临时表。</li><li>（5）使用 SQL 过滤出级别为 error 或 warn 的日志。</li><li>（6）将过滤后的数据保存到 MySQL 的 spark.log123表（请替换123为你的学号后3位）。</li></ul><p>提示代码(注意修改为你的学号后3位)：</p><pre><code>from pyspark.streaming import StreamingContext  
from pyspark import SparkContext
from pyspark.sql import SparkSession

sc =SparkContext('spark://node0:7077','ss-123')
spark =SparkSession(sc)
ssc = StreamingContext(sc, 1)
ds1 = ssc.textFileStream(&lt;补充代码&gt;)
def save2DB(fileRDD):
    &lt;补充代码&gt;
    df2.write.jdbc('jdbc:mysql://localhost:3306/spark?useSSL=false&amp;user=root&amp;password=Mysql0668',table='log123',mode='append',properties={'driver':'com.mysql.jdbc.Driver'})

ds1.foreachRDD(lambda fileRDD:save2DB(fileRDD))
ssc.start();ssc.awaitTermination()
</code></pre><ol start=7><li>使用 spark-submit 运行Log2DB.py。</li></ol><pre><code>spark-submit --master spark://node0:7077 ./Log2DB.py
</code></pre><ol start=8><li><p>把2个日志文件依次上传<code>hdfs://node0:8020/sst-123</code>目录下。</p></li><li><p>观察 MySQL 的spark.log123表记录是否有更新。</p></li></ol><h2 id=常见问题解答faq>【常见问题解答FAQ】</h2><h3 id=问题1上传文件到-hdfs-遇到orgapachehadoopmapreducelibinputinvalidinputexceptioninput-path-does-not-exist-hdfsnode08020xxxtxtcopying之类的问题>问题1：上传文件到 HDFS 遇到<code>org.apache.hadoop.mapreduce.lib.input.InvalidInputException:Input path does not exist: hdfs://node0:8020/xxx.txt.COPYING</code>之类的问题</h3><p>答：可以先把文件上传到 Spark Streaming 非监听目录，例如 HDFS 根目录。再使用<code>hdfs dfs -mv</code>命令，把该文件移动到监听目录。因为直接上传文件会在 HDFS 上生成一个临时文件，后缀是.COPYING，Spark Streaming 程序监听到该临时文件时，文件可能会因为复制完成被删除。导致文件找不到出错。但是<code>hdfs dfs -mv</code>命令是一个事务性的操作，不会产生临时文件。</p></div><div class=my-4><a href=/tags/spark/ class="inline-block bg-tertiary-bg text-sm rounded px-3 py-1 my-1 mr-2 hover:text-eureka">#spark</a>
<a href=/tags/streaming/ class="inline-block bg-tertiary-bg text-sm rounded px-3 py-1 my-1 mr-2 hover:text-eureka">#Streaming</a></div><div class=py-2><div class="flex flex-col md:flex-row items-center my-8"><a href=/authors/heis/ class="w-24 h-24 md:mr-4"><img src=/static/img/authors/heis.png class="w-full bg-primary-bg rounded-full" alt=Avatar></a><div class="w-full md:w-auto mt-4 md:mt-0"><a href=/authors/heis/ class="block font-bold text-lg pb-1 mb-2 border-b">黄老师</a>
<span class="block pb-2"></span><a href=mailto:heishuangzy@qq.com class=mr-1><i class="fas fa-envelope"></i></a><a href=https://gitee.com/heis/ class=mr-1><i class="fab fa-git"></i></a><a href=http://heis.gitee.io/ class=mr-1><i class="fas fa-blog"></i></a></div></div></div><div class="flex flex-col md:flex-row md:justify-between -mx-2 mt-4 px-2 pt-4 border-t"><div id=presec><span class="block font-bold">上一页</span>
<a href=/docs/spark-exp/spark-exp05/ class=block>第五章 SparkSQL 实验手册</a></div><div id=nextsec class="md:text-right mt-4 md:mt-0"><span class="block font-bold">下一页</span>
<a href=/docs/spark-exp/spark-exp07/ class=block>第七章 Spark 机器学习库实验手册</a></div></div></div><div class="hidden lg:block lg:w-1/4"><div class="sticky top-16 z-10 hidden lg:block px-6 py-4 bg-secondary-bg pt-16 -mt-16"><span class="text-lg font-semibold">本页内容</span></div><div class="sticky-toc hidden lg:block px-6 pb-6 pt-10 -mt-10 border-l"><nav id=TableOfContents><ul><li><a href=#版本>【版本】</a></li><li><a href=#实验61-运行网络版的wordcount>实验6.1 ：运行网络版的WordCount</a></li><li><a href=#实验名称-实验61-运行网络版的wordcount>【实验名称】 实验6.1 ：运行网络版的WordCount</a><ul><li><a href=#实验目的>【实验目的】</a></li><li><a href=#实验原理>【实验原理】</a></li><li><a href=#实验环境>【实验环境】</a></li><li><a href=#实验步骤>【实验步骤】</a></li></ul></li><li><a href=#实验62-开发自己的streamingwordcount且支持统计历史数据>实验6.2 ：开发自己的StreamingWordCount，且支持统计历史数据</a></li><li><a href=#实验名称-实验62-开发自己的streamingwordcount且支持统计历史数据>【实验名称】 实验6.2 ：开发自己的StreamingWordCount，且支持统计历史数据</a><ul><li><a href=#实验目的-1>【实验目的】</a></li><li><a href=#实验原理-1>【实验原理】</a></li><li><a href=#实验环境-1>【实验环境】</a></li><li><a href=#实验要求>【实验要求】</a></li></ul></li><li><a href=#实验63流式日志过滤与分析>实验6.3：流式日志过滤与分析</a></li><li><a href=#实验名称-实验63流式日志过滤与分析>【实验名称】 实验6.3：流式日志过滤与分析</a><ul><li><a href=#实验目的-2>【实验目的】</a></li><li><a href=#实验原理-2>【实验原理】</a></li><li><a href=#实验环境-2>【实验环境】</a></li><li><a href=#实验资源>【实验资源】</a></li><li><a href=#实验步骤-1>【实验步骤】</a></li></ul></li><li><a href=#常见问题解答faq>【常见问题解答FAQ】</a><ul><li><a href=#问题1上传文件到-hdfs-遇到orgapachehadoopmapreducelibinputinvalidinputexceptioninput-path-does-not-exist-hdfsnode08020xxxtxtcopying之类的问题>问题1：上传文件到 HDFS 遇到<code>org.apache.hadoop.mapreduce.lib.input.InvalidInputException:Input path does not exist: hdfs://node0:8020/xxx.txt.COPYING</code>之类的问题</a></li></ul></li></ul></nav></div><script>window.addEventListener('DOMContentLoaded',()=>{enableStickyToc();});</script></div></div></div></div></div><div id=outerdiv><div id=innerdiv><img id=bigimg src></div></div><script>document.addEventListener('DOMContentLoaded',()=>{hljs.highlightAll();hljs.initLineNumbersOnLoad({singleLine:true});changeSidebarHeight();switchDocToc();$("img").css("cursor:pointer")
$("img").click(function(){var _this=$(this);imgShow("#outerdiv","#innerdiv","#bigimg",_this);});$("ol").each(function(index){if(/\d{1,4}/.test($(this).attr("start"))){let idx=parseInt($(this).attr("start"));let lis=$(this).find("li");if(lis.length>0){lis.each(function(index){$(this).attr("id","step"+(idx+index));});}else{$(this).attr("id","step"+idx);}}});});</script><script src=/static/js/clipboard.min.js></script><script src=/static/js/codecopy.bundle.js?810></script></div></div></main><footer class=pl-scrollbar><div class="w-full max-w-screen-xl mx-auto"><div class="text-center p-6 pin-b"><p class="text-sm text-tertiary-text">&copy; 2021 <a href=https://www.wangchucheng.com/>C. Wang</a> and <a href=https://www.ruiqima.com/>R. Ma</a>
&#183; Powered by the <a href=https://github.com/wangchucheng/hugo-eureka class=hover:text-eureka>Eureka</a> theme for <a href=https://gohugo.io class=hover:text-eureka>Hugo</a></p></div></div></footer></body></html>