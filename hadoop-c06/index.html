<!doctype html><html xmlns=http://www.w3.org/1999/xhtml xml:lang=zh-CN lang=zh-cn><head><link href=//gmpg.org/xfn/11 rel=profile><meta charset=utf-8><meta name=generator content="Hugo 0.80.0"><meta name=viewport content="width=device-width,initial-scale=1"><title>Hadoop Part 6 - 编写 MapReduce 程序 &#183; Heis</title><link type=text/css rel=stylesheet href=https://huangzhiyi.github.io/css/heis-min.css?60><link type=text/css id=dark_theme_css rel=stylesheet href=https://huangzhiyi.github.io/css/a11y-dark.css title=dark><link type=text/css id=light_theme_css rel="alternate stylesheet" href=https://huangzhiyi.github.io/css/a11y-light.css title=light><script>var _hmt=_hmt||[];(function(){var hm=document.createElement("script");hm.src="https://hm.baidu.com/hm.js?f58b6a2675cf52000232edb4d109eccc";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();</script><link rel=apple-touch-icon-precomposed sizes=144x144 href=/apple-touch-icon-144-precomposed2.png><link rel="shortcut icon" href=/favicon2.png><script src=https://huangzhiyi.github.io/js/jquery-min.js></script></head><body><aside class=sidebar id=bsidebar><button id=hide-sb-btn onclick=hideSidebar()></button><div class="container sidebar-sticky"><div class=sidebar-about><a href=https://huangzhiyi.github.io/><h1 id=side-title>Heis</h1></a><p class=lead>Long live MAMBA</p><p class=ac><a href=https://support.qq.com/products/332688 class=tooltip target=_blank><img class=tooltiptext src=https://huangzhiyi.github.io/feedback.png?20210617>
提点意见和建议»</a></p></div><nav><ul class=sidebar-nav><li><a href=https://huangzhiyi.github.io/>首页</a></li><li><a href=https://huangzhiyi.github.io/categories/javaweb/>Java后台应用项目开发»</a></li><li><a href=https://huangzhiyi.github.io/categories/clouddc/>云数据中心基础»</a></li><li><a href=https://huangzhiyi.github.io/categories/webtraining/>Web企业级项目实战»</a></li><li><a href=https://huangzhiyi.github.io/categories>文章分类»</a></li><li><a href=https://huangzhiyi.github.io/tags>文章标签»</a></li><li><a href=https://heis.gitee.io/ target=_blank>镜像0：heis.gitee.io</a></li><li><a href=http://heisun.xyz/ target=_blank>镜像1：heisun.xyz</a></li><li><a href=https://huangzhiyi.github.io/ target=_blank>镜像2：huangzhiyi.github.io</a></li></ul></nav><p>&copy; 2021. All rights reserved.</p><p></p></div></aside><main class="content container" id=mainpanel><button id=show-sb-btn onclick=showSidebar()></button><div class=post><h1>Hadoop Part 6 - 编写 MapReduce 程序</h1><time datetime=2021-04-11T23:20:00+0800 class=post-date>2021-04-11</time><blockquote><h2>文章导航</h2><aside><nav id=TableOfContents><ul><li><ul><li><a href=#版本>【版本】</a></li></ul></li><li><a href=#实验61----编写-mapreduce-wordcount-程序>实验6.1 - 编写 MapReduce wordcount 程序</a><ul><li><a href=#实验名称>【实验名称】</a></li><li><a href=#实验目的>【实验目的】</a></li><li><a href=#实验环境>【实验环境】</a></li><li><a href=#实验资源>【实验资源】</a></li><li><a href=#实验步骤>【实验步骤】</a></li></ul></li><li><a href=#实验62----编写-mapreduce-程序统计数据>实验6.2 - 编写 MapReduce 程序统计数据</a><ul><li><a href=#实验名称-1>【实验名称】</a></li><li><a href=#实验目的-1>【实验目的】</a></li><li><a href=#实验环境-1>【实验环境】</a></li><li><a href=#实验资源-1>【实验资源】</a></li><li><a href=#实验要求>【实验要求】</a></li><li><a href=#实验步骤-1>【实验步骤】</a></li></ul></li></ul></nav></aside></blockquote><p><a href=/hadoop-c-summary/>«返回课程汇总页面</a></p><h3 id=版本>【版本】</h3><p>当前版本号<code>v20210411</code></p><div class=tbl-start></div><table><thead><tr><th>版本</th><th>修改说明</th></tr></thead><tbody><tr><td>v20210411</td><td>初始化版本</td></tr></tbody></table><div class=tbl-end style=height:10px></div><h2 id=实验61----编写-mapreduce-wordcount-程序>实验6.1 - 编写 MapReduce wordcount 程序</h2><h3 id=实验名称>【实验名称】</h3><p>实验6.1 - 编写 MapReduce wordcount 程序</p><h3 id=实验目的>【实验目的】</h3><ul><li>分析和编写 WordCount 程序</li></ul><h3 id=实验环境>【实验环境】</h3><ul><li>Windows 7 以上64位操作系统</li><li>JDK8</li><li>IDEA</li><li>Hadoop 2.7.3</li><li>CentOS 7</li></ul><h3 id=实验资源>【实验资源】</h3><ul><li>Hadoop</li><li><a href=https://www.oracle.com/java/technologies/javase-downloads.html target=_blank>JDK 8</a> - Java Development Kit是 Oracle 公司针对Java开发人员发布的免费软件开发工具包，是 Java 开发必备的开发工具。</li><li><a href=https://www.jetbrains.com/idea/ target=_blank>Intellij IDEA</a> - 业界简称IDEA，是 jetbrains 公司推出的和 Eclipse 齐名的 Java 集成开发环境（IDE）。</li><li><a href=https://maven.apache.org/ target=_blank>Apache Maven</a> - Apache Maven，是一个软件项目管理及自动构建工具，由Apache软件基金会所提供。是 Java 构建打包最广泛使用的工具。</li></ul><pre><code>下载链接：https://pan.baidu.com/s/1ghde86wcK6pwg1fdSSWg0w
提取码：v3wv
</code></pre><h3 id=实验步骤>【实验步骤】</h3><ol><li><p>打开 Part 4 的 hadoopexp 项目。</p></li><li><p>在项目<code>hadoop-exp\src\main\java</code>下创建一个名为<code>hadoop+你学号后4位.mapreduce.wc</code>的包。注意替换为你的学号后4位。</p></li><li><p>在包下面新建一个 <code>WordCountMapper</code> 的类。代码如下，注意替换为你的学号后4位。</p></li></ol><pre><code>package hadoop你的学号后4位.mapreduce.wc;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.IOException;

public class WordCountMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt;{
    @Override
    protected void map(LongWritable key1,Text v1,Context context)
            throws IOException,InterruptedException{
            String data=v1.toString();
            // 分词
            String[] words=data.split(&quot; &quot;);
            // 输出 k2 v2
            for(String w:words){
                context.write(new Text(w),new IntWritable(1));
            }
    }
}
</code></pre><ol start=4><li>在包下面新建一个 <code>WordCountReducer</code> 的类。代码如下，注意替换为你的学号后4位。</li></ol><pre><code>package hadoop你的学号后4位.mapreduce.wc;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;
import java.io.IOException;

public class WordCountReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
    @Override
    protected void reduce(Text k3, Iterable&lt;IntWritable&gt; v3,Context context) throws IOException, InterruptedException {
		//context 是 reduce 的上下文		
        // 对 v3 求和
		int total = 0;
		for(IntWritable v:v3){
		    total += v.get();
		}
		// 输出： k4 单词 v4 频率
		context.write(k3, new IntWritable(total));
	}
}
</code></pre><ol start=5><li>在包下面新建一个 <code>WordCountMain</code> 的类。代码如下，注意替换为你的学号后4位。</li></ol><pre><code>package hadoop你的学号后4位.mapreduce.wc;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.util.GenericOptionsParser;

import java.io.IOException;

public class WordCountMain {

    public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {
        Configuration conf = new Configuration();
        String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();
        int argLength=otherArgs.length;
        if (otherArgs.length &lt; 2) {
            System.err.println(&quot;Usage: wordcount &lt;in&gt; [&lt;in&gt;...] &lt;out&gt;&quot;);
            System.exit(2);
        }
        //获取一个作业实例，名称为Word Count
        Job job=Job.getInstance(conf,&quot;Word Count&quot;);
        //设置运行的jar包里的类
        job.setJarByClass(WordCountMain.class);
        //设置Mapper
        job.setMapperClass(WordCountMapper.class);
        //设置Reducer
        job.setReducerClass(WordCountReducer.class);
        //设置Combiner
        job.setCombinerClass(WordCountReducer.class);
        //设置k4类型
        job.setOutputKeyClass(Text.class);
        //设置v4类型
        job.setOutputValueClass(IntWritable.class);
        //可以接受多个参数作为输入文件路径
        for(int i=0;i&lt;argLength-1;i++) {
            FileInputFormat.addInputPath(job, new Path(otherArgs[i]));
        }
        //最后的一个参数是结果输出路径
        FileOutputFormat.setOutputPath(job,new Path(otherArgs[argLength-1]));
        //如果作业运行成功就成功退出
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}

</code></pre><ol start=6><li>修改项目的<code>pom.xml</code>。其中<code>&lt;mainClass></code>标签内的类修改为<code>WordCountMain</code>类的包内路径。参考代码如下，注意替换为你的学号后4位。</li></ol><pre><code>&lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.2.0&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;archive&gt;
                        &lt;!--&lt;manifestFile&gt;${project.build.outputDirectory}/META-INF/MANIFEST.MF&lt;/manifestFile&gt;--&gt;
                        &lt;manifest&gt;
                            &lt;!-- main()所在的类，注意修改 --&gt;
                            &lt;mainClass&gt;hadoop你的学号后4位.mapreduce.wc.WordCountMain&lt;/mainClass&gt;
                        &lt;/manifest&gt;
                    &lt;/archive&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
</code></pre><ol start=7><li>在 IDEA 的左下角找到 Terminal，输入以下命令，使用 Maven 对代码进行打包。
<img src=/static/img/hadoop-c06/Snipaste_2021-04-11_23-52-36.png alt></li></ol><pre><code>mvn compile package -Dmaven.test.skip=true
</code></pre><ol start=8><li><p>生成的 jar 包会在项目的 target 目录下。名称为<code>hadoop-exp-1.0.jar</code>。</p></li><li><p>把<code>hadoop-exp-1.0.jar</code>和<code>countryroad.txt</code>都上传到<code>NodeA</code>的<code>/home/hadoop</code>目录下。</p></li><li><p>在<code>NodeA</code>启动Hadoop.</p></li></ol><pre><code>start-hdp.sh
</code></pre><ol start=11><li>把<code>NodeA</code>本地的<code>countryroad.txt</code>文件上传到 HDFS 的根目录<code>/</code>。</li></ol><pre><code>hdfs dfs -put /home/hadoop/countryroad.txt /
</code></pre><ol start=12><li>在<code>NodeA</code>上执行以下命令，开始运行我们编写的 Wordcount 程序。</li></ol><pre><code>hadoop jar /home/hadoop/hadoop-exp-1.0.jar /countryroad.txt /output6
</code></pre><ol start=13><li>运行成功以后，查看结果。</li></ol><pre><code>hdfs dfs -cat /output6/part-r-00000
</code></pre><h2 id=实验62----编写-mapreduce-程序统计数据>实验6.2 - 编写 MapReduce 程序统计数据</h2><h3 id=实验名称-1>【实验名称】</h3><p>实验6.2 - 编写 MapReduce 程序统计数据</p><h3 id=实验目的-1>【实验目的】</h3><ul><li>掌握编写 MapReduce 程序进行统计数据</li></ul><h3 id=实验环境-1>【实验环境】</h3><ul><li>Windows 7 以上64位操作系统</li><li>JDK8</li><li>IDEA</li><li>Hadoop 2.7.3</li><li>CentOS 7</li></ul><h3 id=实验资源-1>【实验资源】</h3><ul><li>Hadoop</li><li><a href=https://www.oracle.com/java/technologies/javase-downloads.html target=_blank>JDK 8</a> - Java Development Kit是 Oracle 公司针对Java开发人员发布的免费软件开发工具包，是 Java 开发必备的开发工具。</li><li><a href=https://www.jetbrains.com/idea/ target=_blank>Intellij IDEA</a> - 业界简称IDEA，是 jetbrains 公司推出的和 Eclipse 齐名的 Java 集成开发环境（IDE）。</li><li><a href=https://maven.apache.org/ target=_blank>Apache Maven</a> - Apache Maven，是一个软件项目管理及自动构建工具，由Apache软件基金会所提供。是 Java 构建打包最广泛使用的工具。</li></ul><pre><code>下载链接：https://pan.baidu.com/s/1ghde86wcK6pwg1fdSSWg0w
提取码：v3wv
</code></pre><h3 id=实验要求>【实验要求】</h3><ul><li><p>（1）获取<code>sales.csv</code>文件，文件内是一份销售数据，数据描述如下：
<img src=/static/img/hadoop-exp05/bc9e7892-997e-4560-a709-da430b79fcce.png alt=bc9e7892-997e-4560-a709-da430b79fcce.png></p></li><li><p>（2）根据以上实验步骤，编写相关代码，调用MapReduce，求出各年销售总额。</p></li></ul><h3 id=实验步骤-1>【实验步骤】</h3><ol><li><p>打开 Part 4 的 hadoopexp 项目。</p></li><li><p>在项目<code>hadoop-exp\src\main\java</code>下创建一个名为<code>hadoop+你学号后4位.mapreduce.sales</code>的包。注意替换为你的学号后4位。</p></li><li><p>在包下面新建一个 <code>SalesMapper</code> 的类。下面是部分参考代码，请完成关键的编码部分，注意替换为你的学号后4位。</p></li></ol><pre><code>package hadoop你的学号后4位.mapreduce.sales;

import org.apache.hadoop.io.*;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.IOException;

public class SalesMapper extends Mapper&lt;LongWritable, Text, Text, DoubleWritable&gt;{
    @Override
    protected void map(LongWritable key1,Text v1,Context context)
            throws IOException,InterruptedException{
            String data=v1.toString();
            // 分词
            String[] words=data.split(&quot;,&quot;);
            // 输出 k2 v2
            for(String w:words){
                此处关键代码请自己完成
            }
    }
}
</code></pre><ol start=4><li>在包下面新建一个 <code>SalesReducer</code> 的类。代码如下，注意替换为你的学号后4位。</li></ol><pre><code>package hadoop你的学号后4位.mapreduce.sales;

import org.apache.hadoop.io.DoubleWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;
import java.io.IOException;

public class SalesReducer extends Reducer&lt;Text, DoubleWritable, Text, DoubleWritable&gt; {
    @Override
    protected void reduce(Text k3, Iterable&lt;DoubleWritable&gt; v3,Context context) throws IOException, InterruptedException {
		此处关键代码请自己完成
	}
}
</code></pre><ol start=5><li>在包下面新建一个 <code>SalesMain</code> 的类。代码如下，注意替换为你的学号后4位。</li></ol><pre><code>package hadoop你的学号后4位.mapreduce.sales;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.DoubleWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.util.GenericOptionsParser;

import java.io.IOException;

public class SalesMain {

    public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {
        Configuration conf = new Configuration();
        String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();
        int argLength=otherArgs.length;
        if (otherArgs.length &lt; 2) {
            System.err.println(&quot;Usage: xxx.jar &lt;in&gt; [&lt;in&gt;...] &lt;out&gt;&quot;);
            System.exit(2);
        }
        //获取一个作业实例
        Job job=Job.getInstance(conf,&quot;Sales Statistic&quot;);
        //设置运行的jar包里的类
        job.setJarByClass(SalesMain.class);
        //设置Mapper
        job.setMapperClass(SalesMapper.class);
        //设置Reducer
        job.setReducerClass(SalesReducer.class);
        //设置Combiner
        job.setCombinerClass(SalesReducer.class);
        //设置k4类型
        job.setOutputKeyClass(Text.class);
        //设置v4类型
        job.setOutputValueClass(DoubleWritable.class);
        //可以接受多个参数作为输入文件路径
        for(int i=0;i&lt;argLength-1;i++) {
            FileInputFormat.addInputPath(job, new Path(otherArgs[i]));
        }
        //最后的一个参数是结果输出路径
        FileOutputFormat.setOutputPath(job,new Path(otherArgs[argLength-1]));
        //如果作业运行成功就成功退出
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}
</code></pre><ol start=6><li>修改项目的<code>pom.xml</code>。其中<code>&lt;mainClass></code>标签内的类修改为<code>SalesMain</code>类的包内路径。参考代码如下，注意替换为你的学号后4位。</li></ol><pre><code>&lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.2.0&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;archive&gt;
                        &lt;!--&lt;manifestFile&gt;${project.build.outputDirectory}/META-INF/MANIFEST.MF&lt;/manifestFile&gt;--&gt;
                        &lt;manifest&gt;
                            &lt;!-- main()所在的类，注意修改 --&gt;
                            &lt;mainClass&gt;hadoop你的学号后4位.mapreduce.sales.SalesMain&lt;/mainClass&gt;
                        &lt;/manifest&gt;
                    &lt;/archive&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
</code></pre><ol start=7><li>参考实验6.1 打包、上传包、运行和查看结果的步骤。参考结果如下：</li></ol><pre><code>1998	1.6858740465058884E8
1999	1.555396336197083E8
2000	1.6635854633980626E8
2001	1.969552338600405E8
</code></pre><p>##【常见问题】</p></div><button id=scroll-top-btn>↑顶部</button>
<button id=switch-theme-btn>换主题</button><div id=outerdiv style=position:fixed;top:0;left:0;background:rgba(0,0,0,.7);z-index:2;width:100%;height:100%;display:none><div id=innerdiv style=position:absolute><img id=bigimg style="border:5px solid #fff" src></div></div><div id=category style=display:none;position:fixed;right:10px;bottom:10px;width:10em></div><script src=https://huangzhiyi.github.io/js/highlight.pack.js></script><script src=https://huangzhiyi.github.io/js/highlightjs-line-numbers.min.js></script><script>hljs.initHighlightingOnLoad();hljs.initLineNumbersOnLoad();$(function(){let curTheme=getCookie("theme");if(curTheme===""){setTheme("dark");}else{setTheme(curTheme);}
$('div.tbl-start').nextUntil('div.tbl-end','table').addClass('tbl');$("img").click(function(){var _this=$(this);imgShow("#outerdiv","#innerdiv","#bigimg",_this);});$("#scroll-top-btn").click(function(){document.body.scrollTop=document.documentElement.scrollTop=0;});$("#switch-theme-btn").click(function(){switchTheme();})});</script><script src=https://huangzhiyi.github.io/js/clipboard.min.js?></script><script src=https://huangzhiyi.github.io/js/codecopy.bundle.js?128></script></main><script src=https://huangzhiyi.github.io/js/heis-custom-min.js?60></script></body></html>