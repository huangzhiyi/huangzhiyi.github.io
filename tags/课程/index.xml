<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>课程 on Heis</title><link>https://huangzhiyi.github.io/tags/%E8%AF%BE%E7%A8%8B/</link><description>Recent content in 课程 on Heis</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Tue, 01 Jun 2021 10:20:00 +0800</lastBuildDate><atom:link href="https://huangzhiyi.github.io/tags/%E8%AF%BE%E7%A8%8B/index.xml" rel="self" type="application/rss+xml"/><item><title>Hadoop Part 10 - Flume 和 Sqoop 操作实例（选做）</title><link>https://huangzhiyi.github.io/hadoop-c10/</link><pubDate>Tue, 01 Jun 2021 10:20:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-c10/</guid><description>«返回课程汇总页面
【版本】 当前版本号v20210611
版本 修改说明 v20210611 新增Sqoop的内容 v20210607 初始化版本
实验10.1 - 部署 Flume 【实验名称】 实验10.1 - 部署 Flume
【实验目的】 部署 Flume 【实验环境】 Windows 7 以上64位操作系统 JDK8 VMWare Workstation Pro Hadoop 2.7.3 CentOS 7 【实验资源】 下载链接：https://pan.baidu.com/s/1ghde86wcK6pwg1fdSSWg0w
提取码：v3wv
【实验步骤】 在NodeA节点运行以下语句，注意提升为root权限执行。 创建 Flume 的安装目录。 su
mkdir /opt/flume chown hadoop:wheel /opt/flume
提升 root 用户权限执行以下语句，加入 ZooKeeper 环境变量。 su
echo &amp;quot;export FLUME_HOME=/opt/flume export PATH=\$FLUME_HOME/bin:\$PATH&amp;quot; &amp;gt;&amp;gt;/etc/profile
切换回 hadoop 用户 su hadoop
使环境变量生效。 source /etc/profile
使用 hadoop 登录NodeA节点。 su hadoop
上传 Flume 安装包apache-flume-1.</description></item><item><title>Hadoop Part 9 - 部署 ZooKeeper 和 ZooKeeper 常用操作(选做)</title><link>https://huangzhiyi.github.io/hadoop-c09/</link><pubDate>Tue, 01 Jun 2021 10:20:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-c09/</guid><description>«返回课程汇总页面
【版本】 当前版本号v20210603-1
版本 修改说明 v20210603-1 修正hostname的错误 v20210603 补充个别shell命令，修正start-zk.sh脚本错误 v20210601 初始化版本
实验9.1 - 部署 ZooKeeper 集群模式 【实验名称】 实验9.1 - 部署 ZooKeeper 集群模式
【实验目的】 部署 ZooKeeper 集群模式 【实验环境】 Windows 7 以上64位操作系统 JDK8 VMWare Workstation Pro Hadoop 2.7.3 CentOS 7 【实验资源】 Hadoop 2.X ZooKeeper 3.X 下载链接：https://pan.baidu.com/s/1ghde86wcK6pwg1fdSSWg0w
提取码：v3wv
【实验步骤】 在NodeA、NodeB、NodeC三个节点分别运行以下语句，注意提升为root权限执行。 分别创建 ZooKeeper 的安装目录、数据存放目录和配置文件存放目录。 su
mkdir /opt/zookeeper
mkdir /opt/zookeeper_data
mkdir /opt/zookeeper_config chown hadoop:wheel /opt/zookeeper
chown hadoop:wheel /opt/zookeeper_data
chown hadoop:wheel /opt/zookeeper_config
提升 root 用户权限执行以下语句，加入 ZooKeeper 环境变量。 su
echo &amp;quot;export ZK_HOME=/opt/zookeeper export PATH=\$ZK_HOME/bin:\$PATH:.</description></item><item><title>Hadoop Part 8 - 部署 HBase 和 HBase 常用操作(选做)</title><link>https://huangzhiyi.github.io/hadoop-c08/</link><pubDate>Thu, 20 May 2021 21:20:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-c08/</guid><description>«返回课程汇总页面
【版本】 当前版本号v20210601
版本 修改说明 v20210601 修正文件夹拷贝的命令错误和一些标点符号的错误 v20210520 初始化版本
实验8.1 - 部署 HBase 完全分布式 【实验名称】 实验8.1 - 部署 HBase 完全分布式
【实验目的】 部署 HBase 完全分布式 【实验环境】 Windows 7 以上64位操作系统 JDK8 VMWare Workstation Pro Hadoop 2.7.3 CentOS 7 【实验资源】 Hadoop 2.X HBase 1.X 下载链接：https://pan.baidu.com/s/1ghde86wcK6pwg1fdSSWg0w
提取码：v3wv
【实验步骤】 在NodeA、NodeB、NodeC三个节点分别运行以下语句，创建 HBase 的安装目录。 sudo mkdir /opt/hbase sudo chown hadoop:wheel /opt/hbase
使用 hadoop 登录NodeA节点。 su hadoop
上传 HBase 安装包hbase-1.</description></item><item><title>Hadoop Part 7 - 部署 Hive 和 Hive 常用操作</title><link>https://huangzhiyi.github.io/hadoop-c07/</link><pubDate>Fri, 16 Apr 2021 23:20:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-c07/</guid><description>«返回课程汇总页面
【版本】 当前版本号v20210527
版本 修改说明 v20210527 修改hive-site.xml的配置 v20210416 初始化版本
实验7.1 - 部署 Hive 【实验名称】 实验7.1 - 部署 Hive
【实验目的】 掌握部署 Hive 【实验环境】 Windows 7 以上64位操作系统 JDK8 IDEA Hadoop 2.7.3 CentOS 7 MariaDB/MySQL 【实验资源】 Hadoop 下载链接：https://pan.baidu.com/s/1ghde86wcK6pwg1fdSSWg0w
提取码：v3wv
【实验步骤】 使用 hadoop 登录NodeA节点。 su hadoop
Hive 的安装需要依赖 MySQL 或 MariaDB，这里我们选择 MariaDB。这里需要提权安装，如果安装失败请检查源配置文件/etc/yum.repos.d/local.repo或者光盘是否挂载成功。 sudo yum install mariadb mariadb-server
启动 MariaDB 并设置为开机启动。 sudo systemctl start mariadb sudo systemctl enable mariadb
使用 MariaDB 的安全安装选项。 mysql_secure_installation
以下为弹出选项的输入值</description></item><item><title>Hadoop Part 6 - 编写 MapReduce 程序</title><link>https://huangzhiyi.github.io/hadoop-c06/</link><pubDate>Sun, 11 Apr 2021 23:20:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-c06/</guid><description>«返回课程汇总页面
【版本】 当前版本号v20210411
版本 修改说明 v20210411 初始化版本
实验6.1 - 编写 MapReduce wordcount 程序 【实验名称】 实验6.1 - 编写 MapReduce wordcount 程序
【实验目的】 分析和编写 WordCount 程序 【实验环境】 Windows 7 以上64位操作系统 JDK8 IDEA Hadoop 2.7.3 CentOS 7 【实验资源】 Hadoop JDK 8 - Java Development Kit是 Oracle 公司针对Java开发人员发布的免费软件开发工具包，是 Java 开发必备的开发工具。 Intellij IDEA - 业界简称IDEA，是 jetbrains 公司推出的和 Eclipse 齐名的 Java 集成开发环境（IDE）。 Apache Maven - Apache Maven，是一个软件项目管理及自动构建工具，由Apache软件基金会所提供。是 Java 构建打包最广泛使用的工具。 下载链接：https://pan.</description></item><item><title>Hadoop Part 5 - HDFS Java 编程访问</title><link>https://huangzhiyi.github.io/hadoop-c05/</link><pubDate>Sat, 03 Apr 2021 23:20:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-c05/</guid><description>«返回课程汇总页面
Hadoop Part 5 - HDFS Java 编程访问 【版本】 当前版本号v20210430
版本 修改说明 v20210430 修正 HdfsUtils 类名错误 v20210404 增加常见问题 v20210403 初始化版本
【实验名称】 Hadoop Part 5 - HDFS Java 编程访问
【实验目的】 掌握 HDFS 文件系统的 Java 编程接口的调用和编程 【实验环境】 Windows 7 以上64位操作系统 【实验资源】 Hadoop JDK 8 - Java Development Kit是 Oracle 公司针对Java开发人员发布的免费软件开发工具包，是 Java 开发必备的开发工具。 Intellij IDEA - 业界简称IDEA，是 jetbrains 公司推出的和 Eclipse 齐名的 Java 集成开发环境（IDE）。 Apache Maven - Apache Maven，是一个软件项目管理及自动构建工具，由Apache软件基金会所提供。是 Java 构建打包最广泛使用的工具。 下载链接：https://pan.</description></item><item><title>Hadoop Part 4 - 搭建 Hadoop 开发环境</title><link>https://huangzhiyi.github.io/hadoop-c04/</link><pubDate>Thu, 01 Apr 2021 23:40:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-c04/</guid><description>«返回课程汇总页面
Hadoop Part 4 - 搭建 Hadoop 开发环境 【版本】 当前版本号v20210416
版本 修改说明 v20210416 修正一些拼写错误 v20210401 初始化版本
【实验名称】 Hadoop Part 4 - 搭建 Hadoop 开发环境
【实验目的】 掌握 JDK 的安装和环境变量的设置 掌握 IDEA 的安装和使用 掌握 Maven 的安装、配置和使用命令 【实验环境】 Windows 7 以上64位操作系统 【实验资源】 Hadoop JDK 8 - Java Development Kit是 Oracle 公司针对Java开发人员发布的免费软件开发工具包，是 Java 开发必备的开发工具。 Intellij IDEA - 业界简称IDEA，是 jetbrains 公司推出的和 Eclipse 齐名的 Java 集成开发环境（IDE）。 Apache Maven - Apache Maven，是一个软件项目管理及自动构建工具，由Apache软件基金会所提供。是 Java 构建打包最广泛使用的工具。 下载链接：https://pan.</description></item><item><title>Hadoop Part 3 - 通过Shell命令访问HDFS</title><link>https://huangzhiyi.github.io/hadoop-c03/</link><pubDate>Sun, 28 Mar 2021 00:44:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-c03/</guid><description>«返回课程汇总页面
Hadoop Part 3 - 通过Shell命令访问HDFS 【版本】 当前版本号v20210423
版本 修改说明 v20210423 修正步骤30 文件夹错误 v20210328 初始化版本
【实验名称】 Hadoop Part 3 - 通过Shell命令访问HDFS
【实验目的】 掌握 Web Console 访问 HDFS。 掌握常用的 Shell 命令访问 HDFS。 了解如何使用 IDEA 创建 Maven 工程、运行 Maven 工程。 了解通过 Java API 访问 HDFS。 【实验环境】 内存：至少4G 硬盘：至少空余40G 操作系统: CentOS 7.4 【实验资源】 XShell CentOS 7.</description></item><item><title>Hadoop Part 2 - 部署 Hadoop 完全分布模式</title><link>https://huangzhiyi.github.io/hadoop-c02/</link><pubDate>Fri, 19 Mar 2021 00:44:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-c02/</guid><description>«返回课程汇总页面
Hadoop Part 2 - 部署 Hadoop 完全分布模式 【版本】 当前版本号v20210415
版本 修改说明 v20210415 修改了虚拟机名称的描述避免误解为hostname v20210414 修改了步骤1，提示要使用hadoop用户进行登录 v20210408 新增配置到core-site.xml，修正jobhistoryserver意外退出的问题 v20210407-1 修正NodeB和NodeC的公钥操作 v20210407 修正authorized_keys 在 NodeB 和 NodeC 的操作 v20210406 修改了mapred-site.xml出现的配置错误；新增了把key写入 authorized_keys 步骤；增加了slaves的说明，避免出错； v20210319 初始化版本
【实验名称】 Hadoop Part 2 - 部署 Hadoop 完全分布模式
【实验目的】 掌握搭建 Hadoop 完全分布模式 熟练掌握Linux命令（vi、tar、mv等等）的使用 掌握VMWare、XShell等客户端的使用 【实验环境】 内存：至少4G 硬盘：至少空余40G 操作系统: 64位 Windows系统。 【实验资源】 XShell CentOS 7.</description></item><item><title>Hadoop Part 1 - 模板机制作</title><link>https://huangzhiyi.github.io/hadoop-c01/</link><pubDate>Sun, 14 Mar 2021 00:44:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-c01/</guid><description>«返回课程汇总页面
Hadoop Part 1 - 模板机制作 【版本】 当前版本号v20210423
版本 修改说明 v20210423 修正DNS的地址 v20210415 增加步骤66的命令 v20210402 修改步骤35，增加修改密码的命令 v20210331 修改步骤59，增加source命令 v20210314 初始化版本
【实验名称】 Hadoop Part 1 - 模板机制作
【实验目的】 掌握搭建 CentOS 模板镜像 熟练掌握Linux命令（vi、tar、mv等等）的使用 掌握VMWare、XShell等客户端的使用 【实验环境】 内存：至少4G 硬盘：至少空余40G 操作系统: 64位 Windows系统。 【实验资源】 XShell CentOS 7.4系统镜像 VMWare WorkStation Pro Hadoop 安装包 下载链接：https://pan.</description></item><item><title>商务智能方法与应用综合实验2</title><link>https://huangzhiyi.github.io/bi-training2/</link><pubDate>Mon, 15 Jun 2020 11:42:51 +0800</pubDate><guid>https://huangzhiyi.github.io/bi-training2/</guid><description>«返回课程汇总页面
【实验手册版本】 当前版本号v20200615
版本 修改说明 v20200615 初始化版本 综合练习2 【实验名称】 综合练习2
【实验目的】 针对教育应用场景，练习使用关系数据库分析解决问题
【实验数据说明】 请从下面链接下载练习数据： https://pan.baidu.com/s/1Q3kheymJorKGTxU4pChd3w#提取码kwvi
stu.sql 中包含了3个表，分别是学生信息表stu，家长信息表parents,学生成绩表score。 学生信息表stu 列 备注 id 主键 stuid 学号 name 姓名 gender 性别 clazz 班级 家长信息表parents 列 备注 id 主键 stuid 学号 fname 父亲姓名 fphone 父亲手机号 fname 母亲姓名 fphone 母亲手机号 学生成绩表score 列 备注 id 主键 testid 考试ID stuid 学号 chn 语文成绩 math 数学成绩 eng 英语成绩 tot 总分 【实验环境】 操作系统：Windows MySQL MySQL Workbench/Navicat/HeidiSQL 【实验原理】 SQL 常用语法模板 select 表名1.</description></item><item><title>数据仓库与挖掘技术课程资源汇总</title><link>https://huangzhiyi.github.io/datamining-summary/</link><pubDate>Fri, 15 May 2020 10:42:51 +0800</pubDate><guid>https://huangzhiyi.github.io/datamining-summary/</guid><description>实验报告模板下载 https://pan.baidu.com/s/1qqhcPcQotylS3PNP4f-edg#提取码vidt
实验报告要求 必须使用老师提供的实验报告模板。 实验步骤每一步都有详细的操作步骤说明，步骤顺序号，截图。 截图只截关键部分信息，不要全屏截图，如果截图信息太多需要标记截图关键信息。推荐使用 Snipaste（官网下载或网盘下载） 进行截图和标记。 作业提交 除了特殊原因申请延后提交实验报告的同学，其他同学请按照时间提交实验报告
第三章实验报告 数学17，2020年6月6日（周六）前提交 http://xzc.cn/TKZbTede44 第四章实验报告 数学17，2020年6月6日（周六）前提交 http://xzc.cn/tEe7tHesA6 第五章实验报告 数学17，2020年5月30日（周五）前提交 http://xzc.cn/PjIc3tMWwJ 第六章实验报告 数学17，2020年6月10日（周三）前提交 http://xzc.cn/HTikQAezeZ 第七章实验报告 数学17，2020年6月17日（周三）前提交 http://xzc.cn/xyLgG91k1w</description></item><item><title>商务智能方法与应用综合实验1参考解决方法</title><link>https://huangzhiyi.github.io/bi-training1-rs/</link><pubDate>Sun, 12 Apr 2020 14:42:51 +0800</pubDate><guid>https://huangzhiyi.github.io/bi-training1-rs/</guid><description>«返回课程汇总页面
【实验手册版本】 当前版本号v20200412
版本 修改说明 v20200412 初始化版本
综合练习1 【实验名称】 综合练习1
【实验目的】 综合前四章学习的知识，完成对数据的清洗，提取，维度建模和 OLAP 分析。
【实验数据说明】 请从下面链接下载练习数据： https://pan.baidu.com/s/1Xj6s2evPcx8TpzpHkvjBDA#提取码u0jg
people.csv 中的数据是中国第五次人口普查（2000年）和第六次人口普查（2010年）的数据。以下为数据列的说明
列序号 说明 1 地区名称 2 户口地区类型，分别为 城市/镇/乡村 3 户口集体类型，分别为 家庭户/集体户 4 统计年份 5 性别 6 人数
其中户口地区类型分为三种，即城市、镇和乡村。每个地区类型下，又按集体类型分为两种，家庭户和集体户。</description></item><item><title>商务智能方法与应用综合实验1</title><link>https://huangzhiyi.github.io/bi-training1/</link><pubDate>Sun, 12 Apr 2020 11:42:51 +0800</pubDate><guid>https://huangzhiyi.github.io/bi-training1/</guid><description>«返回课程汇总页面
【实验手册版本】 当前版本号v20200412
版本 修改说明 v20200506 修改导入csv脚本的字符，utf8改为utf8mb4；新增常见问题解答 v20200412 初始化版本
综合练习1 【实验名称】 综合练习1
【实验目的】 综合前四章学习的知识，完成对数据的清洗，提取，维度建模和 OLAP 分析。
【实验数据说明】 请从下面链接下载练习数据： https://pan.baidu.com/s/1Xj6s2evPcx8TpzpHkvjBDA#提取码u0jg
people.csv 中的数据是中国第五次人口普查（2000年）和第六次人口普查（2010年）的数据。以下为数据列的说明
列序号 说明 1 地区名称 2 户口地区类型，分别为 城市/镇/乡村 3 户口集体类型，分别为 家庭户/集体户 4 统计年份 5 性别 6 人数
其中户口地区类型分为三种，即城市、镇和乡村。每个地区类型下，又按集体类型分为两种，家庭户和集体户。</description></item><item><title>商务智能方法与应用第六章实验手册</title><link>https://huangzhiyi.github.io/bi-exp06/</link><pubDate>Tue, 11 Feb 2020 11:42:51 +0800</pubDate><guid>https://huangzhiyi.github.io/bi-exp06/</guid><description>«返回课程汇总页面
【实验手册版本】 当前版本号v20200605
版本 修改说明 v20200605 实验6.1新增了校验测试结果的步骤 v20200527 修正了数据库连接的问题，修正航空里程列SEG_KM_COUNT为SEG_KM_SUM v20200513 初始化版本
实验6.1：超市客户信息分类预测 【实验名称】 实验6.1：超市客户信息分类预测
【实验目的】 根据现有超市客户数据构造客户分类模型
使用分类模型对客户数据进行预测
熟悉并学会使用weka智能分析环境；
【实验内容】 使用 Weka 的分类模型对现有 foodmart 数据库客户信息进行建模，获取到建模以后，使用模型对数据进行预测。
【实验环境】 Windows 操作系统。 JDK MySQL Foodmart 数据集 Weka：Weka 的全名是怀卡托智能分析环境（Waikato Environment for Knowledge Analysis），是一款免费的，非商业化（与之对应的是SPSS公司商业数据挖掘产品&amp;ndash;Clementine ）的，基于JAVA环境下开源的机器学习（machine learning）以及数据挖掘（data mining）软件。Weka 作为一个公开的数据挖掘工作平台，集合了大量能承担数据挖掘任务的机器学习算法，包括对数据进行预处理，分类，回归、聚类、关联规则以及在新的交互式界面上的可视化。 【实验资源】 实验报告模板下载
https://pan.baidu.com/s/1qqhcPcQotylS3PNP4f-edg#提取码vidt
实验数据下载</description></item><item><title>商务智能方法与应用第五章实验手册</title><link>https://huangzhiyi.github.io/bi-exp05/</link><pubDate>Mon, 10 Feb 2020 13:42:51 +0800</pubDate><guid>https://huangzhiyi.github.io/bi-exp05/</guid><description>«返回课程汇总页面
【实验手册版本】 当前版本号v20200824
版本 修改说明 v20200824 修正敏感词 v20200331 修正分析结果 v20200327 初始化版本
实验5.1：购物篮关联性推荐 【实验名称】 实验5.1：购物篮关联性推荐
【实验目的】 熟悉并学会使用weka智能分析环境；
根据数据源建立数据模型；
根据数据模型对购物篮数据进行关联性分析；
【实验内容】 本实验利用weka智能分析软件，对购物篮销售数据进行关联性分析，从而得出商店如何摆放产品将有利于提高我们的销售额度。
【实验相关知识解读】 Apriori 算法是一种最有影响力的挖掘布尔关联规则的频繁项集的 算法，它是由Rakesh Agrawal 和RamakrishnanSkrikant 提出的。了解更多信息可以参考这篇文章
机器学习领域经典的 FP-growth（Frequent Pattern Growth）模型，它是目前业界经典的频繁项集和关联规则挖掘的算法。相比于 Apriori 模型，FP-growth 模型只需要扫描数据库两次，极大得减少了数据读取次数并显著得提升了算法效率。了解更多信息可以参考这篇文章
ARFF 格式指的是 Attribute-Relation File Format。可以理解为增加了列描述的 CSV 格式。文件主要分为头部（Head）信息和数据信息（Data)。头部信息定义了 Relation 和各列的 Attribute 的类型。数据部分内容和CSV一样，每列内容使用英文逗号隔开。例如下图就是一个 ARFF 格式数据。更多信息可以参考这篇文章。 【实验环境】 Windows 操作系统。 JDK Weka：Weka 的全名是怀卡托智能分析环境（Waikato Environment for Knowledge Analysis），是一款免费的，非商业化（与之对应的是SPSS公司商业数据挖掘产品&amp;ndash;Clementine ）的，基于JAVA环境下开源的机器学习（machine learning）以及数据挖掘（data mining）软件。Weka 作为一个公开的数据挖掘工作平台,汇聚了大量能承担数据挖掘任务的机器学习算法，包括对数据进行预处理，分类，回归、聚类、关联规则以及在新的交互式界面上的可视化。 【实验资源】 实验报告模板下载</description></item><item><title>商务智能方法与应用第四章实验手册</title><link>https://huangzhiyi.github.io/bi-exp04/</link><pubDate>Mon, 10 Feb 2020 12:42:51 +0800</pubDate><guid>https://huangzhiyi.github.io/bi-exp04/</guid><description>«返回课程汇总页面
【实验手册版本】 当前版本号v20200415
版本 修改说明 v20200415 增加了常见问题解答 v20200413 增加了授权文件的说明 v20200408 更正了几个截图 v20200329 更正了几个截图和加入更换驱动的步骤 v20200313 初始化版本
实验4.1：使用 Saiku 进行联机分析（OLAP） 【实验名称】 实验4.1：使用 Saiku 进行联机分析（OLAP）
【实验目的】 1．熟悉 Linux 系统、Saiku等系统和软件的安装和使用； 2．了解联机分析的基本流程； 3．熟悉利用可视化工具 Saiku 对联机分析模型的查询。 【实验原理】 本实验利用 Saiku v3.6 平台来对联机分析模型进行查询。 预先准备好实验3.1完成的 Cube Schema文件 准备加载了 foodmart 库的 MySQL 数据库。 【实验环境】 Windows 操作系统。 MySQL 数据库 JDK8 Saiku CE v3.</description></item><item><title>商务智能方法与应用第三章实验手册</title><link>https://huangzhiyi.github.io/bi-exp03/</link><pubDate>Mon, 10 Feb 2020 11:42:51 +0800</pubDate><guid>https://huangzhiyi.github.io/bi-exp03/</guid><description>«返回课程汇总页面
【实验手册版本】 当前版本号v20200331
版本 修改说明 v20200331 修正关于my-huge.ini步骤的说明 v20200315 修正了度量的 aggregator 为 sum v20200314 增加了MySQL相关配置，提高数据库查询性能；同时增加了foodmart表格说明； v20200304 初始化版本
实验3.1：使用 Schema Workbench 创建 Cube 【实验名称】 使用 Schema Workbench 创建 Cube
【实验目的】 1．熟悉 Schema Workbench 并学会使用； 2．学会创建 Cube。 【实验原理】 数据仓库（Data Warehouse）是一个面向主题的（Subject Oriented）、集成的（Integrated）、相对稳定的（Non-Volatile）、反映历史变化（Time Variant）的数据集合，用于支持管理决策。
Hive 是一个构建于 Hadoop 顶层的数据仓库工具，支持大规模数据存储、分析，具有良好的可扩展性。某种程度上可以将 Hive 看作是用户编程接口。Hive 本身不存储和处理数据，依赖分布式文件系统 HDFS 存储数据，依赖分布式并行计算模型MapReduce 处理数据。Hive 定义了简单的类似 SQL 的查询语言——HiveQL。用户可以通过编写的 HiveQL 语句运行 MapReduce 任务，可以很容易把原来构建在关系数据库上的数据仓库应用程序移植到 Hadoop 平台上。Hive 是一个可以有效、合理、直观的数据分析工具。</description></item><item><title>商务智能方法与应用第二章实验手册</title><link>https://huangzhiyi.github.io/bi-exp02/</link><pubDate>Sun, 09 Feb 2020 10:42:51 +0800</pubDate><guid>https://huangzhiyi.github.io/bi-exp02/</guid><description>«返回课程汇总页面
【实验手册版本】 当前版本号v20200330
版本 修改说明 v20200330 增加了 Hive 优化参数 v20200325 第10步第（4）小题增加了提示 v20200323 更正实验第10步第（3）小题错误 v20200228 初始化版本
实验2.1：Hive 数据仓库的建立和分析 【实验名称】 Hive 数据仓库的建立
【实验目的】 1．熟悉 Linux、MySQL、Hive、HDFS 等系统和软件的安装和使用。 2．了解建立数据仓库的基本流程。 3．熟悉数据预处理方法。 【实验原理】 数据仓库（Data Warehouse）是一个面向主题的（Subject Oriented）、集成的（Integrated）、相对稳定的（Non-Volatile）、反映历史变化（Time Variant）的数据集合，用于支持管理决策。
Hive 是一个构建于 Hadoop 顶层的数据仓库工具，支持大规模数据存储、分析，具有良好的可扩展性。某种程度上可以将 Hive 看作是用户编程接口。Hive 本身不存储和处理数据，依赖分布式文件系统 HDFS 存储数据，依赖分布式并行计算模型MapReduce 处理数据。Hive 定义了简单的类似 SQL 的查询语言——HiveQL。用户可以通过编写的 HiveQL 语句运行 MapReduce 任务，可以很容易把原来构建在关系数据库上的数据仓库应用程序移植到 Hadoop 平台上。Hive 是一个可以有效、合理、直观的数据分析工具。</description></item><item><title>商务智能方法与应用第一章实验手册</title><link>https://huangzhiyi.github.io/bi-exp01/</link><pubDate>Sat, 08 Feb 2020 10:42:51 +0800</pubDate><guid>https://huangzhiyi.github.io/bi-exp01/</guid><description>«返回课程汇总页面
【实验手册版本】 当前版本号v20200407
版本 修改说明 v20200407 修改MySql 的版本为5.x，因为8.x的版本存在兼容问题 v20200325 修改步骤4的相关描述，去掉查看test库的要求 v20200318 修改了MySQL驱动的版本，避免出现驱动不兼容情况 v20200313 增加了 Kettle 网盘下载链接 v20200312 更新了 Kettle 下载链接 v20200210 初始化版本
实验1：销售数据预处理 【实验名称】 销售数据预处理
【实验目的】 熟悉 Linux、MySQL、Insight 等系统和软件的安装与使用。 了解大数据处理的基本流程。 熟悉数据抽取、转换、加载的方法。 熟悉在不同类型数据库之间进行数据的导入与导出。 【实验原理】 本实验将使用 MySQL Workbench （MySQL 连接客户端软件）以及 Pantaho Data Integration（也叫 Kettle，是一个ETL工具）。
首先将销售数据和员工数据导入 MySQL，通过 Kettle 和 MySQL Workbench 连接，将两个数据源利用员工信息号进行整合，最终将生成的一张新表格 写入数据库，达到可在一张表格中查看员工信息和对应销售情况的目的。</description></item><item><title>商务智能课程资源汇总</title><link>https://huangzhiyi.github.io/bi-summary/</link><pubDate>Fri, 07 Feb 2020 10:42:51 +0800</pubDate><guid>https://huangzhiyi.github.io/bi-summary/</guid><description>实验报告模板下载 https://pan.baidu.com/s/1qqhcPcQotylS3PNP4f-edg#提取码vidt
实验报告要求 必须使用老师提供的实验报告模板。 实验步骤每一步都有详细的操作步骤说明，步骤顺序号，截图。 截图只截关键部分信息，不要全屏截图，如果截图信息太多需要标记截图关键信息。推荐使用 Snipaste（官网下载或网盘下载） 进行截图和标记。 实验手册 第一章实验手册
第二章实验手册
第三章实验手册
第四章实验手册
第五章实验手册
第六章实验手册
课程课件资源 https://pan.baidu.com/s/1zSmrVAKFaccUc4cZXcQGxA#提取码vhwc
作业提交 除了特殊原因申请延后提交实验报告的同学，其他同学请按照时间提交实验报告
第一章实验报告 数学17，2020年3月25日（周三）前提交 http://xzc.cn/rxtzGWLsZF 第二章实验报告 数学17，2020年4月6日（周一）前提交 http://xzc.cn/S4gbh6W2bb 第三章实验报告 数学17，2020年4月17日（周五）前提交 http://xzc.cn/n87885OAAP 第四章实验报告 数学17，2020年5月23日（周六）前提交 http://xzc.cn/eNaRinnGkt 第五章实验报告 数学17，2020年6月7日（周日）前提交 http://xzc.cn/B9uqzU44EE 第六章实验报告 数学17，2020年6月14日（周日）前提交 http://xzc.cn/NZT4LY09a5</description></item></channel></rss>