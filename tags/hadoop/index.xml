<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>hadoop on Heis</title><link>https://huangzhiyi.github.io/tags/hadoop/</link><description>Recent content in hadoop on Heis</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Tue, 01 Jun 2021 10:20:00 +0800</lastBuildDate><atom:link href="https://huangzhiyi.github.io/tags/hadoop/index.xml" rel="self" type="application/rss+xml"/><item><title>Hadoop Part 10 - Flume 和 Sqoop 操作实例（选做）</title><link>https://huangzhiyi.github.io/hadoop-c10/</link><pubDate>Tue, 01 Jun 2021 10:20:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-c10/</guid><description>«返回课程汇总页面
【版本】 当前版本号v20210611
版本 修改说明 v20210611 新增Sqoop的内容 v20210607 初始化版本
实验10.1 - 部署 Flume 【实验名称】 实验10.1 - 部署 Flume
【实验目的】 部署 Flume 【实验环境】 Windows 7 以上64位操作系统 JDK8 VMWare Workstation Pro Hadoop 2.7.3 CentOS 7 【实验资源】 下载链接：https://pan.baidu.com/s/1ghde86wcK6pwg1fdSSWg0w 提取码：v3wv 【实验步骤】 在NodeA节点运行以下语句，注意提升为root权限执行。 创建 Flume 的安装目录。 su
mkdir /opt/flume chown hadoop:wheel /opt/flume
提升 root 用户权限执行以下语句，加入 ZooKeeper 环境变量。 su
echo &amp;quot;export FLUME_HOME=/opt/flume export PATH=\$FLUME_HOME/bin:\$PATH&amp;quot; &amp;gt;&amp;gt;/etc/profile
切换回 hadoop 用户 su hadoop
使环境变量生效。 source /etc/profile
使用 hadoop 登录NodeA节点。 su hadoop
上传 Flume 安装包apache-flume-1.</description></item><item><title>Hadoop Part 9 - 部署 ZooKeeper 和 ZooKeeper 常用操作(选做)</title><link>https://huangzhiyi.github.io/hadoop-c09/</link><pubDate>Tue, 01 Jun 2021 10:20:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-c09/</guid><description>«返回课程汇总页面
【版本】 当前版本号v20210603-1
版本 修改说明 v20210603-1 修正hostname的错误 v20210603 补充个别shell命令，修正start-zk.sh脚本错误 v20210601 初始化版本
实验9.1 - 部署 ZooKeeper 集群模式 【实验名称】 实验9.1 - 部署 ZooKeeper 集群模式
【实验目的】 部署 ZooKeeper 集群模式 【实验环境】 Windows 7 以上64位操作系统 JDK8 VMWare Workstation Pro Hadoop 2.7.3 CentOS 7 【实验资源】 Hadoop 2.X ZooKeeper 3.X 下载链接：https://pan.baidu.com/s/1ghde86wcK6pwg1fdSSWg0w 提取码：v3wv 【实验步骤】 在NodeA、NodeB、NodeC三个节点分别运行以下语句，注意提升为root权限执行。 分别创建 ZooKeeper 的安装目录、数据存放目录和配置文件存放目录。 su
mkdir /opt/zookeeper
mkdir /opt/zookeeper_data
mkdir /opt/zookeeper_config chown hadoop:wheel /opt/zookeeper
chown hadoop:wheel /opt/zookeeper_data
chown hadoop:wheel /opt/zookeeper_config
提升 root 用户权限执行以下语句，加入 ZooKeeper 环境变量。 su
echo &amp;quot;export ZK_HOME=/opt/zookeeper export PATH=\$ZK_HOME/bin:\$PATH:.</description></item><item><title>Hadoop大数据集群部署实战 Part 5 - 使用 MapReduce 和 Hive 进行数据分析</title><link>https://huangzhiyi.github.io/hadoop-training05/</link><pubDate>Sun, 23 May 2021 01:40:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-training05/</guid><description>«返回课程汇总页面
Hadoop大数据集群部署实战 Part 5 - 使用 MapReduce 和 Hive 进行数据分析 【版本】 当前版本号v20210521
版本 修改说明 v20210521 初始化版本
数据分析实训5.1 - 在电影库中查找我的演员评分最高的5部电影 【实训名称】 数据分析实训5.1 - 在电影库中查找我的演员评分最高的5部电影
【实训目的】 掌握 MapReduce 的 Mapper 编写 掌握 MapReduce 序列化的使用 掌握 MapReduce 的排序 【实训环境】 Windows 7+ VMWare Workstation Pro CentOS 7 Hadoop 2.7.3 JDK 版本：1.8 或以上版本。 【实训资源】 软件资源 链接：https://pan.baidu.com/s/1xYCO5mT2mxZGkda6j3mtdg 提取码：heis
项目代码 链接：https://pan.</description></item><item><title>Hadoop Part 8 - 部署 HBase 和 HBase 常用操作(选做)</title><link>https://huangzhiyi.github.io/hadoop-c08/</link><pubDate>Thu, 20 May 2021 21:20:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-c08/</guid><description>«返回课程汇总页面
【版本】 当前版本号v20210601
版本 修改说明 v20210601 修正文件夹拷贝的命令错误和一些标点符号的错误 v20210520 初始化版本
实验8.1 - 部署 HBase 完全分布式 【实验名称】 实验8.1 - 部署 HBase 完全分布式
【实验目的】 部署 HBase 完全分布式 【实验环境】 Windows 7 以上64位操作系统 JDK8 VMWare Workstation Pro Hadoop 2.7.3 CentOS 7 【实验资源】 Hadoop 2.X HBase 1.X 下载链接：https://pan.baidu.com/s/1ghde86wcK6pwg1fdSSWg0w 提取码：v3wv 【实验步骤】 在NodeA、NodeB、NodeC三个节点分别运行以下语句，创建 HBase 的安装目录。 sudo mkdir /opt/hbase sudo chown hadoop:wheel /opt/hbase
使用 hadoop 登录NodeA节点。 su hadoop
上传 HBase 安装包hbase-1.</description></item><item><title>Hadoop大数据集群部署实战 Part 4 - 搭建 Hadoop 开发环境</title><link>https://huangzhiyi.github.io/hadoop-training04/</link><pubDate>Mon, 17 May 2021 01:40:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-training04/</guid><description>«返回课程汇总页面
Hadoop大数据集群部署实战 Part 4 - 搭建 Hadoop 开发环境 【版本】 当前版本号v20210416
版本 修改说明 v20210416 修正一些拼写错误 v20210401 初始化版本
【实验名称】 Hadoop Part 4 - 搭建 Hadoop 开发环境
【实验目的】 掌握 JDK 的安装和环境变量的设置 掌握 IDEA 的安装和使用 掌握 Maven 的安装、配置和使用命令 【实验环境】 Windows 7 以上64位操作系统 【实验资源】 软件资源 链接：https://pan.baidu.com/s/1xYCO5mT2mxZGkda6j3mtdg 提取码：heis
项目代码 链接：https://pan.baidu.com/s/1DcLksXdp_xbqv1fOBeF-UA 提取码：heis
【实验步骤】 在 Windows 解压jdk8.</description></item><item><title>Hadoop大数据集群部署实战 Part 3 - 部署 Hive</title><link>https://huangzhiyi.github.io/hadoop-training03/</link><pubDate>Sun, 16 May 2021 01:15:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-training03/</guid><description>«返回课程汇总页面
Hadoop大数据集群部署实战 Part 3 - 部署 Hive 【版本】 当前版本号v20210516
版本 修改说明 v20210516 初始化版本
【实验名称】 Hadoop大数据集群部署实战 Part3 - 部署 Hive
【实验目的】 掌握 Hive 的部署和使用 【实验环境】 内存：至少4G 硬盘：至少空余40G 操作系统: 64位 Windows系统。 【实验资源】 软件资源 链接：https://pan.baidu.com/s/1xYCO5mT2mxZGkda6j3mtdg 提取码：heis
项目代码 链接：https://pan.baidu.com/s/1DcLksXdp_xbqv1fOBeF-UA 提取码：heis
【实验步骤】 使用 hadoop 登录NodeA节点。 su hadoop
Hive 的安装需要依赖 MySQL 或 MariaDB，这里我们选择 MariaDB。这里需要提权安装，如果安装失败请检查源配置文件/etc/yum.repos.d/local.repo或者光盘是否挂载成功。 sudo yum install mariadb mariadb-server
启动 MariaDB 并设置为开机启动。 sudo systemctl start mariadb sudo systemctl enable mariadb
使用 MariaDB 的安全安装选项。 mysql_secure_installation
以下为弹出选项的输入值</description></item><item><title>Hadoop大数据集群部署实战 Part 2 - 部署 Hadoop 完全分布模式</title><link>https://huangzhiyi.github.io/hadoop-training02/</link><pubDate>Sun, 16 May 2021 01:14:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-training02/</guid><description>«返回课程汇总页面
Hadoop大数据集群部署实战 Part 2 - 部署 Hadoop 完全分布模式 【版本】 当前版本号v20210516
版本 修改说明 v20210516 初始化版本
【实验名称】 Hadoop大数据集群部署实战 Part2 - 部署 Hadoop 完全分布模式
【实验目的】 掌握 Hadoop 的完全分布式部署 【实验环境】 内存：至少4G 硬盘：至少空余40G 操作系统: 64位 Windows系统。 【实验资源】 软件资源 链接：https://pan.baidu.com/s/1xYCO5mT2mxZGkda6j3mtdg 提取码：heis
项目代码 链接：https://pan.baidu.com/s/1DcLksXdp_xbqv1fOBeF-UA 提取码：heis
【实验步骤】 关闭 Part1 完成的 HadoopTmpl 模板机。依次克隆出3台虚拟机，名称，主机名和 IP 地址如下表所示，注意替换为你的学号后4位。
虚拟机名称 hostname IP地址 节点A主机（Namenode） nodea+你学号后4位 10.</description></item><item><title>Hadoop大数据集群部署实战 Part 1 - 模板机制作</title><link>https://huangzhiyi.github.io/hadoop-training01/</link><pubDate>Sun, 16 May 2021 00:44:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-training01/</guid><description>«返回课程汇总页面
Hadoop大数据集群部署实战 Part 1 - 模板机制作 【版本】 当前版本号v20210516
版本 修改说明 v20210516 初始化版本
【实验名称】 Hadoop Part 1 - 模板机制作
【实验目的】 掌握搭建 CentOS 模板镜像 熟练掌握Linux命令（vi、tar、mv等等）的使用 掌握VMWare、XShell等客户端的使用 【实验环境】 内存：至少4G 硬盘：至少空余40G 操作系统: 64位 Windows系统。 【实验资源】 软件资源 链接：https://pan.baidu.com/s/1xYCO5mT2mxZGkda6j3mtdg 提取码：heis
项目代码 链接：https://pan.baidu.com/s/1DcLksXdp_xbqv1fOBeF-UA 提取码：heis
【实验步骤】 安装 VMWare Workstation Pro。过程略。
安装 XShell。过程略。
启动VMWare WorkStation Pro，点击“新建新的虚拟机”，开始制作CentOS 模板镜像。 选择稍后安装操作系统。 选择Linux系统，版本为CentOS 7 64位 注意此处需要把虚拟机名称命名为HadoopTmpl+你个人学号后4位（不符合要求会扣分），并选择合适文件目录进行保存。 处理器和内核数都设置为1。 内存设置为1024M。 网络连接选择NAT。 IO控制器和磁盘类型设为默认设置。 创建新虚拟磁盘，空间可设为50G。 完成虚拟机创建向导。 选中刚完成的虚拟机，点击编辑虚拟机设置。 处理器设置勾选虚拟化Intel VT-x/EPT 或 AMD-V/RVI(V)。 CD/DVD选项加载课程资源提供的CentOS系统安装镜像文件CentOS-7.</description></item><item><title>Hadoop 大数据集群部署实战课程资源汇总</title><link>https://huangzhiyi.github.io/hadoop-training-summary/</link><pubDate>Sat, 15 May 2021 00:42:51 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-training-summary/</guid><description>课程设计报告模板资源下载 链接：https://pan.baidu.com/s/1xYCO5mT2mxZGkda6j3mtdg 提取码：heis
课程设计报告要求 必须使用老师提供的课程设计报告模板。 必须保留封面 实验步骤每一步都有详细的文字操作步骤说明，步骤顺序号，截图。 截图只需要截关键部分信息，不能全屏截图。可以用红色框或箭头标注截图重点信息。推荐使用 Snipaste（官网下载或网盘下载） 进行截图和标记。 课程设计报告提交截止时间和地址 后续会公布链接，请各位同学登录网站 https://heis.gitee.io/hadoop-training-summary查看。
课程内容 （1）Hadoop大数据集群部署实战 Part 1 - 模板机制作 （2）Hadoop大数据集群部署实战 Part 2 - 部署 Hadoop 完全分布模式 （3）Hadoop大数据集群部署实战 Part 3 - 部署 Hive （4）Hadoop大数据集群部署实战 Part 4 - 搭建 Hadoop 开发环境 （5）Hadoop大数据集群部署实战 Part 5 - 使用 MapReduce 和 Hive 进行数据分析 课程设计报告提交 19级计算机2班 截止日期：2021/6/7（周一） http://xzc.cn/dNqDFUUidd
19级计算机4班 截止日期：2021/6/21（周一） http://xzc.cn/i8HCP37KAY
Hadoop 官方手册 官方 Hadoop 完全分布式教程
常用命令 vi/vim 命令图 查看IP地址等网络配置信息 ip a
修改包括IP等网络配置命令 #如果你的网卡名为eth0
vim /etc/sysconfig/network-scripts/ifcfg-eth0
#如果你的网卡名为ens33
vim /etc/sysconfig/network-scripts/ifcfg-ens33
#地址
IPADDR=10.</description></item><item><title>Hadoop Part 7 - 部署 Hive 和 Hive 常用操作</title><link>https://huangzhiyi.github.io/hadoop-c07/</link><pubDate>Fri, 16 Apr 2021 23:20:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-c07/</guid><description>«返回课程汇总页面
【版本】 当前版本号v20210527
版本 修改说明 v20210527 修改hive-site.xml的配置 v20210416 初始化版本
实验7.1 - 部署 Hive 【实验名称】 实验7.1 - 部署 Hive
【实验目的】 掌握部署 Hive 【实验环境】 Windows 7 以上64位操作系统 JDK8 IDEA Hadoop 2.7.3 CentOS 7 MariaDB/MySQL 【实验资源】 Hadoop 下载链接：https://pan.baidu.com/s/1ghde86wcK6pwg1fdSSWg0w 提取码：v3wv 【实验步骤】 使用 hadoop 登录NodeA节点。 su hadoop
Hive 的安装需要依赖 MySQL 或 MariaDB，这里我们选择 MariaDB。这里需要提权安装，如果安装失败请检查源配置文件/etc/yum.repos.d/local.repo或者光盘是否挂载成功。 sudo yum install mariadb mariadb-server
启动 MariaDB 并设置为开机启动。 sudo systemctl start mariadb sudo systemctl enable mariadb
使用 MariaDB 的安全安装选项。 mysql_secure_installation
以下为弹出选项的输入值</description></item><item><title>Hadoop Part 6 - 编写 MapReduce 程序</title><link>https://huangzhiyi.github.io/hadoop-c06/</link><pubDate>Sun, 11 Apr 2021 23:20:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-c06/</guid><description>«返回课程汇总页面
【版本】 当前版本号v20210411
版本 修改说明 v20210411 初始化版本
实验6.1 - 编写 MapReduce wordcount 程序 【实验名称】 实验6.1 - 编写 MapReduce wordcount 程序
【实验目的】 分析和编写 WordCount 程序 【实验环境】 Windows 7 以上64位操作系统 JDK8 IDEA Hadoop 2.7.3 CentOS 7 【实验资源】 Hadoop JDK 8 - Java Development Kit是 Oracle 公司针对Java开发人员发布的免费软件开发工具包，是 Java 开发必备的开发工具。 Intellij IDEA - 业界简称IDEA，是 jetbrains 公司推出的和 Eclipse 齐名的 Java 集成开发环境（IDE）。 Apache Maven - Apache Maven，是一个软件项目管理及自动构建工具，由Apache软件基金会所提供。是 Java 构建打包最广泛使用的工具。 下载链接：https://pan.</description></item><item><title>Hadoop Part 5 - HDFS Java 编程访问</title><link>https://huangzhiyi.github.io/hadoop-c05/</link><pubDate>Sat, 03 Apr 2021 23:20:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-c05/</guid><description>«返回课程汇总页面
Hadoop Part 5 - HDFS Java 编程访问 【版本】 当前版本号v20210430
版本 修改说明 v20210430 修正 HdfsUtils 类名错误 v20210404 增加常见问题 v20210403 初始化版本
【实验名称】 Hadoop Part 5 - HDFS Java 编程访问
【实验目的】 掌握 HDFS 文件系统的 Java 编程接口的调用和编程 【实验环境】 Windows 7 以上64位操作系统 【实验资源】 Hadoop JDK 8 - Java Development Kit是 Oracle 公司针对Java开发人员发布的免费软件开发工具包，是 Java 开发必备的开发工具。 Intellij IDEA - 业界简称IDEA，是 jetbrains 公司推出的和 Eclipse 齐名的 Java 集成开发环境（IDE）。 Apache Maven - Apache Maven，是一个软件项目管理及自动构建工具，由Apache软件基金会所提供。是 Java 构建打包最广泛使用的工具。 下载链接：https://pan.</description></item><item><title>Hadoop Part 4 - 搭建 Hadoop 开发环境</title><link>https://huangzhiyi.github.io/hadoop-c04/</link><pubDate>Thu, 01 Apr 2021 23:40:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-c04/</guid><description>«返回课程汇总页面
Hadoop Part 4 - 搭建 Hadoop 开发环境 【版本】 当前版本号v20210416
版本 修改说明 v20210416 修正一些拼写错误 v20210401 初始化版本
【实验名称】 Hadoop Part 4 - 搭建 Hadoop 开发环境
【实验目的】 掌握 JDK 的安装和环境变量的设置 掌握 IDEA 的安装和使用 掌握 Maven 的安装、配置和使用命令 【实验环境】 Windows 7 以上64位操作系统 【实验资源】 Hadoop JDK 8 - Java Development Kit是 Oracle 公司针对Java开发人员发布的免费软件开发工具包，是 Java 开发必备的开发工具。 Intellij IDEA - 业界简称IDEA，是 jetbrains 公司推出的和 Eclipse 齐名的 Java 集成开发环境（IDE）。 Apache Maven - Apache Maven，是一个软件项目管理及自动构建工具，由Apache软件基金会所提供。是 Java 构建打包最广泛使用的工具。 下载链接：https://pan.</description></item><item><title>Hadoop Part 3 - 通过Shell命令访问HDFS</title><link>https://huangzhiyi.github.io/hadoop-c03/</link><pubDate>Sun, 28 Mar 2021 00:44:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-c03/</guid><description>«返回课程汇总页面
Hadoop Part 3 - 通过Shell命令访问HDFS 【版本】 当前版本号v20210423
版本 修改说明 v20210423 修正步骤30 文件夹错误 v20210328 初始化版本
【实验名称】 Hadoop Part 3 - 通过Shell命令访问HDFS
【实验目的】 掌握 Web Console 访问 HDFS。 掌握常用的 Shell 命令访问 HDFS。 了解如何使用 IDEA 创建 Maven 工程、运行 Maven 工程。 了解通过 Java API 访问 HDFS。 【实验环境】 内存：至少4G 硬盘：至少空余40G 操作系统: CentOS 7.4 【实验资源】 XShell CentOS 7.</description></item><item><title>Hadoop Part 2 - 部署 Hadoop 完全分布模式</title><link>https://huangzhiyi.github.io/hadoop-c02/</link><pubDate>Fri, 19 Mar 2021 00:44:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-c02/</guid><description>«返回课程汇总页面
Hadoop Part 2 - 部署 Hadoop 完全分布模式 【版本】 当前版本号v20210415
版本 修改说明 v20210415 修改了虚拟机名称的描述避免误解为hostname v20210414 修改了步骤1，提示要使用hadoop用户进行登录 v20210408 新增配置到core-site.xml，修正jobhistoryserver意外退出的问题 v20210407-1 修正NodeB和NodeC的公钥操作 v20210407 修正authorized_keys 在 NodeB 和 NodeC 的操作 v20210406 修改了mapred-site.xml出现的配置错误；新增了把key写入 authorized_keys 步骤；增加了slaves的说明，避免出错； v20210319 初始化版本
【实验名称】 Hadoop Part 2 - 部署 Hadoop 完全分布模式
【实验目的】 掌握搭建 Hadoop 完全分布模式 熟练掌握Linux命令（vi、tar、mv等等）的使用 掌握VMWare、XShell等客户端的使用 【实验环境】 内存：至少4G 硬盘：至少空余40G 操作系统: 64位 Windows系统。 【实验资源】 XShell CentOS 7.</description></item><item><title>Hadoop Part 1 - 模板机制作</title><link>https://huangzhiyi.github.io/hadoop-c01/</link><pubDate>Sun, 14 Mar 2021 00:44:00 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-c01/</guid><description>«返回课程汇总页面
Hadoop Part 1 - 模板机制作 【版本】 当前版本号v20210423
版本 修改说明 v20210423 修正DNS的地址 v20210415 增加步骤66的命令 v20210402 修改步骤35，增加修改密码的命令 v20210331 修改步骤59，增加source命令 v20210314 初始化版本
【实验名称】 Hadoop Part 1 - 模板机制作
【实验目的】 掌握搭建 CentOS 模板镜像 熟练掌握Linux命令（vi、tar、mv等等）的使用 掌握VMWare、XShell等客户端的使用 【实验环境】 内存：至少4G 硬盘：至少空余40G 操作系统: 64位 Windows系统。 【实验资源】 XShell CentOS 7.4系统镜像 VMWare WorkStation Pro Hadoop 安装包 下载链接：https://pan.</description></item><item><title>Hadoop 课程资源汇总</title><link>https://huangzhiyi.github.io/hadoop-c-summary/</link><pubDate>Sun, 14 Mar 2021 00:42:51 +0800</pubDate><guid>https://huangzhiyi.github.io/hadoop-c-summary/</guid><description>实验报告模板资源下载 https://pan.baidu.com/s/1ghde86wcK6pwg1fdSSWg0w#提取码v3wv
实验报告要求 必须使用老师提供的实验报告模板。 必须保留封面 实验步骤每一步都有详细的文字操作步骤说明，步骤顺序号，截图。 截图只需要截关键部分信息，不能全屏截图。可以用红色框或箭头标注截图重点信息。推荐使用 Snipaste（官网下载或网盘下载） 进行截图和标记。 实验报告提交截止时间和地址 后续会公布链接，请各位同学登录网站 https://heis.gitee.io/hadoop-c-summary查看。
课程内容 （1）Hadoop Part 1 - 模板机制作 （2）Hadoop Part 2 - 部署 Hadoop 完全分布模式 （3）Hadoop Part 3 - HDFS 访问方式 （4）Hadoop Part 4 - 搭建 Hadoop 开发环境 （5）Hadoop Part 5 - HDFS Java 编程访问 （6）Hadoop Part 6 - 编写 MapReduce 程序 （7）Hadoop Part 7 - 部署 Hive 和 Hive 常用操作 （8）Hadoop Part 8 - 部署 HBase 和 HBase 常用操作(选做) （9）Hadoop Part 9 - 部署 ZooKeeper 和 ZooKeeper 常用操作(选做) （10）Hadoop Part 10 - Flume 和 Sqoop 操作实例(选做) 实验报告提交 （1）Hadoop Part 1 实验报告提交，截止日期：2021/4/11（周日） 19级计算机1班 http://xzc.</description></item></channel></rss>