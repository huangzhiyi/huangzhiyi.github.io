<!doctype html><html xmlns=http://www.w3.org/1999/xhtml xml:lang=zh-CN lang=zh-cn><head><link href=//gmpg.org/xfn/11 rel=profile><meta charset=utf-8><meta name=generator content="Hugo 0.80.0"><meta name=viewport content="width=device-width,initial-scale=1"><title>Hadoop Part 5 - HDFS Java 编程访问 &#183; Heis</title><link type=text/css rel=stylesheet href=https://huangzhiyi.github.io/css/heis-min.css?20210716><link type=text/css id=dark_theme_css rel=stylesheet href=https://huangzhiyi.github.io/css/a11y-dark.css title=dark><link type=text/css id=light_theme_css rel="alternate stylesheet" href=https://huangzhiyi.github.io/css/a11y-light.css title=light><script>var _hmt=_hmt||[];(function(){var hm=document.createElement("script");hm.src="https://hm.baidu.com/hm.js?f58b6a2675cf52000232edb4d109eccc";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();</script><link rel=apple-touch-icon-precomposed sizes=144x144 href=/apple-touch-icon-144-precomposed2.png><link rel="shortcut icon" href=/favicon2.png></head><body><style>.tooltip{position:relative;display:inline-block;border-bottom:1px dotted #000}.tooltip .tooltiptext{visibility:hidden;width:auto;max-width:200px;background-color:#000;color:#fff;text-align:center;position:absolute;z-index:1}.tooltip:hover .tooltiptext{visibility:visible;position:absolute;top:2rem;left:0;z-index:1000}</style><aside class=sidebar id=bsidebar><button id=hide-sb-btn onclick=hideSidebar()></button><div class="container sidebar-sticky"><div class=sidebar-about><a href=https://huangzhiyi.github.io/><h1 id=side-title>Heis</h1></a><p class=lead>Long live MAMBA</p><p class=ac><a href=https://support.qq.com/products/332688 class=tooltip target=_blank><img class=tooltiptext src=https://huangzhiyi.github.io/feedback.png?20210617>
提点意见和建议»</a></p></div><nav><ul class=sidebar-nav><li><a href=https://huangzhiyi.github.io/>首页</a></li><li><a href=http://go.heisun.xyz/ target=_blank>课程导航»</a></li><li><a href=https://huangzhiyi.github.io/categories/javaweb/>Java后台应用项目开发»</a></li><li><a href=https://huangzhiyi.github.io/categories/clouddc/>云数据中心基础»</a></li><li><a href=https://huangzhiyi.github.io/categories>文章分类»</a></li><li><a href=https://huangzhiyi.github.io/tags>文章标签»</a></li><li><a href=https://heis.gitee.io/ target=_blank>镜像0：heis.gitee.io</a></li><li><a href=http://heisun.xyz/ target=_blank>镜像1：heisun.xyz</a></li><li><a href=https://huangzhiyi.github.io/ target=_blank>镜像2：huangzhiyi.github.io</a></li></ul></nav><p>&copy; 2021. All rights reserved.</p><p></p></div></aside><main class="content container" id=mainpanel><button id=show-sb-btn onclick=showSidebar()></button>
<script src=https://huangzhiyi.github.io/js/jquery-min.js></script><div class=post><h1>Hadoop Part 5 - HDFS Java 编程访问</h1><time datetime=2021-04-03T23:20:00+0800 class=post-date>2021-04-03</time><blockquote><h2>文章导航</h2><aside><nav id=TableOfContents><ul><li><a href=#hadoop-part-5---hdfs-java-编程访问>Hadoop Part 5 - HDFS Java 编程访问</a><ul><li><a href=#版本>【版本】</a></li><li><a href=#实验名称>【实验名称】</a></li><li><a href=#实验目的>【实验目的】</a></li><li><a href=#实验环境>【实验环境】</a></li><li><a href=#实验资源>【实验资源】</a></li><li><a href=#实验参考>【实验参考】</a></li><li><a href=#实验步骤>【实验步骤】</a></li><li><a href=#报错null-entry-in-command-string>报错：(null) entry in command string</a></li></ul></li></ul></nav></aside></blockquote><p><a href=/hadoop-c-summary/>«返回课程汇总页面</a></p><h2 id=hadoop-part-5---hdfs-java-编程访问>Hadoop Part 5 - HDFS Java 编程访问</h2><h3 id=版本>【版本】</h3><p>当前版本号<code>v20210430</code></p><div class=tbl-start></div><table><thead><tr><th>版本</th><th>修改说明</th></tr></thead><tbody><tr><td>v20210430</td><td>修正 HdfsUtils 类名错误</td></tr><tr><td>v20210404</td><td>增加常见问题</td></tr><tr><td>v20210403</td><td>初始化版本</td></tr></tbody></table><div class=tbl-end style=height:10px></div><h3 id=实验名称>【实验名称】</h3><p>Hadoop Part 5 - HDFS Java 编程访问</p><h3 id=实验目的>【实验目的】</h3><ul><li>掌握 HDFS 文件系统的 Java 编程接口的调用和编程</li></ul><h3 id=实验环境>【实验环境】</h3><ul><li>Windows 7 以上64位操作系统</li></ul><h3 id=实验资源>【实验资源】</h3><ul><li>Hadoop</li><li><a href=https://www.oracle.com/java/technologies/javase-downloads.html target=_blank>JDK 8</a> - Java Development Kit是 Oracle 公司针对Java开发人员发布的免费软件开发工具包，是 Java 开发必备的开发工具。</li><li><a href=https://www.jetbrains.com/idea/ target=_blank>Intellij IDEA</a> - 业界简称IDEA，是 jetbrains 公司推出的和 Eclipse 齐名的 Java 集成开发环境（IDE）。</li><li><a href=https://maven.apache.org/ target=_blank>Apache Maven</a> - Apache Maven，是一个软件项目管理及自动构建工具，由Apache软件基金会所提供。是 Java 构建打包最广泛使用的工具。</li></ul><pre><code>下载链接：https://pan.baidu.com/s/1ghde86wcK6pwg1fdSSWg0w
提取码：v3wv
</code></pre><h3 id=实验参考>【实验参考】</h3><p>类 org.apache.hadoop.fs.FileSystem 的 <a href=https://hadoop.apache.org/docs/r2.7.3/api/org/apache/hadoop/fs/FileSystem.html>参考文档</a></p><h3 id=实验步骤>【实验步骤】</h3><ol><li><p>打开 Part 4 的 hadoopexp 项目。</p></li><li><p>在项目<code>hadoop-exp\src\main\java</code>下创建一个名为<code>hadoop+你学号后4位.hdfs</code>的包。注意替换为你的学号后4位。</p></li><li><p>在包下面新建一个 HdfsUtils 的类。该类包含了一个在HDFS上创建文件并写入内容的方法<code>createFile</code>。代码如下，注意替换为你的学号后4位。</p></li></ol><pre><code>package hadoop你学号后4位.hdfs;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;

import java.io.IOException;
import java.net.URI;

public class HdfsUtils {

    /**
     * 在HDFS上创建文件并写入内容
     * @param conf HDFS的配置
     * @param hdfsFilePath HDFS创建的文件的路径
     * @param content 写入文件的内容
     * @param overwrite true表示覆盖原文件，false表示不覆盖
     */
    public static boolean createFile(Configuration conf,URI uri,String hdfsFilePath,String content,boolean overwrite) {
        FileSystem fs=null;
        FSDataOutputStream os=null;
        boolean rs=false;
        try {
            // 指定用户名 , 获取 FileSystem 对象
            fs = FileSystem.get(uri, conf, &quot;hadoop&quot;);
            //定义文件路径
            Path dfs = new Path(hdfsFilePath);
            os = fs.create(dfs, overwrite);
            //往文件写入信息
            os.writeBytes(content);
            //成功创建文件，设置为true
            rs=true;
        }catch(Exception e){
            e.printStackTrace();
        }finally {
            try {
                if(os!=null) {
                    // 关闭流
                    os.close();
                }
                if(fs!=null) {
                    // 不需要再操作 FileSystem 了，关闭
                    fs.close();
                }
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
        return rs;
    }
}
</code></pre><ol start=4><li><p>在项目<code>hadoop-exp\src\test\java</code>下创建一个名为<code>hadoop+你学号后4位.hdfs</code>的包。注意替换为你的学号后4位。</p></li><li><p>在包下面新建一个 HdfsUtilsTest 的类，用于单元测试。代码如下，注意替换为你的学号后4位。此测试用例主要目的是在 HDFS 上创建一个文件，并把 “hello” 写入文件。</p></li></ol><pre><code>package hadoop替换为你学号后4位.hdfs;

import hadoop替换为你学号后4位.hdfs.HdfsUtils;
import org.apache.hadoop.conf.Configuration;
import org.junit.Test;

import java.net.URI;

public class HdfsUtilsTest {
    @Test
    public void testCreate() {
        Configuration conf=new Configuration();
        boolean rs=false;
        //创建的文件路径
        String filePath=&quot;/替换为你学号后4位/test.txt&quot;;
        String content=&quot;hello&quot;;
        try {
            URI uri = new URI(&quot;hdfs://10.0.0.71:8020&quot;);
            rs= HdfsUtils.createFile(conf, uri, filePath, content, true);
        }catch(Exception e){
            e.printStackTrace();
        }
        if(rs){
            System.out.println(&quot;Create successfully!&quot;);
        }else{
            System.out.println(&quot;Create fail!&quot;);
        }
    }
}
</code></pre><ol start=6><li><p>复制文件 hadoop.dll 到 C:\Windows\System32 下。</p></li><li><p>启动虚拟机的 Hadoop。</p></li><li><p>运行HdfsUtilsTest。查看 IDEA 的控制台输出结果是否创建成功。</p></li><li><p>SSH 登录 NodeA，运行以下命令查看创建文件的内容输出。是否和创建的文件内容一致。注意替换为你的学号后4位。</p></li></ol><pre><code>hdfs dfs -cat /替换为你学号后4位/test.txt
</code></pre><ol start=10><li>参考以上代码和【实验参考】给出的 API 文档，完成以下编程要求</li></ol><ul><li>（1）在<code>HdfsUtils</code>类新增一个<code>uploadFile</code>方法，可以上传本地文件到 HDFS。</li><li>（2）在<code>HdfsUtilsTest</code>类新增一个<code>testUpload</code>方法，测试上传文件到 HDFS。</li><li>（3）在<code>HdfsUtils</code>类新增一个<code>dowloadFile</code>方法，可以下载 HDFS 文件到本地。</li><li>（4）在<code>HdfsUtilsTest</code>类新增一个<code>testDownload</code>方法，测试下载 HDFS 文件到本地。</li></ul><p>##【常见问题】</p><h3 id=报错null-entry-in-command-string>报错：(null) entry in command string</h3><p>这是缺少文件hadoop.dll文件
1、下载hadoop.dll文件
2、把文件放在:\windows\system32目录下</p></div><button id=scroll-top-btn>↑顶部</button>
<button id=switch-theme-btn>换主题</button><div id=outerdiv style=position:fixed;top:0;left:0;background:rgba(0,0,0,.7);z-index:2;width:100%;height:100%;display:none><div id=innerdiv style=position:absolute><img id=bigimg style="border:5px solid #fff" src></div></div><div id=category style=display:none;position:fixed;right:10px;bottom:10px;width:10em></div><script src=https://huangzhiyi.github.io/js/highlight.pack.js></script><script src=https://huangzhiyi.github.io/js/highlightjs-line-numbers.min.js></script><script>hljs.initHighlightingOnLoad();hljs.initLineNumbersOnLoad();$(function(){let curTheme=getCookie("theme");if(curTheme===""){setTheme("dark");}else{setTheme(curTheme);}
$('div.tbl-start').nextUntil('div.tbl-end','table').addClass('tbl');$("img").click(function(){var _this=$(this);imgShow("#outerdiv","#innerdiv","#bigimg",_this);});$("#scroll-top-btn").click(function(){document.body.scrollTop=document.documentElement.scrollTop=0;});$("#switch-theme-btn").click(function(){switchTheme();})});</script><script src=https://huangzhiyi.github.io/js/clipboard.min.js></script><script src=https://huangzhiyi.github.io/js/codecopy.bundle.js?20210612></script></main><script src=https://huangzhiyi.github.io/js/jquery-min.js></script><script src=https://huangzhiyi.github.io/js/heis-custom-min.js?211029></script></body></html>