<!doctype html><html xmlns=http://www.w3.org/1999/xhtml xml:lang=zh-CN lang=zh-cn><head><link href=//gmpg.org/xfn/11 rel=profile><meta charset=utf-8><meta name=generator content="Hugo 0.80.0"><meta name=viewport content="width=device-width,initial-scale=1"><title>Hadoop Part 7 - 部署 Hive 和 Hive 常用操作 &#183; Heis</title><link type=text/css rel=stylesheet href=https://huangzhiyi.github.io/css/heis-min.css?20210716><script>var _hmt=_hmt||[];(function(){var hm=document.createElement("script");hm.src="https://hm.baidu.com/hm.js?f58b6a2675cf52000232edb4d109eccc";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();</script><link rel=apple-touch-icon-precomposed sizes=144x144 href=/apple-touch-icon-144-precomposed2.png><link rel="shortcut icon" href=/favicon2.png></head><body><style>.tooltip{position:relative;display:inline-block;border-bottom:1px dotted #000}.tooltip .tooltiptext{visibility:hidden;width:auto;max-width:200px;background-color:#000;color:#fff;text-align:center;position:absolute;z-index:1}.tooltip:hover .tooltiptext{visibility:visible;position:absolute;top:2rem;left:0;z-index:1000}</style><aside class=sidebar id=bsidebar><button id=hide-sb-btn onclick=hideSidebar()></button><div class="container sidebar-sticky"><div class=sidebar-about><a href=https://huangzhiyi.github.io/><h1 id=side-title>Heis</h1></a><p class=lead>Long live MAMBA</p><p class=ac><a href=https://support.qq.com/products/332688 class=tooltip target=_blank><img class=tooltiptext src=https://huangzhiyi.github.io/feedback.png?20210617>
提点意见和建议»</a></p></div><nav><ul class=sidebar-nav><li><a href=https://huangzhiyi.github.io/>首页</a></li><li><a href=http://go.heisun.xyz/ target=_blank>课程导航»</a></li><li><a href=https://huangzhiyi.github.io/categories/javaweb/>Java后台应用项目开发»</a></li><li><a href=https://huangzhiyi.github.io/categories/clouddc/>云数据中心基础»</a></li><li><a href=https://huangzhiyi.github.io/categories>文章分类»</a></li><li><a href=https://huangzhiyi.github.io/tags>文章标签»</a></li><li><a href=https://heis.gitee.io/ target=_blank>镜像0：heis.gitee.io</a></li><li><a href=http://heisun.xyz/ target=_blank>镜像1：heisun.xyz</a></li><li><a href=https://huangzhiyi.github.io/ target=_blank>镜像2：huangzhiyi.github.io</a></li></ul></nav><p>&copy; 2021. All rights reserved.</p><p></p></div></aside><main class="content container" id=mainpanel><button id=show-sb-btn onclick=showSidebar()></button>
<script src=https://huangzhiyi.github.io/js/jquery-min.js></script><div class=post><h1>Hadoop Part 7 - 部署 Hive 和 Hive 常用操作</h1><time datetime=2021-04-16T23:20:00+0800 class=post-date>2021-04-16</time><blockquote><h2>文章导航</h2><aside><nav id=TableOfContents><ul><li><ul><li><a href=#版本>【版本】</a></li></ul></li><li><a href=#实验71----部署-hive>实验7.1 - 部署 Hive</a><ul><li><a href=#实验名称>【实验名称】</a></li><li><a href=#实验目的>【实验目的】</a></li><li><a href=#实验环境>【实验环境】</a></li><li><a href=#实验资源>【实验资源】</a></li><li><a href=#实验步骤>【实验步骤】</a></li></ul></li><li><a href=#实验72----使用-hive-进行简单分析>实验7.2 - 使用 Hive 进行简单分析</a><ul><li><a href=#实验名称-1>【实验名称】</a></li><li><a href=#实验目的-1>【实验目的】</a></li><li><a href=#实验环境-1>【实验环境】</a></li><li><a href=#实验资源-1>【实验资源】</a></li><li><a href=#实验步骤-1>【实验步骤】</a></li></ul></li><li><a href=#常见问题>【常见问题】</a></li></ul></nav></aside></blockquote><p><a href=/hadoop-c-summary/>«返回课程汇总页面</a></p><h3 id=版本>【版本】</h3><p>当前版本号<code>v20210527</code></p><div class=tbl-start></div><table><thead><tr><th>版本</th><th>修改说明</th></tr></thead><tbody><tr><td>v20210527</td><td>修改hive-site.xml的配置</td></tr><tr><td>v20210416</td><td>初始化版本</td></tr></tbody></table><div class=tbl-end style=height:10px></div><h2 id=实验71----部署-hive>实验7.1 - 部署 Hive</h2><h3 id=实验名称>【实验名称】</h3><p>实验7.1 - 部署 Hive</p><h3 id=实验目的>【实验目的】</h3><ul><li>掌握部署 Hive</li></ul><h3 id=实验环境>【实验环境】</h3><ul><li>Windows 7 以上64位操作系统</li><li>JDK8</li><li>IDEA</li><li>Hadoop 2.7.3</li><li>CentOS 7</li><li>MariaDB/MySQL</li></ul><h3 id=实验资源>【实验资源】</h3><ul><li>Hadoop</li></ul><pre><code>下载链接：https://pan.baidu.com/s/1ghde86wcK6pwg1fdSSWg0w 
提取码：v3wv 
</code></pre><h3 id=实验步骤>【实验步骤】</h3><ol><li>使用 hadoop 登录NodeA节点。</li></ol><pre><code>su hadoop
</code></pre><ol start=2><li>Hive 的安装需要依赖 MySQL 或 MariaDB，这里我们选择 MariaDB。这里需要提权安装，如果安装失败请检查源配置文件<code>/etc/yum.repos.d/local.repo</code>或者光盘是否挂载成功。</li></ol><pre><code>sudo yum install mariadb mariadb-server
</code></pre><ol start=3><li>启动 MariaDB 并设置为开机启动。</li></ol><pre><code>sudo systemctl start mariadb
sudo systemctl enable mariadb
</code></pre><ol start=4><li>使用 MariaDB 的安全安装选项。</li></ol><pre><code>mysql_secure_installation
</code></pre><p>以下为弹出选项的输入值</p><pre><code>Enter current password for root (enter for none): 回车
Set root password? [Y/n] Y
New password: 123456
Re-enter new password:123456
Remove anonymous users? [Y/n] Y
Disallow root login remotely? [Y/n] Y
Remove test database and access to it? [Y/n] Y
Reload privilege tables now? [Y/n] Y
</code></pre><ol start=5><li>测试使用 root 账户登录 MariaDB。密码为<code>123456</code></li></ol><pre><code>mysql -u root -p
</code></pre><ol start=6><li>登录进入 MariaDB 以后。执行以下SQL</li></ol><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=color:#75715e>-- 创建 hive 数据库
</span><span style=color:#75715e></span><span style=color:#66d9ef>create</span> <span style=color:#66d9ef>database</span> hive CHARACTER <span style=color:#66d9ef>SET</span> utf8 <span style=color:#66d9ef>COLLATE</span> utf8_general_ci;
<span style=color:#75715e>-- 创建 hive 用户并授权
</span><span style=color:#75715e></span><span style=color:#66d9ef>create</span> <span style=color:#66d9ef>user</span> <span style=color:#e6db74>&#39;hive&#39;</span><span style=color:#f92672>@</span><span style=color:#e6db74>&#39;localhost&#39;</span> identified <span style=color:#66d9ef>by</span> <span style=color:#e6db74>&#39;hive123456&#39;</span>;
<span style=color:#66d9ef>create</span> <span style=color:#66d9ef>user</span> <span style=color:#e6db74>&#39;hive&#39;</span><span style=color:#f92672>@</span><span style=color:#e6db74>&#39;%&#39;</span> identified <span style=color:#66d9ef>by</span> <span style=color:#e6db74>&#39;hive123456&#39;</span>;
<span style=color:#66d9ef>grant</span> <span style=color:#66d9ef>all</span> <span style=color:#66d9ef>on</span> hive.<span style=color:#f92672>*</span> <span style=color:#66d9ef>to</span> <span style=color:#e6db74>&#39;hive&#39;</span><span style=color:#f92672>@</span><span style=color:#e6db74>&#39;localhost&#39;</span>;
<span style=color:#66d9ef>grant</span> <span style=color:#66d9ef>all</span> <span style=color:#66d9ef>on</span> hive.<span style=color:#f92672>*</span> <span style=color:#66d9ef>to</span> <span style=color:#e6db74>&#39;hive&#39;</span><span style=color:#f92672>@</span><span style=color:#e6db74>&#39;%&#39;</span>;
exit
</code></pre></div><ol start=7><li>退出 MariaDB 命令行，使用 hive 用户进行登录，登录以后查看是否有 hive 这个库。</li></ol><pre><code>mysql hive -uhive -p
</code></pre><ol start=8><li>退出 MariaDB 命令行，切换到系统 root 用户。</li></ol><pre><code>su
</code></pre><ol start=9><li>增加 Hive 相关环境变量设置。</li></ol><ul><li>需要root权限执行</li></ul><pre><code>echo &quot;export HIVE_HOME=/opt/hive
export PATH=\$HIVE_HOME/bin:\$PATH&quot; &gt;&gt;/etc/profile
</code></pre><ol start=10><li>新增 MariaDB 配置。</li></ol><ul><li>需要root权限执行</li></ul><pre><code>echo '[client]
default-character-set=utf8
[mysqld]
bind-address = 0.0.0.0
default-storage-engine = innodb
innodb_file_per_table
max_connections = 4096
collation-server = utf8_general_ci
character-set-server = utf8
wait_timeout = 600
max_allowed_packet = 64M
sql_mode=NO_BACKSLASH_ESCAPES
[mysql]
default-character-set=utf8'  &gt;/etc/my.cnf.d/hive.cnf
</code></pre><ol start=11><li>切换到系统 hadoop 用户。</li></ol><pre><code>su hadoop
</code></pre><ol start=12><li>查看环境变量的输出是否正确。</li></ol><pre><code>source /etc/profile
echo $HIVE_HOME
</code></pre><p>应该输出</p><pre><code>/opt/hive
</code></pre><ol start=12><li>重启 MariaDB。</li></ol><pre><code>sudo systemctl restart mariadb
</code></pre><ol start=13><li>查看进程和端口是否正常。</li></ol><pre><code>sudo netstat -tulpn|grep mysql
</code></pre><p>正常会输出进程信息，类似以下内容：</p><pre><code>tcp  0   0 0.0.0.0:3306  0.0.0.0:* LISTEN  2152/mysqld
</code></pre><ol start=14><li>使用 hadoop 用户上传 Hive 安装文件<code>apache-hive-2.3.8-bin.tar.gz</code>到 /home/hadoop 并解压。</li></ol><pre><code>cd ~
tar -xvf apache-hive-2.3.8-bin.tar.gz
</code></pre><ol start=15><li>创建 hive 安装目录，并拷贝文件到安装目录。</li></ol><pre><code>sudo mkdir -p /opt/hive
sudo chown hadoop:wheel /opt/hive
mv ~/apache-hive-2.3.8-bin/* /opt/hive
</code></pre><ol start=16><li><p>上传 MariaDB 驱动<code>mariadb-java-client-2.7.2.jar</code>到 /opt/hive/lib/ 目录下。</p></li><li><p>编辑 Hive 的配置文件。</p></li></ol><pre><code>cd /opt/hive/conf/
vi hive-site.xml
</code></pre><ol start=18><li>加入以下内容。</li></ol><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-xml data-lang=xml><span style=color:#75715e>&lt;?xml version=&#34;1.0&#34; encoding=&#34;utf-8&#34; standalone=&#34;no&#34;?&gt;</span>
<span style=color:#75715e>&lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&gt;</span>
<span style=color:#f92672>&lt;configuration&gt;</span>
  <span style=color:#75715e>&lt;!-- 数据库连接 --&gt;</span>
  <span style=color:#f92672>&lt;property&gt;</span>
    <span style=color:#f92672>&lt;name&gt;</span>javax.jdo.option.ConnectionURL<span style=color:#f92672>&lt;/name&gt;</span>
    <span style=color:#f92672>&lt;value&gt;</span>jdbc:mysql://localhost:3306/hive?useSSL=false<span style=color:#f92672>&lt;/value&gt;</span>
  <span style=color:#f92672>&lt;/property&gt;</span>
  <span style=color:#75715e>&lt;!-- 数据库驱动名 --&gt;</span>
  <span style=color:#f92672>&lt;property&gt;</span>
    <span style=color:#f92672>&lt;name&gt;</span>javax.jdo.option.ConnectionDriverName<span style=color:#f92672>&lt;/name&gt;</span>
    <span style=color:#f92672>&lt;value&gt;</span>org.mariadb.jdbc.Driver<span style=color:#f92672>&lt;/value&gt;</span>
  <span style=color:#f92672>&lt;/property&gt;</span>
  <span style=color:#75715e>&lt;!-- 数据库用户名 --&gt;</span>
  <span style=color:#f92672>&lt;property&gt;</span>
    <span style=color:#f92672>&lt;name&gt;</span>javax.jdo.option.ConnectionUserName<span style=color:#f92672>&lt;/name&gt;</span>
    <span style=color:#f92672>&lt;value&gt;</span>hive<span style=color:#f92672>&lt;/value&gt;</span>
  <span style=color:#f92672>&lt;/property&gt;</span>
  <span style=color:#75715e>&lt;!-- 数据库用户密码 --&gt;</span>
  <span style=color:#f92672>&lt;property&gt;</span>
    <span style=color:#f92672>&lt;name&gt;</span>javax.jdo.option.ConnectionPassword<span style=color:#f92672>&lt;/name&gt;</span>
    <span style=color:#f92672>&lt;value&gt;</span>hive123456<span style=color:#f92672>&lt;/value&gt;</span>
  <span style=color:#f92672>&lt;/property&gt;</span>
  <span style=color:#75715e>&lt;!-- 不校验 Schema --&gt;</span>
  <span style=color:#f92672>&lt;property&gt;</span>
    <span style=color:#f92672>&lt;name&gt;</span>hive.metastore.schema.verification<span style=color:#f92672>&lt;/name&gt;</span>
    <span style=color:#f92672>&lt;value&gt;</span>false<span style=color:#f92672>&lt;/value&gt;</span>
  <span style=color:#f92672>&lt;/property&gt;</span>
  <span style=color:#75715e>&lt;!-- 显示表名 --&gt;</span>
  <span style=color:#f92672>&lt;property&gt;</span>
    <span style=color:#f92672>&lt;name&gt;</span>hive.cli.print.current.db<span style=color:#f92672>&lt;/name&gt;</span>
    <span style=color:#f92672>&lt;value&gt;</span>true<span style=color:#f92672>&lt;/value&gt;</span>
  <span style=color:#f92672>&lt;/property&gt;</span>
  <span style=color:#75715e>&lt;!-- 显示表头 --&gt;</span>
  <span style=color:#f92672>&lt;property&gt;</span>
    <span style=color:#f92672>&lt;name&gt;</span>hive.cli.print.header<span style=color:#f92672>&lt;/name&gt;</span>
    <span style=color:#f92672>&lt;value&gt;</span>true<span style=color:#f92672>&lt;/value&gt;</span>
  <span style=color:#f92672>&lt;/property&gt;</span>
  <span style=color:#75715e>&lt;!-- 表头不显示表名 --&gt;</span>
  <span style=color:#f92672>&lt;property&gt;</span>
    <span style=color:#f92672>&lt;name&gt;</span>hive.resultset.use.unique.column.names<span style=color:#f92672>&lt;/name&gt;</span>
    <span style=color:#f92672>&lt;value&gt;</span>false<span style=color:#f92672>&lt;/value&gt;</span>
  <span style=color:#f92672>&lt;/property&gt;</span>
<span style=color:#f92672>&lt;/configuration&gt;</span>
</code></pre></div><ol start=19><li>初始化 Hive 的 Schema。</li></ol><pre><code>schematool -dbType mysql -initSchema
</code></pre><ol start=20><li>检查 MariaDB 的 hive 库里是否有表。</li></ol><pre><code>mysql hive -uhive -phive123456
show tables
exit
</code></pre><ol start=21><li>启动 Hadoop。</li></ol><pre><code>start-hdp.sh
</code></pre><ol start=22><li>启动 Hive</li></ol><pre><code>hive
</code></pre><ol start=23><li>查看所有数据库</li></ol><pre><code>hive&gt; show databases;
</code></pre><h2 id=实验72----使用-hive-进行简单分析>实验7.2 - 使用 Hive 进行简单分析</h2><h3 id=实验名称-1>【实验名称】</h3><p>实验7.2 - 部署 Hive</p><h3 id=实验目的-1>【实验目的】</h3><ul><li>掌握使用 HiveQL 进行数据分析</li></ul><h3 id=实验环境-1>【实验环境】</h3><ul><li>Windows 7 以上64位操作系统</li><li>JDK8</li><li>IDEA</li><li>Hadoop 2.7.3</li><li>CentOS 7</li><li>MariaDB/MySQL</li><li>Hive 2.x</li></ul><h3 id=实验资源-1>【实验资源】</h3><ul><li>Hadoop</li><li>Hive</li><li>部门数据 dept.csv</li><li>员工数据 emp.csv</li></ul><pre><code>下载链接：https://pan.baidu.com/s/1ghde86wcK6pwg1fdSSWg0w 
提取码：v3wv 
</code></pre><h3 id=实验步骤-1>【实验步骤】</h3><ol><li><p>启动 Hadoop。</p></li><li><p>上传<code>dept.csv</code>和<code>emp.csv</code>到 Linux 系统。将实验环境提到的源数据的两张表复制到 HDFS 的/exp7 目录下。</p></li></ol><pre><code>hdfs dfs -mkdir -p /exp7
hdfs dfs -put dept.csv /exp7
hdfs dfs -put emp.csv /exp7
</code></pre><ol start=3><li>启动 Hive</li></ol><pre><code>hive
</code></pre><ol start=4><li>创建员工表，注意替换为你的学号后4位。</li></ol><pre><code>hive&gt; create table emp你的学号后4位(empno int,ename string,job string,mgr int,hiredate string,sal int,comm int,deptno int) row format delimited fields terminated by ',';
</code></pre><ol start=5><li>创建部门表，注意替换为你的学号后4位。</li></ol><pre><code>hive&gt; create table dept你的学号后4位(deptno int,dname string,loc string) row format delimited fields terminated by ',';
</code></pre><ol start=6><li>导入数据。</li></ol><pre><code>hive&gt; load data inpath '/exp7/emp.csv' into table emp你的学号后4位;
hive&gt; load data inpath '/exp7/dept.csv' into table dept你的学号后4位;
</code></pre><ol start=7><li>根据员工的部门号创建分区，表名为<code>emp_part+学号后4位</code>。</li></ol><pre><code>hive&gt; create table emp_part你的学号后4位(empno int,ename string,job string,mgr int,hiredate string,sal int,comm int)partitioned by (deptno int)row format delimited fields terminated by ',';
</code></pre><ol start=8><li>向分区表插入数据：指明导入的数据的分区（通过子查询导入数据）。</li></ol><pre><code>hive&gt; insert into table emp_part你的学号后4位 partition(deptno=10) select empno,ename,job,mgr,hiredate,sal,comm from emp你的学号后4位 where deptno=10;
hive&gt; insert into table emp_part你的学号后4位 partition(deptno=20) select empno,ename,job,mgr,hiredate,sal,comm from emp你的学号后4位 where deptno=20;
hive&gt; insert into table emp_part你的学号后4位 partition(deptno=30) select empno,ename,job,mgr,hiredate,sal,comm from emp你的学号后4位 where deptno=30;
</code></pre><ol start=9><li>创建一个桶表，表名为<code>emp_bucket+学号后4位</code>，根据员工的职位（job）进行分桶。</li></ol><pre><code>hive&gt; create table emp_bucket你的学号后4位(empno int,ename string,job string,mgr int,hiredate string,sal int,comm int,deptno int)clustered by (job) into 4 buckets row format delimited fields terminated by ',';
</code></pre><ol start=10><li>通过子查询插入数据：</li></ol><pre><code>hive&gt; insert into emp_bucket你的学号后4位 select * from emp你的学号后4位;
</code></pre><ol start=11><li>独立完成以下 HiveQL 查询。记录下你的 HiveQL。</li></ol><ul><li>（1）查询所有的员工信息。
期望结果：</li></ul><pre><code>empno	ename	job	    mgr	 hiredate	sal	comm	deptno
7369	SMITH	CLERK	7902	1980/12/17	800	NULL	20
7499	ALLEN	SALESMAN	7698	1981/2/20	1600	300	30
7521	WARD	SALESMAN	7698	1981/2/22	1250	500	30
7566	JONES	MANAGER	7839	1981/4/2	2975	NULL	20
7654	MARTIN	SALESMAN	7698	1981/9/28	1250	1400	30
7698	BLAKE	MANAGER	7839	1981/5/1	2850	NULL	30
7782	CLARK	MANAGER	7839	1981/6/9	2450	NULL	10
7788	SCOTT	ANALYST	7566	1987/4/19	3000	NULL	20
7839	KING	PRESIDENT	NULL	1981/11/17	5000	NULL	10
7844	TURNER	SALESMAN	7698	1981/9/8	1500	0	30
7876	ADAMS	CLERK	7788	1987/5/23	1100	NULL	20
7900	JAMES	CLERK	7698	1981/12/3	950	NULL	30
7902	FORD	ANALYST	7566	1981/12/3	3000	NULL	20
7934	MILLER	CLERK	7782	1982/1/23	1300	NULL	10
</code></pre><ul><li>（2）<code>查询员工信息</code>：查询员工姓名为<code>BLAKE</code>的员工号、姓名和薪水。</li></ul><p>期望结果：</p><pre><code>empno	ename	sal
7698	BLAKE	2850
</code></pre><ul><li>（3）<code>多表关联查询</code>：关联查询<code>emp</code>表和<code>dept</code>表中所有员工部门名称、员工姓名，并按部门名称排序。</li></ul><p>期望结果：</p><pre><code>dname	ename
ACCOUNTING	MILLER
ACCOUNTING	KING
ACCOUNTING	CLARK
RESEARCH	ADAMS
RESEARCH	SCOTT
RESEARCH	SMITH
RESEARCH	JONES
RESEARCH	FORD
SALES	TURNER
SALES	ALLEN
SALES	BLAKE
SALES	MARTIN
SALES	WARD
SALES	JAMES
</code></pre><ul><li>（4）<code>分区表关联查询</code>：关联查询<code>emp_part</code>表和<code>dept</code>表，找到员工部门是10和20的部门名称和员工姓名，并按部门名称排序。</li></ul><p>期望结果：</p><pre><code>dname	ename
ACCOUNTING	MILLER
ACCOUNTING	KING
ACCOUNTING	CLARK
RESEARCH	FORD
RESEARCH	ADAMS
RESEARCH	SCOTT
RESEARCH	JONES
RESEARCH	SMITH
</code></pre><ul><li>（5）<code>桶表关联查询</code>：关联查询<code>emp_bucket</code>表和<code>dept</code>表，找到员工部门是20和30的部门名称和部门下员工的数量。</li></ul><p>期望结果：</p><pre><code>dname	no
RESEARCH	5
SALES	6
</code></pre><ul><li>（6）查询各个部门的总薪水。</li></ul><p>期望结果：</p><pre><code>dname	sumsal
ACCOUNTING	8750
RESEARCH	10875
SALES	9400
</code></pre><ul><li>（7）根据职位给员工涨工资，并把涨前、涨后的薪水显示出来。</li></ul><div class=tbl-start></div><table><thead><tr><th>职位</th><th>薪水变化</th></tr></thead><tbody><tr><td>PRESIDENT</td><td>+1000</td></tr><tr><td>MANAGER</td><td>+800</td></tr><tr><td>其他</td><td>+400</td></tr></tbody></table><div class=tbl-end style=height:10px></div><p>期望结果：</p><pre><code>empno	ename	job	sal_before	sal_after
7369	SMITH	CLERK	800	1200
7499	ALLEN	SALESMAN	1600	2000
7521	WARD	SALESMAN	1250	1650
7566	JONES	MANAGER	2975	3775
7654	MARTIN	SALESMAN	1250	1650
7698	BLAKE	MANAGER	2850	3650
7782	CLARK	MANAGER	2450	3250
7788	SCOTT	ANALYST	3000	3400
7839	KING	PRESIDENT	5000	6000
7844	TURNER	SALESMAN	1500	1900
7876	ADAMS	CLERK	1100	1500
7900	JAMES	CLERK	950	1350
7902	FORD	ANALYST	3000	3400
7934	MILLER	CLERK	1300	1700
</code></pre><h2 id=常见问题>【常见问题】</h2></div><button id=scroll-top-btn>↑顶部</button><div id=outerdiv style=position:fixed;top:0;left:0;background:rgba(0,0,0,.7);z-index:2;width:100%;height:100%;display:none><div id=innerdiv style=position:absolute><img id=bigimg style="border:5px solid #fff" src></div></div><div id=category style=display:none;position:fixed;right:10px;bottom:10px;width:10em></div><script src=https://huangzhiyi.github.io/js/highlight.pack.js></script><script src=https://huangzhiyi.github.io/js/highlightjs-line-numbers.min.js></script><script>hljs.initHighlightingOnLoad();hljs.initLineNumbersOnLoad();$(function(){$('div.tbl-start').nextUntil('div.tbl-end','table').addClass('tbl');$("img").click(function(){var _this=$(this);imgShow("#outerdiv","#innerdiv","#bigimg",_this);});$("#scroll-top-btn").click(function(){document.body.scrollTop=document.documentElement.scrollTop=0;});});$(function(){var notdefault=0;$('.post').find('h1,h2').each(function(index,item){notdefault=1;$(this).attr('id','c'+index);var headerText=$(this).text();var tagName=$(this)[0].tagName.toLowerCase();var tagIndex=parseInt(tagName.charAt(1));if(tagIndex==1)
$('#category').append($('<a name="c'+index+'"  class="cbtn article-ch'+tagIndex+'" >'+headerText+'</a>'));else
$('#category').append($('<a name="c'+index+'"  class="cbtn article-ch'+tagIndex+'" > '+headerText+'</a>'));});if(notdefault==0){$('#c-default').css('display','block');}
var navH=$(".post").offset().top;$(window).scroll(function(){var scroH=$(this).scrollTop();if(scroH>=navH){$("#category-ct").css({position:'fixed'});$("#category-ct").animate({top:'30px'},1000);}
else{$("#category-ct").css({position:'static',top:'0px'});}});$(document).on('click','.cbtn',function(e){$('html,body').animate({scrollTop:$("#"+this.name).offset().top},500);});});</script><script src=https://huangzhiyi.github.io/js/clipboard.min.js></script><script src=https://huangzhiyi.github.io/js/codecopy.bundle.js?20210612></script></main><script src=https://huangzhiyi.github.io/js/jquery-min.js></script><script src=https://huangzhiyi.github.io/js/heis-custom-min.js?210610></script></body></html>